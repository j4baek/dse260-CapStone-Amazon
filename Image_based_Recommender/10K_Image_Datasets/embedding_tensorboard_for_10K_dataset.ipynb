{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create TensorBoard Image Embedding Projector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yeongchoi/Anaconda3/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.15.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os,cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import MeanShift\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.contrib.tensorboard.plugins import projector\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Feature data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get image urls and save as dictionary. {asin: image_url}\n",
    "imgUrl_df = pd.read_csv('./Results/asin_url_for_10k.csv')\n",
    "imgUrl_dict = pd.Series(imgUrl_df.url.values,index=imgUrl_df.asin).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load features.\n",
    "feature_vectors = pd.read_csv('./Results/features_10k.csv')\n",
    "feature_vectors = feature_vectors.rename(columns={\"Unnamed: 0\": \"product_id\"})\n",
    "feature_vectors.set_index('product_id',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_vectors_shape: (774, 4096)\n",
      "num of images: 774\n",
      "size of individual feature vector: 4096\n"
     ]
    }
   ],
   "source": [
    "print (\"feature_vectors_shape:\",feature_vectors.shape)\n",
    "print (\"num of images:\",feature_vectors.shape[0])\n",
    "print (\"size of individual feature vector:\",feature_vectors.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering (15 clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MinMasScaler \n",
    "mms = MinMaxScaler()\n",
    "mms.fit(feature_vectors)\n",
    "feature_transformed = mms.transform(feature_vectors)\n",
    "\n",
    "# Kmeans\n",
    "km = KMeans(n_clusters=15, random_state=0)\n",
    "km = km.fit(feature_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(774,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = np.array(km.labels_)\n",
    "label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0 34]\n",
      " [ 1 58]\n",
      " [ 2 87]\n",
      " [ 3 38]\n",
      " [ 4 63]\n",
      " [ 5 73]\n",
      " [ 6 38]\n",
      " [ 7 53]\n",
      " [ 8 41]\n",
      " [ 9 39]\n",
      " [10 45]\n",
      " [11 77]\n",
      " [12 42]\n",
      " [13 29]\n",
      " [14 57]]\n"
     ]
    }
   ],
   "source": [
    "# Check products in each cluster\n",
    "(unique, counts) = np.unique(label, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "\n",
    "print(frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('./Results/Cluster_result_15.txt', label, delimiter= ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_label_df = feature_vectors\n",
    "feature_label_df['cluster']=label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>4087</th>\n",
       "      <th>4088</th>\n",
       "      <th>4089</th>\n",
       "      <th>4090</th>\n",
       "      <th>4091</th>\n",
       "      <th>4092</th>\n",
       "      <th>4093</th>\n",
       "      <th>4094</th>\n",
       "      <th>4095</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>B00XB2Y4BA</th>\n",
       "      <td>2.579302</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.017223</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.858268</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.010415</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.510618</td>\n",
       "      <td>0.936177</td>\n",
       "      <td>4.268580</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.378045</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B00318CFWE</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.981456</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.030918</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.826475</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B00B5SCMMU</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.926949</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.650023</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.880582</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.450393</td>\n",
       "      <td>0.173273</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B00B7NVFF8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.192223</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.384481</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.443201</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B00IA41NWM</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.460994</td>\n",
       "      <td>0.079312</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.405677</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.275759</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.837105</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.871971</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4097 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0    1         2         3    4         5         6  \\\n",
       "product_id                                                               \n",
       "B00XB2Y4BA  2.579302  0.0  3.017223  0.000000  0.0  3.858268  0.000000   \n",
       "B00318CFWE  0.000000  0.0  0.000000  0.000000  0.0  0.000000  0.000000   \n",
       "B00B5SCMMU  0.000000  0.0  0.000000  3.926949  0.0  0.000000  0.000000   \n",
       "B00B7NVFF8  0.000000  0.0  0.000000  0.000000  0.0  0.000000  0.000000   \n",
       "B00IA41NWM  0.000000  0.0  0.000000  0.000000  0.0  0.460994  0.079312   \n",
       "\n",
       "                   7    8         9  ...  4087  4088      4089      4090  \\\n",
       "product_id                           ...                                   \n",
       "B00XB2Y4BA  0.000000  0.0  1.010415  ...   0.0   0.0  0.000000  0.000000   \n",
       "B00318CFWE  5.981456  0.0  0.000000  ...   0.0   0.0  2.030918  0.000000   \n",
       "B00B5SCMMU  1.650023  0.0  4.880582  ...   0.0   0.0  0.000000  0.450393   \n",
       "B00B7NVFF8  0.000000  0.0  2.192223  ...   0.0   0.0  3.384481  0.000000   \n",
       "B00IA41NWM  0.000000  0.0  4.405677  ...   0.0   0.0  1.275759  0.000000   \n",
       "\n",
       "                4091      4092      4093  4094      4095  cluster  \n",
       "product_id                                                         \n",
       "B00XB2Y4BA  1.510618  0.936177  4.268580   0.0  1.378045        1  \n",
       "B00318CFWE  0.826475  0.000000  0.000000   0.0  0.000000        1  \n",
       "B00B5SCMMU  0.173273  0.000000  0.000000   0.0  0.000000       11  \n",
       "B00B7NVFF8  4.443201  0.000000  0.000000   0.0  0.000000        7  \n",
       "B00IA41NWM  3.837105  0.000000  1.871971   0.0  0.000000        4  \n",
       "\n",
       "[5 rows x 4097 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature_label_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot take a larger sample than population when 'replace=False'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-c90fe07e327c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_label_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature_label_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cluster'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mframes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Anaconda3/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, n, frac, replace, weights, random_state, axis)\u001b[0m\n\u001b[1;32m   4968\u001b[0m             )\n\u001b[1;32m   4969\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4970\u001b[0;31m         \u001b[0mlocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4971\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_copy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot take a larger sample than population when 'replace=False'"
     ]
    }
   ],
   "source": [
    "frames = []\n",
    "for i in range(15):\n",
    "    df = feature_label_df[feature_label_df['cluster']==i].sample(n=30)\n",
    "    frames.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(450, 4097)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_feature_label_df = pd.concat(frames)\n",
    "sample_feature_label_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>4087</th>\n",
       "      <th>4088</th>\n",
       "      <th>4089</th>\n",
       "      <th>4090</th>\n",
       "      <th>4091</th>\n",
       "      <th>4092</th>\n",
       "      <th>4093</th>\n",
       "      <th>4094</th>\n",
       "      <th>4095</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>B00BMVL3FM</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.772492</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.954608</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.637149</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.180952</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B0007WDF7G</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.186482</td>\n",
       "      <td>1.742248</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.113785</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.983343</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B00IFVL0Q4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.484371</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.373306</td>\n",
       "      <td>0.494256</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.367028</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.257505</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B008OV4IUA</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.079173</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.442839</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B00F0IMQYU</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.361643</td>\n",
       "      <td>0.101608</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.269840</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.591999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.719977</td>\n",
       "      <td>1.058692</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4097 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0    1         2    3    4         5         6         7    8  \\\n",
       "product_id                                                                    \n",
       "B00BMVL3FM  0.0  0.0  0.000000  0.0  0.0  1.772492  0.000000  1.954608  0.0   \n",
       "B0007WDF7G  0.0  0.0  0.000000  0.0  0.0  2.186482  1.742248  0.000000  0.0   \n",
       "B00IFVL0Q4  0.0  0.0  0.484371  0.0  0.0  1.373306  0.494256  0.000000  0.0   \n",
       "B008OV4IUA  0.0  0.0  0.000000  0.0  0.0  1.079173  0.000000  0.000000  0.0   \n",
       "B00F0IMQYU  0.0  0.0  0.000000  0.0  0.0  0.361643  0.101608  0.000000  0.0   \n",
       "\n",
       "                   9  ...      4087  4088      4089  4090      4091  4092  \\\n",
       "product_id            ...                                                   \n",
       "B00BMVL3FM  6.637149  ...  0.000000   0.0  0.180952   0.0  0.000000   0.0   \n",
       "B0007WDF7G  2.113785  ...  0.000000   0.0  0.000000   0.0  8.983343   0.0   \n",
       "B00IFVL0Q4  0.000000  ...  0.367028   0.0  0.000000   0.0  5.257505   0.0   \n",
       "B008OV4IUA  0.000000  ...  0.000000   0.0  0.442839   0.0  0.000000   0.0   \n",
       "B00F0IMQYU  2.269840  ...  0.000000   0.0  0.000000   0.0  4.591999   0.0   \n",
       "\n",
       "                4093      4094  4095  cluster  \n",
       "product_id                                     \n",
       "B00BMVL3FM  0.000000  0.000000   0.0        0  \n",
       "B0007WDF7G  0.000000  0.000000   0.0        0  \n",
       "B00IFVL0Q4  0.000000  0.000000   0.0        0  \n",
       "B008OV4IUA  0.000000  0.000000   0.0        0  \n",
       "B00F0IMQYU  0.719977  1.058692   0.0        0  \n",
       "\n",
       "[5 rows x 4097 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_feature_label_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "products = list(sample_feature_label_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image_Path = './Sample_Images_for_tensorboard/Images_50K_sample_450/'\n",
    "# Get images for samples. \n",
    "for asin in products:\n",
    "    \n",
    "    url = imgUrl_dict[asin]\n",
    "    # Open the url image, set stream to True, this will return the stream content.\n",
    "    resp = requests.get(url, stream=True)\n",
    "    # Open a local file with wb ( write binary ) permission. (created increment filename)\n",
    "    path = os.path.join(Image_Path, asin + \".\" + \"jpg\")\n",
    "#     print(path)\n",
    "    local_file = open(path, 'wb')\n",
    "    # Set decode_content value to True, otherwise the downloaded image file's size will be zero.\n",
    "    resp.raw.decode_content = True\n",
    "    # Copy the response stream raw data to local image file.\n",
    "    shutil.copyfileobj(resp.raw, local_file)\n",
    "    # Remove the image url response object.\n",
    "    del resp\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_feature_label_df.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get features & labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'features_1:0' shape=(774, 4096) dtype=float64_ref>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = tf.Variable(feature_label_df.iloc[:,:-1], name='features')\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "774"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = feature_label_df.loc[:,'cluster'].values\n",
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_samples_all = [frequencies[i][1] for i in range(15)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize - TensorBoard "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - create a log directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of images: 774\n"
     ]
    }
   ],
   "source": [
    "PATH = os.getcwd()\n",
    "\n",
    "LOG_DIR = PATH+ '/embedding-logs'\n",
    "#metadata = os.path.join(LOG_DIR, 'metadata2.tsv')\n",
    "\n",
    "#%%\n",
    "data_path = PATH + '/10K_Shoes_images/'\n",
    "data_dir_list = os.listdir(data_path)\n",
    "print(\"number of images:\",len(data_dir_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize images\n",
    "img_data=[]\n",
    "for img in data_dir_list:\n",
    "    \n",
    "#     img_list=os.listdir(data_path+'/'+ dataset)\n",
    "#     print ('Loaded the images of dataset-'+'{}\\n'.format(dataset))\n",
    "#     print(img_list)\n",
    "#     for img in img_list:\n",
    "\n",
    "    input_img=cv2.imread(data_path + str(img) )\n",
    "    input_img_resize=cv2.resize(input_img,(224,224))\n",
    "    img_data.append(input_img_resize)\n",
    "    \n",
    "                \n",
    "img_data = np.array(img_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of images: 774\n"
     ]
    }
   ],
   "source": [
    "print(\"number of images:\",len(img_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of individual image data: (224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"shape of individual image data:\", img_data[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "774"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_of_samples = feature_label_df.shape[0]\n",
    "num_of_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['cluster0','cluster1','cluster2','cluster3','cluster4',\n",
    "         'cluster5','cluster6','cluster7','cluster8','cluster9',\n",
    "         'cluster10','cluster11','cluster12','cluster13','cluster14']\n",
    "\n",
    "#with open(metadata, 'w') as metadata_file:\n",
    "#    for row in range(210):\n",
    "#        c = y[row]\n",
    "#        metadata_file.write('{}\\n'.format(c))\n",
    "\n",
    "metadata_file = open(os.path.join(LOG_DIR, 'metadata_4_classes.tsv'), 'w')\n",
    "metadata_file.write('Class\\tName\\n')\n",
    "k=20 # num of samples in each class\n",
    "j=0\n",
    "#for i in range(210):\n",
    "#    metadata_file.write('%06d\\t%s\\n' % (i, names[y[i]]))\n",
    "for c in range(15):\n",
    "    num_of_samples = num_of_samples_all[c]\n",
    "    for i in range(num_of_samples):\n",
    "            n = names[c]\n",
    "            if i%k==0:\n",
    "                j=j+1\n",
    "            metadata_file.write('{}\\t{}\\n'.format(j,n))\n",
    "        #metadata_file.write('%06d\\t%s\\n' % (j, c))\n",
    "metadata_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken from: https://github.com/tensorflow/tensorflow/issues/6322\n",
    "def images_to_sprite(data):\n",
    "    \"\"\"Creates the sprite image along with any necessary padding\n",
    "\n",
    "    Args:\n",
    "      data: NxHxW[x3] tensor containing the images.\n",
    "\n",
    "    Returns:\n",
    "      data: Properly shaped HxWx3 image with any necessary padding.\n",
    "    \"\"\"\n",
    "    if len(data.shape) == 3:\n",
    "        data = np.tile(data[...,np.newaxis], (1,1,1,3))\n",
    "    data = data.astype(np.float32)\n",
    "    min = np.min(data.reshape((data.shape[0], -1)), axis=1)\n",
    "    data = (data.transpose(1,2,3,0) - min).transpose(3,0,1,2)\n",
    "    max = np.max(data.reshape((data.shape[0], -1)), axis=1)\n",
    "    data = (data.transpose(1,2,3,0) / max).transpose(3,0,1,2)\n",
    "    # Inverting the colors seems to look better for MNIST\n",
    "    #data = 1 - data\n",
    "\n",
    "    n = int(np.ceil(np.sqrt(data.shape[0])))\n",
    "    padding = ((0, n ** 2 - data.shape[0]), (0, 0),\n",
    "            (0, 0)) + ((0, 0),) * (data.ndim - 3)\n",
    "    data = np.pad(data, padding, mode='constant',\n",
    "            constant_values=0)\n",
    "    # Tile the individual thumbnails into an image.\n",
    "    data = data.reshape((n, n) + data.shape[1:]).transpose((0, 2, 1, 3)\n",
    "            + tuple(range(4, data.ndim + 1)))\n",
    "    data = data.reshape((n * data.shape[1], n * data.shape[3]) + data.shape[4:])\n",
    "    data = (data * 255).astype(np.uint8)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sprite = images_to_sprite(img_data)\n",
    "cv2.imwrite(os.path.join(LOG_DIR, 'sprite_4_classes.png'), sprite)\n",
    "#scipy.misc.imsave(os.path.join(LOG_DIR, 'sprite.png'), sprite)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver = tf.train.Saver([features])\n",
    "\n",
    "    sess.run(features.initializer)\n",
    "    saver.save(sess, os.path.join(LOG_DIR, 'images_4_classes.ckpt'))\n",
    "    \n",
    "    config = projector.ProjectorConfig()\n",
    "    # One can add multiple embeddings.\n",
    "    embedding = config.embeddings.add()\n",
    "    embedding.tensor_name = features.name\n",
    "    # Link this tensor to its metadata file (e.g. labels).\n",
    "    embedding.metadata_path = os.path.join(LOG_DIR, 'metadata_4_classes.tsv')\n",
    "    # Comment out if you don't want sprites\n",
    "    embedding.sprite.image_path = os.path.join(LOG_DIR, 'sprite_4_classes.png')\n",
    "    embedding.sprite.single_image_dim.extend([img_data.shape[1], img_data.shape[1]])\n",
    "    # Saves a config file that TensorBoard will read during startup.\n",
    "    projector.visualize_embeddings(tf.summary.FileWriter(LOG_DIR), config)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorboard --logdir=embedding-logs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
