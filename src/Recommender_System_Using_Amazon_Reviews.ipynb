{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender System Using Amazon Reviews\n",
    "\n",
    "- Base Dataset: \n",
    "    - Main dataset page: \n",
    "        - https://nijianmo.github.io/amazon/index.html\n",
    "    - Download dataset: \n",
    "        - http://deepyeti.ucsd.edu/jianmo/amazon/categoryFilesSmall/Clothing_Shoes_and_Jewelry_5.json.gz\n",
    "\n",
    "\n",
    "- Subset Datset to use Recommender system: \n",
    "    - Clothing_Shoes_and_Jewelry_5_reviewerID_asin_overall_unixReviewTime.csv\n",
    "    \n",
    "\n",
    "### Description of columns \n",
    "#### - Clothing_Shoes_and_Jewelry_5_reviewerID_asin_overall_unixReviewTime.csv\n",
    "- reviewerID - ID of the reviewer, e.g. A2SUAM1J3GNN3B\n",
    "    - Ex) http://www.amazon.com/gp/cdp/member-reviews/A2SUAM1J3GNN3B\n",
    "- asin - ID of the product, e.g. 0000013714\n",
    "    - Ex) http://www.amazon.com/dp/0000013714\n",
    "- overall - rating of the product\n",
    "- unixReviewTime - time of the review (unix time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/dse260-CapStone-Amazon/src\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "!{sys.executable} -m pip install --upgrade pip\n",
    "!{sys.executable} -m pip install sagemaker-experiments\n",
    "!{sys.executable} -m pip install pandas\n",
    "!{sys.executable} -m pip install numpy\n",
    "!{sys.executable} -m pip install matplotlib\n",
    "!{sys.executable} -m pip install boto3\n",
    "!{sys.executable} -m pip install sagemaker\n",
    "!{sys.executable} -m pip install pyspark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{sys.executable} -m pip install ipython-autotime\n",
    "!{sys.executable} -m pip install surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### To measure all running time\n",
    "# https://github.com/cpcloud/ipython-autotime\n",
    "\n",
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas_profiling'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e6a954763158>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msmart_open\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msmart_open\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas_profiling\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mProfileReport\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas_profiling'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.session import Session\n",
    "from sagemaker.analytics import ExperimentAnalytics\n",
    "\n",
    "import gzip\n",
    "import json\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.types import StructField, StructType, StringType, DoubleType\n",
    "from pyspark.ml.feature import StringIndexer, VectorIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "# spark imports\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import UserDefinedFunction, explode, desc\n",
    "from pyspark.sql.types import StringType, ArrayType\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from smart_open import smart_open\n",
    "\n",
    "# from pandas_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset and analysis\n",
    "- s3://dse-cohort5-group1/data-lake-landing-zone/ratings/Clothing_Shoes_and_Jewelry.csv.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install smart_open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get your credentials from environment variables\n",
    "# aws_key = 'AKIAZAERIKDLAVRFZK35'\n",
    "# aws_secret = 'tkkdilY5f9Lm0f5AvGMcCe0/51aNDW8HaF+r5WSM'\n",
    "# # aws_key = os.environ['AWS_ACCESS_KEY']\n",
    "# # aws_secret = os.environ['AWS_SECRET_ACCESS_KEY']\n",
    "\n",
    "# # s3://dse-cohort5-group1/data-lake-landing-zone/reviews/Clothing_Shoes_and_Jewelry.json.gz\n",
    "# bucket_name = 'dse-cohort5-group1'\n",
    "# object_key = 'data-lake-landing-zone/reviews/Clothing_Shoes_and_Jewelry.json.gz'\n",
    "\n",
    "# path = 's3://{}:{}@{}/{}'.format(aws_key, aws_secret, bucket_name, object_key)\n",
    "\n",
    "# review_orgin_df = pd.read_csv(smart_open(path), error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -al"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_cores = 16\n",
    "memory_gb = 64\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"amazon recommendation\") \\\n",
    "    .config(\"spark.driver.memory\", '{}g'.format(memory_gb)) \\\n",
    "    .config(\"spark.master\", 'local[{}]'.format(number_cores)) \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# get spark context\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = './'\n",
    "REVIEW_DATA = 'Clothing_Shoes_and_Jewelry.json.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = spark.read.load(DATA_PATH+REVIEW_DATA, format='json', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of Data\", (ratings.count(), len(ratings.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop and Clean data\n",
    "    - Drop null in Vote\n",
    "    - Voted review comment is more reliable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_ratings = ratings.na.drop(how='any', subset='vote')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of Data\", (clean_ratings.count(), len(clean_ratings.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_ratings.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_ratings = clean_ratings.drop(\n",
    " 'image',\n",
    " 'reviewText',\n",
    " 'reviewTime',\n",
    " 'reviewerName',\n",
    " 'style',\n",
    " 'summary',\n",
    " 'unixReviewTime',\n",
    " 'verified',\n",
    " 'vote')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_ratings.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(product_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create csv file\n",
    "product_ratings.write.csv(\"./voted_asin_overall_reviewerID.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset from filtered data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -alh ./voted_asin_overall_reviewerID.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_orgin_df = pd.read_csv('./voted_asin_overall_reviewerID.csv/part-00000-e46fb25d-448f-4be7-8739-ad2f627a4e52-c000.csv',\n",
    "                        names=['asin', 'overall', 'reviewerID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_orgin_df.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_orgin_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! conda install -c conda-forge pandas-profiling=2.6.0 -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = ProfileReport(review_orgin_df, \n",
    "                        title='Clothing_Shoes_and_Jewelry_5_reviewerID_asin_overall_unixReviewTime', \n",
    "                        minimal=True)\n",
    "profile.to_file(output_file=\"Clothing_Shoes_and_Jewelry_5_josn-Profiling-Report.html\")\n",
    "profile.to_notebook_iframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "- E-commerce companies like Amazon uses different recommendation systems to provide suggestions to the customers.\n",
    "- Amazon uses currently item-item collaberrative filtering, which scales to massive datasets and produces high quality recommendation system in the real time. \n",
    "- This system is a kind of a information filtering system which seeks to predict the \"rating\" or preferences which user is interested in.\n",
    "\n",
    "<img src=\"refer_pics/1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of recommendations\n",
    "There are mainly 6 types of the recommendations systems :\n",
    "\n",
    "1. Popularity based systems : \n",
    "    - It works by recommeding items viewed and purchased by most people and are rated high.It is not a personalized recommendation.\n",
    "2. Classification model based: \n",
    "    - It works by understanding the features of the user and applying the classification algorithm to decide whether the user is interested or not in the prodcut.\n",
    "3. Content based recommedations:\n",
    "    - It is based on the information on the contents of the item rather than on the user opinions.The main idea is if the user likes an item then he or she will like the \"other\" similar item.\n",
    "4. Collaberative Filtering:\n",
    "    - It is based on assumption that people like things similar to other things they like, and things that are liked by other people with similar taste. \n",
    "    - it is mainly of two types: a) User-User b) Item -Item\n",
    "5. Hybrid Approaches:\n",
    "    - This system approach is to combine collaborative filtering, content-based filtering, and other approaches .\n",
    "6. Association rule mining :\n",
    "    - Association rules capture the relationships between items based on their patterns of co-occurrence across transactions.\n",
    "\n",
    "## Attribute Information\n",
    "- reviewerID - ID of the reviewer, e.g. A2SUAM1J3GNN3B\n",
    "    - Ex) http://www.amazon.com/gp/cdp/member-reviews/A2SUAM1J3GNN3B\n",
    "- asin - ID of the product, e.g. 0000013714\n",
    "    - Ex) http://www.amazon.com/dp/0000013714\n",
    "- overall - rating of the product\n",
    "- unixReviewTime - time of the review (unix time)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import math\n",
    "import json\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.externals import joblib\n",
    "import scipy.sparse\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse.linalg import svds\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_orgin_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_orgin_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Five point summary \n",
    "review_orgin_df.describe()['overall'].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the minimum and maximum ratings\n",
    "print('Minimum rating is: %d' %(review_orgin_df.overall.min()))\n",
    "print('Maximum rating is: %d' %(review_orgin_df.overall.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Handling Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for missing values\n",
    "print('Number of missing values across columns: \\n',review_orgin_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ratings \n",
    "    - Most of the people has given the rating of 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the distribution of the rating\n",
    "with sns.axes_style('white'):\n",
    "    g = sns.factorplot(\"overall\", data=review_orgin_df, aspect=2.0, kind='count')\n",
    "    g.set_ylabels(\"Total number of ratings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unique Users and products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total data \")\n",
    "print(\"-\"*50)\n",
    "print(\"\\nTotal no of ratings :\",review_orgin_df.shape[0])\n",
    "print(\"Total No of Users   :\", len(np.unique(review_orgin_df.reviewerID)))\n",
    "print(\"Total No of products  :\", len(np.unique(review_orgin_df.asin)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing the rating ( overall )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analysis of rating given by the user \n",
    "no_of_rated_products_per_user = review_orgin_df.groupby(by='reviewerID')['overall'].count().sort_values(ascending=False)\n",
    "no_of_rated_products_per_user.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### how-to-format-how-a-numpy-array-prints-in-pytho\n",
    "# https://kite.com/python/answers/how-to-format-how-a-numpy-array-prints-in-python\n",
    "\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_rated_products_per_user.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles = no_of_rated_products_per_user.quantile(np.arange(0,1.01,0.01), interpolation='higher')\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.title(\"Quantiles and their Values\")\n",
    "quantiles.plot()\n",
    "# quantiles with 0.05 difference\n",
    "plt.scatter(x=quantiles.index[::5], y=quantiles.values[::5], c='orange', label=\"quantiles with 0.05 intervals\")\n",
    "# quantiles with 0.25 difference\n",
    "plt.scatter(x=quantiles.index[::25], y=quantiles.values[::25], c='m', label = \"quantiles with 0.25 intervals\")\n",
    "plt.ylabel('No of ratings by user')\n",
    "plt.xlabel('Value at the quantile')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('\\n No of rated product more than 50 per user : {}\\n'.format(sum(no_of_rated_products_per_user >= 50)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Popularity Based Recommendation\n",
    "\n",
    "- Popularity based recommendation system works with the trend. \n",
    "- It basically uses the items which are in trend right now. \n",
    "    - For example, if any product which is usually bought by every new user then there are chances that it may suggest that item to the user who just signed up.\n",
    "- The problems with popularity based recommendation system is that the personalization is not available with this method \n",
    "    - i.e. even though you know the behaviour of the user you cannot recommend items accordingly.\n",
    "    \n",
    "<img src=\"./refer_pics/2.png\">    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_df=review_orgin_df.groupby(\"asin\").filter(lambda x:x['overall'].count() >=300)\n",
    "new_df=review_orgin_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_ratings_per_product = new_df.groupby(by='asin')['overall'].count().sort_values(ascending=False)\n",
    "\n",
    "fig = plt.figure(figsize=plt.figaspect(.5))\n",
    "ax = plt.gca()\n",
    "plt.plot(no_of_ratings_per_product.values)\n",
    "plt.title('# RATINGS per Product')\n",
    "plt.xlabel('Product')\n",
    "plt.ylabel('No of ratings per product')\n",
    "ax.set_xticklabels([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Average rating of the product \n",
    "\n",
    "new_df.groupby('asin')['overall'].mean().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.groupby('asin')['overall'].mean().sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Total number of rating for product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.groupby('asin')['overall'].count().sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_mean_count = pd.DataFrame(new_df.groupby('asin')['overall'].mean())\n",
    "ratings_mean_count['rating_counts'] = pd.DataFrame(new_df.groupby('asin')['overall'].count())\n",
    "ratings_mean_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_mean_count['rating_counts'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.rcParams['patch.force_edgecolor'] = True\n",
    "ratings_mean_count['rating_counts'].hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.rcParams['patch.force_edgecolor'] = True\n",
    "ratings_mean_count['overall'].hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.rcParams['patch.force_edgecolor'] = True\n",
    "# sns.jointplot(x='overall', y='rating_counts', data=ratings_mean_count, alpha=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *** Recommned products based on Popularity Based Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_products = pd.DataFrame(new_df.groupby('asin')['overall'].count())\n",
    "most_popular = popular_products.sort_values('overall', ascending=False)\n",
    "most_popular.head(30).plot(kind = \"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Collaberative filtering (Item-Item recommedation)\n",
    "\n",
    "- Collaborative filtering is commonly used for recommender systems. \n",
    "- These techniques aim to fill in the missing entries of a user-item association matrix. \n",
    "- We are going to use collaborative filtering (CF) approach. \n",
    "    - CF is based on the idea that the best recommendations come from people who have similar tastes. \n",
    "    - In other words, it uses historical item ratings of like-minded people to predict how someone would rate an item.\n",
    "    - Collaborative filtering has two sub-categories that are generally called memory based and model-based approaches.\n",
    "    \n",
    "#### using python module: https://surprise.readthedocs.io/en/stable/    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import KNNWithMeans\n",
    "from surprise import Dataset\n",
    "from surprise import accuracy\n",
    "from surprise import Reader\n",
    "import os\n",
    "from surprise.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **** Sampling data for testing\n",
    "- Original sample size: (6940556, 4)\n",
    "- Size of sample: 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NUM_SAMPLE = 10000\n",
    "\n",
    "# print(\"shape of data: \", new_df.shape)\n",
    "# sample_df = new_df.sample(n=NUM_SAMPLE, random_state=2)\n",
    "# print(\"Sample shape of data: \", sample_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Reading the dataset\n",
    "# sample_df = sample_df.drop(columns=['unixReviewTime'])\n",
    "# reader = Reader(rating_scale=(1, 5))\n",
    "# data = Dataset.load_from_df(sample_df, reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **** All Data for testing\n",
    "- Original sample size: (6940556, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the dataset\n",
    "# data_df = new_df.drop(columns=['unixReviewTime'])\n",
    "data_df = new_df\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(data_df, reader)\n",
    "print(\"shape of data: \", data_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the dataset\n",
    "trainset, testset = train_test_split(new_df, test_size=0.3, random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collaborative Filtering\n",
    "\n",
    "- Collaborative Filtering is the most common technique used when it comes to building intelligent recommender systems that can learn to give better recommendations as more information about users is collected.\n",
    "\n",
    "- Most websites like Amazon, YouTube, and Netflix use collaborative filtering as a part of their sophisticated recommendation systems. You can use this technique to build recommenders that give suggestions to a user on the basis of the likes and dislikes of similar users.\n",
    "\n",
    "#### What Is Collaborative Filtering?\n",
    "- Collaborative filtering is a technique that can filter out items that a user might like on the basis of reactions by similar users.\n",
    "\n",
    "- It works by searching a large group of people and finding a smaller set of users with tastes similar to a particular user. It looks at the items they like and combines them to create a ranked list of suggestions.\n",
    "\n",
    "- There are many ways to decide which users are similar and combine their choices to create a list of recommendations.\n",
    "\n",
    "    - https://surprise.readthedocs.io/en/stable/knn_inspired.html\n",
    "    - https://realpython.com/build-recommendation-engine-collaborative-filtering/\n",
    "\n",
    "<img src=\"./refer_pics/KNNWithMeans.png\">  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use user_based true/false to switch for: \n",
    "- user-based collaborative filtering \n",
    "- item-based collaborative filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo = KNNWithMeans(k=5, sim_options={'name': 'pearson_baseline', 'user_based': False})\n",
    "algo.fit(trainset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the trained model against the testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = algo.test(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Item-based Model : Test Set\")\n",
    "accuracy.rmse(test_pred, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Model-based collaborative filtering system\n",
    "\n",
    "- These methods are based on machine learning and data mining techniques. \n",
    "- The goal is to train models to be able to make predictions. \n",
    "- For example, we could use existing user-item interactions to train a model to predict the top-5 items that a user might like the most. \n",
    "- One advantage of these methods is that they are able to recommend a larger number of items to a larger number of users, compared to other methods like memory based approach. - They have large coverage, even when working with large sparse matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"size of sample_df: \", sample_df.shape)\n",
    "# ratings_matrix = sample_df.pivot_table(values='overall', index='reviewerID', columns='asin', fill_value=0)\n",
    "# ratings_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/57507832/unable-to-allocate-array-with-shape-and-data-type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat /proc/sys/vm/overcommit_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo echo 1 > /proc/sys/vm/overcommit_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat /proc/sys/vm/overcommit_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"size of data_df: \", data_df.shape)\n",
    "ratings_matrix = data_df.pivot_table(values='overall', index='reviewerID', columns='asin', fill_value=0)\n",
    "ratings_matrix.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As expected, the utility matrix obtaned above is sparce, I have filled up the unknown values wth 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Transposing the matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ratings_matrix.T\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Unique products in subset of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decomposing the Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "SVD = TruncatedSVD(n_components=10)\n",
    "decomposed_matrix = SVD.fit_transform(X)\n",
    "decomposed_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = np.corrcoef(decomposed_matrix)\n",
    "correlation_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction: \n",
    "Index # of product ID purchased by customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_id = X.index[75]\n",
    "print(\"Index # of producnt ID purchased by customer: \", product_id)\n",
    "print(\"https://www.amazon.com/dp/\"+product_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.amazon.com/dp/B0002NYQO6\n",
    "\n",
    "\n",
    "<img src=\"./refer_pics/input_1.png\">  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_names = list(X.index)\n",
    "product_ID = product_names.index(product_id)\n",
    "product_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation for all items with the item purchased by this customer based on items rated by other customers people who bought the same product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_product_ID = correlation_matrix[product_ID]\n",
    "correlation_product_ID.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recommending top 25 highly correlated products in sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here are the top 10 products to be displayed by the recommendation system to the above customer based on the purchase history of other customers in the website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Recommend = list(X.index[correlation_product_ID > 0.65])\n",
    "\n",
    "# Removes the item already bought by the customer\n",
    "Recommend.remove(product_id) \n",
    "\n",
    "Recommend[0:24]\n",
    "\n",
    "for p_id in Recommend[0:24]:\n",
    "    print(\"https://www.amazon.com/dp/\"+p_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://www.amazon.com/dp/B0000AFSY8\n",
    "\n",
    "<img src=\"./refer_pics/out_1.png\">  \n",
    "\n",
    "- https://www.amazon.com/dp/B0001YRE04\n",
    "\n",
    "<img src=\"./refer_pics/out_2.png\">  \n",
    "\n",
    "- https://www.amazon.com/dp/B0002FHJ66    \n",
    "\n",
    "<img src=\"./refer_pics/out_3.png\"> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
