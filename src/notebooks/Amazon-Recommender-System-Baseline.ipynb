{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### To measure all running time\n",
    "# https://github.com/cpcloud/ipython-autotime\n",
    "\n",
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 661 ms\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "from collections import defaultdict\n",
    "import scipy\n",
    "import scipy.optimize\n",
    "import numpy\n",
    "import random\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import time\n",
    "import csv\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 817 µs\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = './Dataset/'\n",
    "\n",
    "# fn_meta = 'meta_Clothing_Shoes_and_Jewelry.json.gz'\n",
    "# fn_reviews = 'reviews_Clothing_Shoes_and_Jewelry_5.json.gz'\n",
    "# sample = 'sample_data_1M.json.gz'\n",
    "\n",
    "# download file from http://deepyeti.ucsd.edu/jianmo/amazon/categoryFilesSmall/Clothing_Shoes_and_Jewelry.csv\n",
    "# and run gzip to compress\n",
    "fn_ratings = 'Clothing_Shoes_and_Jewelry.csv.gz'\n",
    "\n",
    "path = DATA_DIR + fn_ratings\n",
    "\n",
    "ENV = 'local'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 788 µs\n"
     ]
    }
   ],
   "source": [
    "# colnames=['user_id', 'product_id', 'rating'] \n",
    "# rating_df = pd.read_csv(path, names=colnames, header=None,  compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.97 ms\n"
     ]
    }
   ],
   "source": [
    "def parse(path):\n",
    "    for line in gzip.open(path, 'r'):\n",
    "        yield json.loads(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For 5-core ( start ) review "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Dataset/Clothing_Shoes_and_Jewelry_5.json.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'user_id': 'AZI75OKBKZ98R', 'product_id': '0871167042', 'rating': 5}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.18 s\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = './Dataset/'\n",
    "fn_5core = 'Clothing_Shoes_and_Jewelry_5.json.gz'\n",
    "path = DATA_DIR + fn_5core\n",
    "print(path)\n",
    "\n",
    "BATCH_SIZE = 100000\n",
    "\n",
    "i = 0\n",
    "\n",
    "dataset = []\n",
    "usersPerItem = defaultdict(set)\n",
    "itemsPerUser = defaultdict(set)\n",
    "reviewsPerUser = defaultdict(list)\n",
    "reviewsPerItem = defaultdict(list) \n",
    "\n",
    "for line in parse(path):\n",
    "    d = dict()\n",
    "    d['user_id'] = line['reviewerID']\n",
    "    d['product_id'] = line['asin']\n",
    "    d['rating'] = int(line['overall'])\n",
    "    dataset.append(d)\n",
    "    i += 1\n",
    "    if i > BATCH_SIZE:\n",
    "        break\n",
    "    \n",
    "for d in dataset:\n",
    "    user,item = d['user_id'], d['product_id']\n",
    "    reviewsPerUser[user].append(d)\n",
    "    reviewsPerItem[item].append(d)\n",
    "    usersPerItem[item].add(user)\n",
    "    itemsPerUser[user].add(item)\n",
    "\n",
    "dataset[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 6.81 ms\n"
     ]
    }
   ],
   "source": [
    "N = len(dataset)\n",
    "nUsers = len(reviewsPerUser)\n",
    "nItems = len(reviewsPerItem)\n",
    "\n",
    "#Getting a list of keys\n",
    "users = list(reviewsPerUser.keys())\n",
    "items = list(reviewsPerItem.keys())\n",
    "\n",
    "#This is equivalent to our Rating Mean from week 1\n",
    "alpha = sum([d['rating'] for d in dataset]) / len(dataset)\n",
    "\n",
    "#Create another two defaultdict's, this time being float types because they are prediction based\n",
    "userBiases = defaultdict(float)\n",
    "itemBiases = defaultdict(float)\n",
    "\n",
    "def MSE(predictions, labels):\n",
    "    differences = [(x-y)**2 for x,y in zip(predictions,labels)]\n",
    "    return sum(differences) / len(differences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.24 ms\n"
     ]
    }
   ],
   "source": [
    "def Jaccard(s1, s2):\n",
    "    numer = len(s1.intersection(s2))\n",
    "    denom = len(s1.union(s2))\n",
    "    return numer / denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 5.12 ms\n"
     ]
    }
   ],
   "source": [
    "def predictRating(user,item):\n",
    "    ratings = []\n",
    "    similarities = []\n",
    "    for d in reviewsPerUser[user]:\n",
    "        i2 = d['product_id']\n",
    "        if i2 == item: continue\n",
    "        ratings.append(d['rating'])\n",
    "        similarities.append(Jaccard(usersPerItem[item],usersPerItem[i2]))\n",
    "    if (sum(similarities) > 0):\n",
    "        weightedRatings = [(x*y) for x,y in zip(ratings,similarities)]\n",
    "        return sum(weightedRatings) / sum(similarities)\n",
    "    else:\n",
    "        # User hasn't rated any similar items\n",
    "        return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 7.29 ms\n"
     ]
    }
   ],
   "source": [
    "class Logger():\n",
    "    def __init__(self):\n",
    "        self.STATUS = 'OFF'\n",
    "        self.START_TIME = None\n",
    "        self.END_TIME = None\n",
    "        self.EXECUTION_TIME = None\n",
    "        self.LOGS = []\n",
    "        self.MODEL = None\n",
    "        self.SCORE = None\n",
    "        self.STAT = None\n",
    "        \n",
    "    def start(self, model=None, stat=None, score=None):\n",
    "        self.START_TIME = time.time()\n",
    "        self.STATUS = 'ON'\n",
    "        if model:\n",
    "            self.MODEL = model\n",
    "            self.LOGS.append(\"Model: {m}\".format(m=model))\n",
    "        if stat:\n",
    "            self.STAT = stat\n",
    "            self.LOGS.append(\"Statistic: {s}\".format(s=stat))\n",
    "        if score:\n",
    "            self.SCORE = score\n",
    "            self.LOGS.append(\"Score: {s}\".format(s=score))\n",
    "        \n",
    "    def end(self, display=True, score=None):\n",
    "        if self.STATUS == 'OFF':\n",
    "            print(\"No timer started.\")\n",
    "        else:\n",
    "            self.END_TIME = time.time()\n",
    "            self.EXECUTION_TIME = self.END_TIME - self.START_TIME\n",
    "            self.LOGS.append(\"Time: {t}\".format(t=self.EXECUTION_TIME))\n",
    "            if score:\n",
    "                self.SCORE = score\n",
    "                self.LOGS.append(\"Score: {s}\".format(s=score))\n",
    "            if display == True:\n",
    "                self.getStats(last=False)\n",
    "            else:\n",
    "                r = self.LOGS\n",
    "                self.tearDown()\n",
    "                return r\n",
    "            self.tearDown()\n",
    "    \n",
    "    def tearDown(self):\n",
    "        self.STATUS = 'OFF'\n",
    "        self.LOGS = []\n",
    "        \n",
    "    def getStats(self, show=True, last=True):\n",
    "        if show == True:   \n",
    "            if last == True:\n",
    "                print(\"STATUS: {v}\".format(v=self.STATUS))\n",
    "                print(\"START_TIME: {v}\".format(v=self.START_TIME))\n",
    "                print(\"END_TIME: {v}\".format(v=self.END_TIME))\n",
    "                print(\"EXECUTION_TIME: {v}\".format(v=self.EXECUTION_TIME))\n",
    "                print(\"MODEL: {v}\".format(v=self.MODEL))\n",
    "                print(\"STAT: {v}\".format(v=self.STAT))\n",
    "                print(\"SCORE: {v}\".format(v=self.SCORE))\n",
    "            else:\n",
    "                for l in self.LOGS:\n",
    "                    print(l)\n",
    "        else:\n",
    "            return self.MODEL, self.STAT, self.SCORE, self.EXECUTION_TIME\n",
    "\n",
    "        \n",
    "timer = Logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 17.1 ms\n"
     ]
    }
   ],
   "source": [
    "labels = [d['rating'] for d in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2160867173437198\n",
      "0.9359891765231052\n",
      "1.2160867173437198 0.9359891765231052\n",
      "\n",
      "Model: Baseline\n",
      "Statistic: MSE\n",
      "Score: 1.2160867173437198\n",
      "Time: 0.0025463104248046875\n",
      "\n",
      "time: 13.8 s\n"
     ]
    }
   ],
   "source": [
    "# baseline\n",
    "alwaysPredictMean = [alpha for d in dataset]\n",
    "labels = [d['rating'] for d in dataset]\n",
    "MSE(alwaysPredictMean, labels)\n",
    "\n",
    "cfPredictions = [predictRating(d['user_id'], d['product_id']) for d in dataset] \n",
    "\n",
    "print(MSE(alwaysPredictMean, labels))\n",
    "print(MSE(cfPredictions, labels))\n",
    "print(MSE(alwaysPredictMean, labels), MSE(cfPredictions, labels)) \n",
    "print()\n",
    "timer.start(model='Baseline', stat='MSE', score=MSE(alwaysPredictMean, labels))\n",
    "alwaysPredictMean = [alpha for d in dataset]\n",
    "timer.end()\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heuristic \n",
    "\n",
    "- Heuristic analysis is an expert based analysis that determines the susceptibility of a system towards particular threat/risk using various decision rules or weighing methods. MultiCriteria analysis (MCA) is one of the means of weighing.\n",
    "\n",
    "- https://en.wikipedia.org/wiki/Heuristic_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mode: Weighted Ratings Heuristic\n",
      "Score by MSE:  0.9359891765231052\n",
      "time: 13.8 s\n"
     ]
    }
   ],
   "source": [
    "score=MSE(cfPredictions, labels)\n",
    "cfPredictions = [predictRating(d['user_id'], d['product_id']) for d in dataset]\n",
    "print(\"Mode: Weighted Ratings Heuristic\")\n",
    "print(\"Score by MSE: \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 101\n",
      "ProductID: 3979050432\n",
      "Number Matches: 10\n",
      "time: 3.89 ms\n"
     ]
    }
   ],
   "source": [
    "def mostSimilar(item, n):\n",
    "    similarities = []\n",
    "    users = usersPerItem[item]\n",
    "    for i2 in usersPerItem:\n",
    "        if i2 == item: continue\n",
    "        sim = Jaccard(users, usersPerItem[i2])\n",
    "        similarities.append([sim,i2])\n",
    "    similarities.sort(reverse=True)\n",
    "    return similarities[:n]\n",
    "\n",
    "def mostSimilarFast(item, n):\n",
    "    similarities = []\n",
    "    users = usersPerItem[item]\n",
    "    candidateItems = set()\n",
    "    for u in users:\n",
    "        candidateItems = candidateItems.union(itemsPerUser[u])\n",
    "    for i2 in candidateItems:\n",
    "        if i2 == item: continue\n",
    "        sim = Jaccard(users, usersPerItem[i2])\n",
    "        similarities.append([sim, i2])\n",
    "    similarities.sort(reverse=True)\n",
    "    return similarities[:n]\n",
    "\n",
    "# Test Params\n",
    "n = 10 \n",
    "idx = 101 \n",
    "query = dataset[idx]['product_id']\n",
    "\n",
    "print(\"Index: {i}\".format(i=idx))\n",
    "print(\"ProductID: {q}\".format(q=query))\n",
    "print(\"Number Matches: {i}\".format(i=n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Most Similar\n",
      "Statistic: Jaccard Similarity\n",
      "Time: 0.025446176528930664\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[0.009174311926605505, 'B00001T38Y'],\n",
       " [0.003003003003003003, 'B0000WL1Q0'],\n",
       " [0.002680965147453083, 'B0000WL0XY'],\n",
       " [0.0010706638115631692, 'B0000DCS5T'],\n",
       " [0.0008880994671403197, 'B0001YR54E'],\n",
       " [0.0005558643690939411, 'B00009ZM7Z'],\n",
       " [0.0005518763796909492, 'B0000CBALZ'],\n",
       " [0.00014490653528474135, 'B00028AZ6E'],\n",
       " [0.00014490653528474135, 'B0001YRFS0'],\n",
       " [0.0, 'B0002NZ898']]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 30.5 ms\n"
     ]
    }
   ],
   "source": [
    "timer.start(model='Most Similar', stat='Jaccard Similarity')\n",
    "sims1 = mostSimilar(query, n)\n",
    "timer.end(display=True)\n",
    "sims1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Most Similar Optimized\n",
      "Statistic: Jaccard Similarity\n",
      "Time: 0.004246950149536133\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[0.009174311926605505, 'B00001T38Y'],\n",
       " [0.003003003003003003, 'B0000WL1Q0'],\n",
       " [0.002680965147453083, 'B0000WL0XY'],\n",
       " [0.0010706638115631692, 'B0000DCS5T'],\n",
       " [0.0008880994671403197, 'B0001YR54E'],\n",
       " [0.0005558643690939411, 'B00009ZM7Z'],\n",
       " [0.0005518763796909492, 'B0000CBALZ'],\n",
       " [0.00014490653528474135, 'B00028AZ6E'],\n",
       " [0.00014490653528474135, 'B0001YRFS0']]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 13.6 ms\n"
     ]
    }
   ],
   "source": [
    "timer.start(model='Most Similar Optimized', stat='Jaccard Similarity')\n",
    "sims2 = mostSimilarFast(query, n)\n",
    "timer.end(display=True)\n",
    "sims2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A2IC3NZN488KWK</td>\n",
       "      <td>0871167042</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A30FG02C424EJ5</td>\n",
       "      <td>0871167042</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A2G9GWQEWWNQUB</td>\n",
       "      <td>0871167042</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A3NI5OGW35SLY2</td>\n",
       "      <td>0871167042</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A1OPRA4NE56EV6</td>\n",
       "      <td>0871167042</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          user_id  product_id  rating\n",
       "0  A2IC3NZN488KWK  0871167042       5\n",
       "1  A30FG02C424EJ5  0871167042       5\n",
       "2  A2G9GWQEWWNQUB  0871167042       5\n",
       "3  A3NI5OGW35SLY2  0871167042       5\n",
       "4  A1OPRA4NE56EV6  0871167042       5"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 95.7 ms\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(dataset)\n",
    "X = df[['user_id', 'product_id']]\n",
    "y = df[['rating']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaberative filtering \n",
    "\n",
    "* Product Similarity recommedation\n",
    "* User Similarity recomendation\n",
    "\n",
    "This model uses historical user/item ratings that are similar to predict ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.1 ms\n"
     ]
    }
   ],
   "source": [
    "# !pip install surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 388 ms\n"
     ]
    }
   ],
   "source": [
    "from surprise import KNNWithMeans\n",
    "from surprise import Dataset\n",
    "from surprise import accuracy\n",
    "from surprise import Reader\n",
    "import os\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "#Reading the dataset\n",
    "reader = Reader(rating_scale=(0, 5))\n",
    "data = Dataset.load_from_df(df,reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 142 ms\n"
     ]
    }
   ],
   "source": [
    "#Splitting the dataset\n",
    "trainset, testset = train_test_split(data, \n",
    "                                     test_size=0.3,\n",
    "                                     random_state=11, \n",
    "                                     shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use user_based true/false to switch between user-based or item-based collaborative filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Model: Product KNN\n",
      "Statistic: MSE\n",
      "Time: 0.31182003021240234\n",
      "Score:  0.9860290835457611\n",
      "time: 316 ms\n"
     ]
    }
   ],
   "source": [
    "timer.start(model='Product KNN', stat='MSE')\n",
    "algo = KNNWithMeans(k=5, sim_options={'name': 'cosine', 'user_based': False})\n",
    "algo.fit(trainset)\n",
    "test_pred = algo.test(testset)\n",
    "acc = accuracy.mse(test_pred, verbose=False)\n",
    "timer.end()\n",
    "print(\"Score: \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timer.start(model='User KNN', stat='MSE')\n",
    "algo = KNNWithMeans(k=5, sim_options={'name': 'cosine', 'user_based': True})\n",
    "algo.fit(trainset)\n",
    "test_pred = algo.test(testset)\n",
    "acc = accuracy.mse(test_pred, verbose=False)\n",
    "timer.end()\n",
    "print(\"Score: \", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Script to create batch files with 1M records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item2indx = dict()\n",
    "user2indx = dict()\n",
    "review2indx = dict()\n",
    "metadata = {}\n",
    "user_counts = Counter()\n",
    "item_counts = Counter()\n",
    "review_counts = Counter()\n",
    "\n",
    "idx = 0\n",
    "idxs = 0\n",
    "BATCH_SIZE=1000000\n",
    "nBatches = 24\n",
    "cBatch = 0\n",
    "maxid = idx + BATCH_SIZE\n",
    "f = gzip.open(path, 'rt', encoding=\"utf8\")\n",
    "header = ['userID', 'itemID', 'rating']\n",
    "\n",
    "for line in f:\n",
    "    fields = line.strip().split(',')\n",
    "    d = dict(zip(header, fields))\n",
    "\n",
    "    user, item, rating = d['itemID'], d['userID'], int(d['rating'][0])\n",
    "\n",
    "    if user not in user2indx:\n",
    "        user2indx[user] = len(user2indx)\n",
    "    if item not in item2indx:\n",
    "        item2indx[item] = len(item2indx)\n",
    "\n",
    "    userid, itemid = user2indx[user], item2indx[item]\n",
    "    user_counts[userid] += 1\n",
    "    item_counts[itemid] += 1\n",
    "    review_counts[rating] += 1\n",
    "\n",
    "    if itemid < minItemId:\n",
    "        minItemId = itemid\n",
    "    if itemid > maxItemId:\n",
    "        maxItemId = itemid\n",
    "\n",
    "    reviewIdxs.append([userid, itemid, rating])\n",
    "    idx += 1\n",
    "\n",
    "    if idx >= maxid:\n",
    "        try:\n",
    "            with open(DATA_DIR + 'Clothing_Shoes_and_Jewelry/items/' + str(minItemId) + \"_\" + str(maxItemId) + \".csv\", 'w') as batch2:\n",
    "                batch_writer2 = csv.writer(batch2)   \n",
    "                print(minItemId, maxItemId)\n",
    "                batch_writer2.writerows(reviewIdxs)\n",
    "            \n",
    "        except csv.Error as e:\n",
    "            print(e)\n",
    "\n",
    "        finally:\n",
    "            batch2.close()\n",
    "            reviewIdxs = []\n",
    "            maxid = idx + BATCH_SIZE\n",
    "            minItemId = 9999999999999999\n",
    "            maxItemId = 0        \n",
    "            cBatch += 1\n",
    "            if maxid >= 32292099 + 100000:\n",
    "                maxid = 32292099\n",
    "                cBatch = 23\n",
    "                print('maxbatch')\n",
    "            if cBatch >= nBatches:\n",
    "                break  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example data sets\n",
    "pd.read_csv(DATA_DIR + 'Clothing_Shoes_and_Jewelry/items/14022_609843.csv', header=None, names=['userID', 'itemID', 'rating'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user2indx\n",
    "user_counts\n",
    "item_counts\n",
    "len(item2indx)\n",
    "print('i size: {}'.format(len(item_counts)))\n",
    "print('u size: {}'.format(len(user_counts)))\n",
    "print('r size: {}'.format(len(review_counts)))\n",
    "print('most common: {}'.format(item_counts.most_common(10)))\n",
    "indx2item = {indx:itm for itm,indx in item2indx.items()}\n",
    "index2user = {indx:itm for itm,indx in user2indx.items()}\n",
    "with open(DATA_DIR + 'Clothing_Shoes_and_Jewelry/items/id_to_item.json', 'w') as f:\n",
    "    json.dump(indx2item, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df1=dfs.head(10000)\n",
    "ratings_matrix = new_df1.pivot_table(values='rating', index='user_id', columns='product_id', fill_value=0)\n",
    "ratings_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes / Scratch code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metadata = {}\n",
    "# metadata['X_train'] = {\n",
    "#     \"users\": X_train['user_id'].count(),\n",
    "#     \"items\": X_train['product_id'].count()\n",
    "# }\n",
    "# metadata['y_train'] = {\n",
    "#     \"ratings\": y_train['rating'].count()\n",
    "# }\n",
    "# metadata['X_valid'] = {\n",
    "#     \"users\": X_valid['user_id'].count(),\n",
    "#     \"items\": X_valid['product_id'].count()\n",
    "# }\n",
    "# metadata['y_valid'] = {\n",
    "#     \"ratings\": y_valid['rating'].count()\n",
    "# }\n",
    "# metadata['X_test'] = {\n",
    "#     \"users\": X_test['user_id'].count(),\n",
    "#     \"items\": X_test['product_id'].count()\n",
    "# }\n",
    "# metadata['y_test'] = {\n",
    "#     \"ratings\": y_test['rating'].count()\n",
    "# }\n",
    "# metadata\n",
    "\n",
    "def load(data):\n",
    "    \"\"\"\n",
    "    takes the training file no and return training and test data\n",
    "    Ex. fileno = 1 for u1.base and u1.test\n",
    "        fileno = 5 for u5.base and u5.test\n",
    "    \"\"\"\n",
    "#     dataset = filename\n",
    "#     df = pd.DataFrame(dataset)\n",
    "#     X = df[['user_id', 'product_id']]\n",
    "#     y = df[['rating']]\n",
    "#     df.head()\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "#     X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
    "\n",
    "    # userid songid user-rating\n",
    "#     basedir = \"../dataset/ml-100k/u%s.\" % (fileno)\n",
    "#     with open(basedir + 'base') as f:\n",
    "#         training = np.loadtxt(f)\n",
    "#     with open(basedir + 'test') as f:\n",
    "#         test = np.loadtxt(f)    \n",
    "#     with open('../dataset/ml-100k/u.info') as f:\n",
    "#         metafile = np.genfromtxt(f)\n",
    "#     metafile = np.delete(metafile, len(metafile[0]) - 1, 1)\n",
    "\n",
    "    metadata = {}\n",
    "    metadata['users'] = data['user_id'].nunique() \n",
    "    metadata['items'] = data['product_id'].nunique() \n",
    "    metadata['ratings'] = data['rating'].nunique() \n",
    "    return data, metadata\n",
    "\n",
    "data, metadata = load(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def constructRatingMatrix(data, metadata):\n",
    "    user = int(metadata['users'])\n",
    "    item = int(metadata['items'])\n",
    "    # ratingMatrix = np.zeros((metadata['users'], metadata['items']))\n",
    "    ratingMatrix = np.zeros((user, item))\n",
    "    for i in data:\n",
    "        \n",
    "        ratingMatrix[int(i[0])-1][int(i[1])-1] = i[2] \n",
    "    return ratingMatrix\n",
    "\n",
    "\n",
    "\n",
    "ratingMatrix = constructRatingMatrix(data, metadata)\n",
    "ratingMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = np.array(X_train)\n",
    "for i in d:\n",
    "#     print(i-2)\n",
    "    print(i[0])\n",
    "    print(i[1])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr\n",
    "# dataArray\n",
    "ratingMatrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timer.start()\n",
    "def makeDic(data):\n",
    "    dataDic = {}\n",
    "    for i in data:\n",
    "        dataDic.setdefault(i[0], {}).update({i[1]: i[2]})\n",
    "    return dataDic\n",
    "\n",
    "dataArray = np.array(df)\n",
    "dataDic = makeDic(dataArray)\n",
    "timer.end()\n",
    "len(dataDic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timer.start()\n",
    "def makeArray(dic):\n",
    "    arr = []\n",
    "    for user,items in dic.items():\n",
    "        for k,v in items.items():\n",
    "            row = []\n",
    "            row.append(user)\n",
    "            row.append(k)\n",
    "            row.append(v)\n",
    "            arr.append(row)\n",
    "    return arr\n",
    "\n",
    "arr = makeArray(dataDic)\n",
    "timer.end()\n",
    "len(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(dfs['user_id'])\n",
    "usersEnc = le.transform(dfs['user_id'])\n",
    "le.classes_\n",
    "\n",
    "le2 = preprocessing.LabelEncoder()\n",
    "le2.fit(dfs['product_id'])\n",
    "productsEnc = le2.transform(dfs['product_id'])\n",
    "le2.classes_\n",
    "\n",
    "le3 = preprocessing.LabelEncoder()\n",
    "le3.fit(dfs['rating'])\n",
    "ratingsEnc = le3.transform(dfs['rating'])\n",
    "le3.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = np.array([usersEnc, productsEnc, ratingsEnc])\n",
    "mat = mat.T\n",
    "print(mat.shape)\n",
    "mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "simmat = cosine_similarity(mat).flatten()\n",
    "simmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ratings_matrix.T\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decomposing the Matrix\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "SVD = TruncatedSVD(n_components=10)\n",
    "decomposed_matrix = SVD.fit_transform(X)\n",
    "decomposed_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation Matrix\n",
    "\n",
    "correlation_matrix = np.corrcoef(decomposed_matrix)\n",
    "correlation_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainset, testset = train_test_split(data, test_size=0.3,random_state=10)\n",
    "X.index[75]\n",
    "\n",
    "i = \"B0001ZNZF6\"\n",
    "\n",
    "product_names = list(X.index)\n",
    "product_ID = product_names.index(i)\n",
    "product_ID\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_product_ID = correlation_matrix[product_ID]\n",
    "correlation_product_ID.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Recommend = list(X.index[correlation_product_ID > 0.65])\n",
    "\n",
    "# Removes the item already bought by the customer\n",
    "Recommend.remove(i) \n",
    "\n",
    "Recommend[0:24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use user_based true/false to switch between user-based or item-based collaborative filtering\n",
    "algo = KNNWithMeans(k=5, sim_options={'name': 'cosine', 'user_based': True})\n",
    "algo.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the trained model against the testset\n",
    "test_pred = algo.test(testset)\n",
    "\n",
    "print(\"User-based Model : Test Set\")\n",
    "accuracy.rmse(test_pred, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the trained model against the testset\n",
    "test_pred = algo.test(testset)\n",
    "\n",
    "print(\"User-based Model : Test Set\")\n",
    "accuracy.rmse(test_pred, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get RMSE\n",
    "print(\"Item-based Model : Test Set\")\n",
    "accuracy.rmse(test_pred, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine(n_x, yr, min_support):\n",
    "    # sum (r_xy * r_x'y) for common ys\n",
    "#     cdef np.ndarray[np.double_t, ndim=2] prods\n",
    "#     # number of common ys\n",
    "#     cdef np.ndarray[np.int_t, ndim=2] freq\n",
    "#     # sum (r_xy ^ 2) for common ys\n",
    "#     cdef np.ndarray[np.double_t, ndim=2] sqi\n",
    "#     # sum (r_x'y ^ 2) for common ys\n",
    "#     cdef np.ndarray[np.double_t, ndim=2] sqj\n",
    "#     # the similarity matrix\n",
    "#     cdef np.ndarray[np.double_t, ndim=2] sim\n",
    "\n",
    "#     cdef int xi, xj\n",
    "#     cdef double ri, rj\n",
    "#     cdef int min_sprt = min_support\n",
    "\n",
    "    prods = np.zeros((n_x, n_x), np.double)\n",
    "    freq = np.zeros((n_x, n_x), np.int)\n",
    "    sqi = np.zeros((n_x, n_x), np.double)\n",
    "    sqj = np.zeros((n_x, n_x), np.double)\n",
    "    sim = np.zeros((n_x, n_x), np.double)\n",
    "\n",
    "    for y, y_ratings in iteritems(yr):\n",
    "        for xi, ri in y_ratings:\n",
    "            for xj, rj in y_ratings:\n",
    "                freq[xi, xj] += 1\n",
    "                prods[xi, xj] += ri * rj\n",
    "                sqi[xi, xj] += ri**2\n",
    "                sqj[xi, xj] += rj**2\n",
    "\n",
    "    for xi in range(n_x):\n",
    "        sim[xi, xi] = 1\n",
    "        for xj in range(xi + 1, n_x):\n",
    "            if freq[xi, xj] < min_sprt:\n",
    "                sim[xi, xj] = 0\n",
    "            else:\n",
    "                denum = np.sqrt(sqi[xi, xj] * sqj[xi, xj])\n",
    "                sim[xi, xj] = prods[xi, xj] / denum\n",
    "\n",
    "            sim[xj, xi] = sim[xi, xj]\n",
    "\n",
    "    return sim\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def ww_sim(s1, s2):\n",
    "    \"\"\"Calculate topn most similar words to word\"\"\"\n",
    "#     indx = tok2indx[word]\n",
    "    s1list = []\n",
    "    for x in s1:\n",
    "        indx = tok2indx[x]\n",
    "        s1list.append(indx)\n",
    "        \n",
    "    s2list = []\n",
    "\n",
    "    for y in s2:\n",
    "        indy = tok2indx[y]\n",
    "        s2list.append(indy)\n",
    "#     if isinstance(mat, sparse.csr_matrix):\n",
    "#         v1 = mat.getrow(indx)\n",
    "#     else:\n",
    "#         v1 = mat[indx:indx+1, :]\n",
    "    sims = cosine_similarity(np.array(s1list).reshape(-1, 1), np.array(s2list).reshape(-1, 1))\n",
    "#     sindxs = np.argsort(-sims)\n",
    "#     sim_word_scores = [(indx2tok[sindx], sims[sindx]) for sindx in sindxs[0:topn]]\n",
    "    return sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_c = cooc/cooc.sum(axis=0).sum()\n",
    "p_c_w = cooc\n",
    "for x in range(len(p_c_w)):\n",
    "    p_c_w[x,:] = p_c_w[x,:]/p_c_w[x,:].sum()\n",
    "\n",
    "p_c_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item2indx = dict()\n",
    "item_counts = Counter()\n",
    "\n",
    "for token in df:\n",
    "    item = token[0]\n",
    "    item_counts[item] += 1\n",
    "    if item not in item2indx:\n",
    "        item2indx[item] = len(item2indx)\n",
    "indx2item = {indx:tok for tok,indx in item2indx.items()}\n",
    "print('vocabulary size: {}'.format(len(item_counts)))\n",
    "print('most common: {}'.format(item_counts.most_common(10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "back_window = 2\n",
    "front_window = 2\n",
    "skipgram_counts = Counter()\n",
    "\n",
    "for ifw, fw in enumerate(df):\n",
    "        icw_min = max(0, ifw - back_window)\n",
    "        icw_max = min(len(filtered_words) - 1, ifw + front_window)\n",
    "        icws = [ii for ii in range(icw_min, icw_max + 1) if ii != ifw]\n",
    "        \n",
    "        for d in reviewsPerUser[user]:\n",
    "        i2 = d['product_id']\n",
    "        if i2 == item: continue\n",
    "        ratings.append(d['star_rating'])\n",
    "        similarities.append(Jaccard(usersPerItem[item],usersPerItem[i2]))\n",
    "    if (sum(similarities) > 0):\n",
    "        weightedRatings = [(x*y) for x,y in zip(ratings,similarities)]\n",
    "        return sum(weightedRatings) / sum(similarities)\n",
    "    else:\n",
    "        # User hasn't rated any similar items\n",
    "        return ratingMean\n",
    "    \n",
    "        for icw in icws:\n",
    "            skipgram = (filtered_words[ifw], filtered_words[icw])\n",
    "            skipgram_counts[skipgram] += 1\n",
    "\n",
    "        \n",
    "print('number of skipgrams: {}'.format(len(skipgram_counts)))\n",
    "print('most common: {}'.format(skipgram_counts.most_common(10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import *\n",
    "from pyspark import SparkContext,SparkConf\n",
    "\n",
    "def create_sc(pyFiles):\n",
    "    sc_conf = SparkConf()\n",
    "    sc_conf.setAppName(\"RecomenderAmazon\")\n",
    "    sc_conf.set('spark.executor.memory', '3g')\n",
    "    sc_conf.set('spark.executor.cores', '1')\n",
    "    sc_conf.set('spark.cores.max', '4')\n",
    "    sc_conf.set('spark.default.parallelism','10')\n",
    "    sc_conf.set('spark.logConf', True)\n",
    "    print(sc_conf.getAll())\n",
    "\n",
    "    sc = SparkContext(conf=sc_conf,pyFiles=pyFiles)\n",
    "\n",
    "    return sc \n",
    "\n",
    "sc = create_sc(pyFiles=[])\n",
    "\n",
    "sqlContext = SQLContext(sc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df=sqlContext.read.parquet(parquet_path)\n",
    "\n",
    "# RDDin\n",
    "# RDD=RDDin.map(lambda v:np.array(np.insert(v,0,1),dtype=np.float64))\n",
    "# df.to_parquet('df.parquet.gzip',\n",
    "#               compression='gzip')  \n",
    "\n",
    "# df.append(['0123456479', 'A1KLRMWW2FWPL4', 5.0])\n",
    "# df.append(['1608299953', 'A1KLRMWW2FWPL4', 4.0])\n",
    "# df.append(['1617160377', 'A2G5TCU2WDFZ65', 5.0])\n",
    "sdf = sqlContext.createDataFrame(df, (\"item\", \"user\", \"rating\"))\n",
    "sdf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlContext.registerDataFrameAsTable(sdf,'ratings')\n",
    "\n",
    "Query=\"\"\"\n",
    "SELECT item, count(item) as count \n",
    "FROM ratings \n",
    "GROUP BY item\n",
    "ORDER BY count desc\n",
    "\"\"\"\n",
    "counts=sqlContext.sql(Query)\n",
    "counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Query2=\"\"\"\n",
    "SELECT user, count(user) as count \n",
    "FROM ratings \n",
    "GROUP BY user\n",
    "ORDER BY count desc\n",
    "\"\"\"\n",
    "counts2=sqlContext.sql(Query2)\n",
    "counts2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Query3=\"\"\"\n",
    "SELECT item, rating from ratings \n",
    "where user = 'A1KLRMWW2FWPL4' and item <>'0000031887'\n",
    "\"\"\"\n",
    "counts3=sqlContext.sql(Query3)\n",
    "counts3.show()\n",
    "\n",
    "Query3=\"\"\"\n",
    "SELECT user, rating from ratings \n",
    "where item in ('0123456479', '1608299953')\n",
    "\"\"\"\n",
    "counts3=sqlContext.sql(Query3)\n",
    "counts3.show()\n",
    "\n",
    "# ratings.append(d['star_rating'])\n",
    "#         similarities.append(Jaccard(usersPerItem[item],usersPerItem[i2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import linalg as LA\n",
    "\n",
    "def outerProduct(X):\n",
    "    \"\"\"Computer outer product and indicate which locations in matrix are undefined\"\"\"\n",
    "    O=np.outer(X,X)\n",
    "    N=1-np.isnan(O)\n",
    "    return (O,N)\n",
    "\n",
    "def sumWithNan(M1,M2):\n",
    "    \"\"\"Add two pairs of (matrix,count)\"\"\"\n",
    "    (X1,N1)=M1\n",
    "    (X2,N2)=M2\n",
    "    N=N1+N2\n",
    "    X=np.nansum(np.dstack((X1,X2)),axis=2)\n",
    "    return (X,N)\n",
    "\n",
    "\n",
    "def HW_func(S,N):\n",
    "    E=      np.ones([365]) # E is the sum of the vectors\n",
    "    NE=     np.ones([365]) # NE is the number of not-nan antries for each coordinate of the vectors\n",
    "    Mean=   np.ones([365]) # Mean is the Mean vector (ignoring nans)\n",
    "    O=      np.ones([365,365]) # O is the sum of the outer products\n",
    "    NO=     np.ones([365,365]) # NO is the number of non-nans in the outer product.\n",
    "    return  E,NE,Mean,O,NO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeCov(RDDin):\n",
    "    \"\"\"computeCov recieves as input an RDD of np arrays, all of the same length, \n",
    "    and computes the covariance matrix for that set of vectors\"\"\"\n",
    "    RDD=RDDin.map(lambda v:np.array(np.insert(v,0,1),dtype=np.float64)) # insert a 1 at the beginning of each vector so that the same \n",
    "                                           #calculation also yields the mean vector\n",
    "    OuterRDD=RDD.map(outerProduct)   # separating the map and the reduce does not matter because of Spark uses lazy execution.\n",
    "    (S,N)=OuterRDD.reduce(sumWithNan)\n",
    "\n",
    "    E,NE,Mean,O,NO=HW_func(S,N)\n",
    "\n",
    "    Cov=O/NO - np.outer(Mean,Mean)\n",
    "    # Output also the diagnal which is the variance for each day\n",
    "    Var=np.array([Cov[i,i] for i in range(Cov.shape[0])])\n",
    "    return {'E':E,'NE':NE,'O':O,'NO':NO,'Cov':Cov,'Mean':Mean,'Var':Var}\n",
    "\n",
    "RDD=sc.parallelize(df)\n",
    "RDD = RDD.map(lambda x: x[2])\n",
    "OUT=computeCov(RDD)\n",
    "\n",
    "eigval,eigvec=LA.eig(OUT['Cov'])\n",
    "print('eigval=',eigval)\n",
    "print('eigvec=',eigvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeOverAllDist(rdd0):\n",
    "    UnDef=np.array(rdd0.map(lambda row:sum(np.isnan(row))).sample(False,0.01).collect())\n",
    "    flat=rdd0.flatMap(lambda v:list(v)).filter(lambda x: not np.isnan(x)).cache()\n",
    "    count,S1,S2=flat.map(lambda x: np.float64([1,x,x**2]))\\\n",
    "                  .reduce(lambda x,y: x+y)\n",
    "    mean=S1/count\n",
    "    std=np.sqrt(S2/count-mean**2)\n",
    "    Vals=flat.sample(False,0.0001).collect()\n",
    "    SortedVals=np.array(sorted(Vals))\n",
    "    low100,high100=find_percentiles(SortedVals,100)\n",
    "    low1000,high1000=find_percentiles(SortedVals,1000)\n",
    "    return {'UnDef':UnDef,\\\n",
    "          'mean':mean,\\\n",
    "          'std':std,\\\n",
    "          'SortedVals':SortedVals,\\\n",
    "          'low100':low100,\\\n",
    "          'high100':high100,\\\n",
    "          'low1000':low100,\\\n",
    "          'high1000':high1000\n",
    "          }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# sdf.select('rating').filter(\"user == 'A1KLRMWW2FWPL4'\").groupBy('user').show()\n",
    "def packArray(a):\n",
    "    \"\"\"\n",
    "    pack a numpy array into a bytearray that can be stored as a single \n",
    "    field in a spark DataFrame\n",
    "\n",
    "    :param a: a numpy ndarray \n",
    "    :returns: a bytearray\n",
    "    :rtype:\n",
    "\n",
    "    \"\"\"\n",
    "    if type(a)!=np.ndarray:\n",
    "        raise Exception(\"input to packArray should be numpy.ndarray. It is instead \"+str(type(a)))\n",
    "    return bytearray(a.tobytes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from numpy_pack import packArray,unpackArray\n",
    "def unpackArray(x,data_type=np.int16):\n",
    "    \"\"\"\n",
    "    unpack a bytearray into a numpy.ndarray\n",
    "\n",
    "    :param x: a bytearray\n",
    "    :param data_type: The dtype of the array. This is important because if determines how many bytes go into each entry in the array.\n",
    "    :returns: a numpy array\n",
    "    :rtype: a numpy ndarray of dtype data_type.\n",
    "\n",
    "    \"\"\"\n",
    "    return np.frombuffer(x,dtype=data_type)\n",
    "\n",
    "data=mdf.rdd.map(lambda row: unpackArray(row['Values'],np.float16))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
