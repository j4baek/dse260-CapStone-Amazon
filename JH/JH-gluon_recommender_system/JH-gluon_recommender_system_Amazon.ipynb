{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing a Recommender System with SageMaker, MXNet, and Gluon\n",
    "_**Making Product Recommendations Using Neural Networks and Embeddings**_\n",
    "\n",
    "--- \n",
    "\n",
    "---\n",
    "\n",
    "*This work is based on content from the [Cyrus Vahid's 2017 re:Invent Talk](https://github.com/cyrusmvahid/gluontutorials/blob/master/recommendations/MLPMF.ipynb)*\n",
    "\n",
    "\n",
    "## Contents\n",
    "\n",
    "1. [Background](#Background)\n",
    "1. [Setup](#Setup)\n",
    "1. [Data](#Data)\n",
    "  1. [Explore](#Explore)\n",
    "  1. [Clean](#Clean)\n",
    "  1. [Prepare](#Prepare)\n",
    "1. [Train Locally](#Train-Locally)\n",
    "  1. [Define Network](#Define-Network)\n",
    "  1. [Set Parameters](#Set-Parameters)\n",
    "  1. [Execute](#Execute)\n",
    "1. [Train with SageMaker](#Train-with-SageMaker)\n",
    "  1. [Wrap Code](#Wrap-Code)\n",
    "  1. [Move Data](#Move-Data)\n",
    "  1. [Submit](#Submit)\n",
    "1. [Host](#Host)\n",
    "  1. [Evaluate](#Evaluate)\n",
    "1. [Wrap-up](#Wrap-up)\n",
    "\n",
    "---\n",
    "\n",
    "## Background\n",
    "\n",
    "In many ways, recommender systems were a catalyst for the current popularity of machine learning.  One of Amazon's earliest successes was the \"Customers who bought this, also bought...\" feature, while the million dollar Netflix Prize spurred research, raised public awareness, and inspired numerous other data science competitions.\n",
    "\n",
    "Recommender systems can utilize a multitude of data sources and ML algorithms, and most combine various unsupervised, supervised, and reinforcement learning techniques into a holistic framework.  However, the core component is almost always a model which which predicts a user's rating (or purchase) for a certain item based on that user's historical ratings of similar items as well as the behavior of other similar users.  The minimal required dataset for this is a history of user item ratings.  In our case, we'll use 1 to 5 star ratings from over 2M Amazon customers on over 160K digital videos.  More details on this dataset can be found at its [AWS Public Datasets page](https://s3.amazonaws.com/amazon-reviews-pds/readme.html).\n",
    "\n",
    "Matrix factorization has been the cornerstone of most user-item prediction models.  This method starts with the large, sparse, user-item ratings in a single matrix, where users index the rows, and items index the columns.  It then seeks to find two lower-dimensional, dense matrices which, when multiplied together, preserve the information and relationships in the larger matrix.\n",
    "\n",
    "![image](https://data-artisans.com/img/blog/factorization.svg)\n",
    "\n",
    "Matrix factorization has been extended and genarlized with deep learning and embeddings.  These techniques allows us to introduce non-linearities for enhanced performance and flexibility.  This notebook will fit a neural network-based model to generate recommendations for the Amazon video dataset.  It will start by exploring our data in the notebook and even training a model on a sample of the data.  Later we'll expand to the full dataset and fit our model using a SageMaker managed training cluster.  We'll then deploy to an endpoint and check our method.\n",
    "\n",
    "---\n",
    "\n",
    "## Setup\n",
    "\n",
    "_This notebook was created and tested on an ml.p2.xlarge notebook instance._\n",
    "\n",
    "Let's start by specifying:\n",
    "\n",
    "- The S3 bucket and prefix that you want to use for training and model data.  This should be within the same region as the Notebook Instance, training, and hosting.\n",
    "- The IAM role arn used to give training and hosting access to your data. See the documentation for how to create these.  Note, if more than one role is required for notebook instances, training, and/or hosting, please replace the `get_execution_role()` call with the appropriate full IAM role arn string(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipython-autotime in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (0.1)\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 20.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install ipython-autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### To measure all running time\n",
    "# https://github.com/cpcloud/ipython-autotime\n",
    "\n",
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "isConfigCell": true,
    "tags": [
     "parameters"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 805 ms\n"
     ]
    }
   ],
   "source": [
    "bucket = 'dse-cohort5-group1'\n",
    "prefix = 'UCSD-sagemaker/recommender-gluon-recsys'\n",
    "\n",
    "import sagemaker\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's load the Python libraries we'll need for the remainder of this example notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.46 s\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import mxnet as mx\n",
    "from mxnet import gluon, nd, ndarray\n",
    "from mxnet.metric import MSE\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sagemaker\n",
    "from sagemaker.mxnet import MXNet\n",
    "import boto3\n",
    "import json\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Data\n",
    "\n",
    "### Explore\n",
    "\n",
    "Let's start by bringing in our dataset from an S3 public bucket.  As mentioned above, this contains 1 to 5 star ratings from over 2M Amazon customers on over 160K digital videos.  More details on this dataset can be found at its [AWS Public Datasets page](https://s3.amazonaws.com/amazon-reviews-pds/readme.html).\n",
    "\n",
    "_Note, because this dataset is over a half gigabyte, the load from S3 may take ~10 minutes.  Also, since Amazon SageMaker Notebooks start with a 5GB persistent volume by default, and we don't need to keep this data on our instance for long, we'll bring it to the temporary volume (which has up to 20GB of storage)._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 741 Âµs\n"
     ]
    }
   ],
   "source": [
    "# !mkdir /tmp/recsys/\n",
    "# !aws s3 cp s3://amazon-reviews-pds/tsv/amazon_reviews_us_Digital_Video_Download_v1_00.tsv.gz /tmp/recsys/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 1.9G\n",
      "drwxrwxr-x 4 ec2-user ec2-user 4.0K May 16 02:00 .\n",
      "drwxrwxr-x 7 ec2-user ec2-user 4.0K May 15 02:45 ..\n",
      "-rw-rw-r-- 1 ec2-user ec2-user 916M May 15 19:31 asin_overall_reviewerID_with_voted_review_2.csv\n",
      "-rw-rw-r-- 1 ec2-user ec2-user 916M May 14 18:17 asin_overall_reviewerID_with_voted_review.csv\n",
      "drwxrwxr-x 2 ec2-user ec2-user 4.0K May 15 16:56 .ipynb_checkpoints\n",
      "-rw-rw-r-- 1 ec2-user ec2-user 122K May 16 01:58 JH-gluon_recommender_system_Amazon.ipynb\n",
      "drwxrwxr-x 2 ec2-user ec2-user 4.0K May 16 01:59 __pycache__\n",
      "-rw-rw-r-- 1 ec2-user ec2-user 9.4K May 16 01:58 recommender.py\n",
      "-rw-rw-r-- 1 ec2-user ec2-user 3.9M May 16 01:47 remove_long_tail_customer_product_start_with_voted_review.csv\n",
      "-rw-rw-r-- 1 ec2-user ec2-user 5.2M May 16 01:47 remove_long_tail_customer_product_start_with_voted_review.pickle\n",
      "-rw-rw-r-- 1 ec2-user ec2-user 3.9M May 16 01:47 remove_long_tail_customer_product_start_with_voted_review.tsv\n",
      "-rw-rw-r-- 1 ec2-user ec2-user  89M May 15 18:15 remove_long_tail_customer_product_start_with_voted_review.tsv.gz\n",
      "-rw-rw-r-- 1 ec2-user ec2-user  23K May 16 02:00 test_recommender.ipynb\n"
     ]
    }
   ],
   "source": [
    "!ls -alh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access /tmp/recsys/: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!ls -al /tmp/recsys/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 188 ms\n"
     ]
    }
   ],
   "source": [
    "!rm -rf /tmp/recsys/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access /tmp/recsys/: No such file or directory\n",
      "time: 118 ms\n"
     ]
    }
   ],
   "source": [
    "!ls -al /tmp/recsys/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir /tmp/recsys/\n",
    "# !cp asin_overall_reviewerID_with_voted_review.csv /tmp/recsys/\n",
    "!cp asin_overall_reviewerID_with_voted_review_2.csv /tmp/recsys/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's read the data into a [Pandas DataFrame](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html) so that we can begin to understand it.\n",
    "\n",
    "*Note, we'll set `error_bad_lines=False` when reading the file in as there appear to be a very small number of records which would create a problem otherwise.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 916M\n",
      "drwxrwxr-x  2 ec2-user ec2-user 4.0K May 16 01:42 .\n",
      "drwxrwxrwx 44 root     root     148K May 16 01:42 ..\n",
      "-rw-rw-r--  1 ec2-user ec2-user 916M May 16 01:42 asin_overall_reviewerID_with_voted_review_2.csv\n",
      "time: 118 ms\n"
     ]
    }
   ],
   "source": [
    "!ls -alh /tmp/recsys/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>star_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A2IC3NZN488KWK</td>\n",
       "      <td>0871167042</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A3OT9BYASFGU2X</td>\n",
       "      <td>0871167042</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A28GK1G2KDXHRP</td>\n",
       "      <td>0871167042</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A3NFXFEKW8OK0E</td>\n",
       "      <td>0871167042</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A3I6G5TKBVJEK9</td>\n",
       "      <td>0871167042</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      customer_id  product_id  star_rating\n",
       "0  A2IC3NZN488KWK  0871167042          5.0\n",
       "1  A3OT9BYASFGU2X  0871167042          4.0\n",
       "2  A28GK1G2KDXHRP  0871167042          5.0\n",
       "3  A3NFXFEKW8OK0E  0871167042          5.0\n",
       "4  A3I6G5TKBVJEK9  0871167042          5.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 27.1 s\n"
     ]
    }
   ],
   "source": [
    "# df = pd.read_csv('/tmp/recsys/asin_overall_reviewerID_with_voted_review.csv', \n",
    "#                  names=['product_id', 'star_rating', 'customer_id'],\n",
    "#                  error_bad_lines=False)\n",
    "\n",
    "df = pd.read_csv('/tmp/recsys/asin_overall_reviewerID_with_voted_review_2.csv',\n",
    "                 error_bad_lines=False)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32292099, 3)\n",
      "customer_id    0\n",
      "product_id     0\n",
      "star_rating    0\n",
      "dtype: int64\n",
      "time: 4.59 s\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3998345, 3)\n",
      "customer_id    0\n",
      "product_id     0\n",
      "star_rating    0\n",
      "dtype: int64\n",
      "time: 5.17 s\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "df = df.sample(n=3998345, random_state=1)\n",
    "\n",
    "print(df.shape)\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data format\n",
    "- Format is one-review-per-line in json. See examples below for further help reading the data.\n",
    "\n",
    "    - reviewerID ( customer_id ) - ID of the reviewer, e.g. A2SUAM1J3GNN3B\n",
    "    - asin ( product_id )- ID of the product, e.g. 0000013714\n",
    "    - reviewerName - name of the reviewer\n",
    "    - vote - helpful votes of the review\n",
    "    - style - a disctionary of the product metadata, e.g., \"Format\" is \"Hardcover\"\n",
    "    - reviewText - text of the review\n",
    "    - overall ( star_rating )- rating of the product\n",
    "    - summary - summary of the review\n",
    "    - unixReviewTime - time of the review (unix time)\n",
    "    - reviewTime - time of the review (raw)\n",
    "    - image - images that users post after they have received the produc\n",
    "    \n",
    "## Drop and Clean data\n",
    "    - Drop null in Vote\n",
    "    - Voted review comment is more reliable.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df[['customer_id', 'product_id', 'star_rating']]\n",
    "# print(df.shape)\n",
    "# df.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('asin_overall_reviewerID_with_voted_review_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Because most people haven't review most products, and people rate fewer products than we actually use, we'd expect our data to be sparse.  \n",
    "#### - Our algorithm should work well with this sparse problem in general, but we may still want to clean out some of the long tail.  \n",
    "#### - Let's look at some basic percentiles to confirm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "customers\n",
      " 0.00     1.0\n",
      "0.01     1.0\n",
      "0.02     1.0\n",
      "0.03     1.0\n",
      "0.04     1.0\n",
      "0.05     1.0\n",
      "0.10     1.0\n",
      "0.25     1.0\n",
      "0.50     1.0\n",
      "0.75     1.0\n",
      "0.90     2.0\n",
      "0.95     3.0\n",
      "0.96     3.0\n",
      "0.97     3.0\n",
      "0.98     4.0\n",
      "0.99     5.0\n",
      "1.00    71.0\n",
      "Name: customer_id, dtype: float64\n",
      "===========================================\n",
      "products\n",
      " 0.00       1.0\n",
      "0.01       1.0\n",
      "0.02       1.0\n",
      "0.03       1.0\n",
      "0.04       1.0\n",
      "0.05       1.0\n",
      "0.10       1.0\n",
      "0.25       1.0\n",
      "0.50       1.0\n",
      "0.75       3.0\n",
      "0.90       7.0\n",
      "0.95      14.0\n",
      "0.96      17.0\n",
      "0.97      21.0\n",
      "0.98      30.0\n",
      "0.99      52.0\n",
      "1.00    2358.0\n",
      "Name: product_id, dtype: float64\n",
      "time: 6.89 s\n"
     ]
    }
   ],
   "source": [
    "customers = df['customer_id'].value_counts()\n",
    "products = df['product_id'].value_counts()\n",
    "\n",
    "quantiles = [0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.1, 0.25, 0.5, 0.75, 0.9, 0.95, 0.96, 0.97, 0.98, 0.99, 1]\n",
    "print('customers\\n', customers.quantile(quantiles))\n",
    "print('===========================================')\n",
    "print('products\\n', products.quantile(quantiles))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As we can see, only about 10% of customers have rated 5 or more products, and only 10% of products have been rated by 16+ customers.\n",
    "\n",
    "## Clean\n",
    "\n",
    "### - Let's filter out this long tail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>star_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AZ9VR9ESKVJEV</td>\n",
       "      <td>B001AXVE7O</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A22J6E4W5280PN</td>\n",
       "      <td>B001AXVE7O</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A2F3AONT5ZFWUQ</td>\n",
       "      <td>B001AXVE7O</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      customer_id  product_id  star_rating\n",
       "0   AZ9VR9ESKVJEV  B001AXVE7O          5.0\n",
       "1  A22J6E4W5280PN  B001AXVE7O          5.0\n",
       "2  A2F3AONT5ZFWUQ  B001AXVE7O          5.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 5.78 s\n"
     ]
    }
   ],
   "source": [
    "customers = customers[customers >= 5]\n",
    "products = products[products >= 16]\n",
    "\n",
    "reduced_df = df.merge(pd.DataFrame({'customer_id': customers.index})).merge(pd.DataFrame({'product_id': products.index}))\n",
    "reduced_df.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(137310, 3)\n",
      "customer_id    0\n",
      "product_id     0\n",
      "star_rating    0\n",
      "dtype: int64\n",
      "time: 40.9 ms\n"
     ]
    }
   ],
   "source": [
    "print(reduced_df.shape)\n",
    "print(reduced_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After filtering out long tail:  (137310, 3)\n",
      "The removed rows after filtering out long tail:  3861035\n",
      "time: 1.21 ms\n"
     ]
    }
   ],
   "source": [
    "print(\"After filtering out long tail: \", reduced_df.shape)\n",
    "print(\"The removed rows after filtering out long tail: \", df.shape[0]-reduced_df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save dataframe to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 403 ms\n"
     ]
    }
   ],
   "source": [
    "reduced_df.to_csv('remove_long_tail_customer_product_start_with_voted_review.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save dataframe to pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 111 ms\n"
     ]
    }
   ],
   "source": [
    "reduced_df.to_pickle('remove_long_tail_customer_product_start_with_voted_review.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save dataframe to tsv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 405 ms\n"
     ]
    }
   ],
   "source": [
    "reduced_df.to_csv('remove_long_tail_customer_product_start_with_voted_review.tsv', sep='\\t',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "customer_id\tproduct_id\tstar_rating\n",
      "AZ9VR9ESKVJEV\tB001AXVE7O\t5.0\n",
      "A22J6E4W5280PN\tB001AXVE7O\t5.0\n",
      "A2F3AONT5ZFWUQ\tB001AXVE7O\t5.0\n",
      "A35S4JL923WBHM\tB001AXVE7O\t5.0\n",
      "A3A4UKJUP34E18\tB001AXVE7O\t4.0\n",
      "AC2R5BG2IN9MY\tB001AXVE7O\t5.0\n",
      "APSVODIXP6LQ3\tB001AXVE7O\t4.0\n",
      "AM7K48FV8I2TV\tB001AXVE7O\t4.0\n",
      "A1D2UACWUF2FLA\tB001AXVE7O\t5.0\n",
      "time: 187 ms\n"
     ]
    }
   ],
   "source": [
    "!head remove_long_tail_customer_product_start_with_voted_review.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 971 Âµs\n"
     ]
    }
   ],
   "source": [
    "# !gzip remove_long_tail_customer_product_start_with_voted_review.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 916M\n",
      "drwxrwxr-x  2 ec2-user ec2-user 4.0K May 16 01:42 .\n",
      "drwxrwxrwx 44 root     root     148K May 16 01:46 ..\n",
      "-rw-rw-r--  1 ec2-user ec2-user 916M May 16 01:42 asin_overall_reviewerID_with_voted_review_2.csv\n",
      "time: 186 ms\n"
     ]
    }
   ],
   "source": [
    "!ls -alh /tmp/recsys/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 371 ms\n"
     ]
    }
   ],
   "source": [
    "!rm -rf /tmp/recsys/\n",
    "!mkdir /tmp/recsys/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 152K\n",
      "drwxrwxr-x  2 ec2-user ec2-user 4.0K May 16 01:49 .\n",
      "drwxrwxrwx 44 root     root     148K May 16 01:49 ..\n",
      "time: 185 ms\n"
     ]
    }
   ],
   "source": [
    "!ls -alh /tmp/recsys/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 188 ms\n"
     ]
    }
   ],
   "source": [
    "!cp remove_long_tail_customer_product_start_with_voted_review.csv /tmp/recsys/\n",
    "# !cp remove_long_tail_customer_product_start_with_voted_review.tsv.gz /tmp/recsys/\n",
    "# !cp remove_long_tail_customer_product_start_with_voted_review.pickle /tmp/recsys/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 4.1M\n",
      "drwxrwxr-x  2 ec2-user ec2-user 4.0K May 16 01:49 .\n",
      "drwxrwxrwx 44 root     root     148K May 16 01:49 ..\n",
      "-rw-rw-r--  1 ec2-user ec2-user 3.9M May 16 01:49 remove_long_tail_customer_product_start_with_voted_review.csv\n",
      "time: 187 ms\n"
     ]
    }
   ],
   "source": [
    "!ls -alh /tmp/recsys/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataframe from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 99.1 ms\n"
     ]
    }
   ],
   "source": [
    "reduced_df = pd.read_csv('/tmp/recsys/remove_long_tail_customer_product_start_with_voted_review.csv')\n",
    "# reduced_df = pd.read_pickle('remove_long_tail_customer_product_start_with_voted_review.pickle')\n",
    "# reduced_df = pd.read_csv('remove_long_tail_customer_product_start_with_voted_review.tsv.gz',\n",
    "#                             delimiter='\\t', \n",
    "#                             error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>star_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AZ9VR9ESKVJEV</td>\n",
       "      <td>B001AXVE7O</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A22J6E4W5280PN</td>\n",
       "      <td>B001AXVE7O</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      customer_id  product_id  star_rating\n",
       "0   AZ9VR9ESKVJEV  B001AXVE7O          5.0\n",
       "1  A22J6E4W5280PN  B001AXVE7O          5.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 7.69 ms\n"
     ]
    }
   ],
   "source": [
    "reduced_df.head(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(137310, 3)\n",
      "customer_id    0\n",
      "product_id     0\n",
      "star_rating    0\n",
      "dtype: int64\n",
      "time: 22.9 ms\n"
     ]
    }
   ],
   "source": [
    "print(reduced_df.shape)\n",
    "print(reduced_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll recreate our customer and product lists since there are customers with more than 5 reviews, but all of their reviews are on products with less than 5 reviews (and vice versa)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 115 ms\n"
     ]
    }
   ],
   "source": [
    "customers = reduced_df['customer_id'].value_counts()\n",
    "products = reduced_df['product_id'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll number each user and item, giving them their own sequential index.  This will allow us to hold the information in a sparse format where the sequential indices indicate the row and column in our ratings matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AZ9VR9ESKVJEV</td>\n",
       "      <td>B001AXVE7O</td>\n",
       "      <td>5.0</td>\n",
       "      <td>34832</td>\n",
       "      <td>1972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A22J6E4W5280PN</td>\n",
       "      <td>B001AXVE7O</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15423</td>\n",
       "      <td>1972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A2F3AONT5ZFWUQ</td>\n",
       "      <td>B001AXVE7O</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2987</td>\n",
       "      <td>1972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A35S4JL923WBHM</td>\n",
       "      <td>B001AXVE7O</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11045</td>\n",
       "      <td>1972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A3A4UKJUP34E18</td>\n",
       "      <td>B001AXVE7O</td>\n",
       "      <td>4.0</td>\n",
       "      <td>34043</td>\n",
       "      <td>1972</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      customer_id  product_id  star_rating   user  item\n",
       "0   AZ9VR9ESKVJEV  B001AXVE7O          5.0  34832  1972\n",
       "1  A22J6E4W5280PN  B001AXVE7O          5.0  15423  1972\n",
       "2  A2F3AONT5ZFWUQ  B001AXVE7O          5.0   2987  1972\n",
       "3  A35S4JL923WBHM  B001AXVE7O          5.0  11045  1972\n",
       "4  A3A4UKJUP34E18  B001AXVE7O          4.0  34043  1972"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 83.6 ms\n"
     ]
    }
   ],
   "source": [
    "customer_index = pd.DataFrame({'customer_id': customers.index, 'user': np.arange(customers.shape[0])})\n",
    "product_index = pd.DataFrame({'product_id': products.index, \n",
    "                              'item': np.arange(products.shape[0])})\n",
    "\n",
    "reduced_df = reduced_df.merge(customer_index).merge(product_index)\n",
    "reduced_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare\n",
    "\n",
    "Let's start by splitting in training and test sets.  This will allow us to estimate the model's accuracy on videos our customers rated, but wasn't included in our training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 199 ms\n"
     ]
    }
   ],
   "source": [
    "test_df = reduced_df.groupby('customer_id').last().reset_index()\n",
    "\n",
    "train_df = reduced_df.merge(test_df[['customer_id', 'product_id']], \n",
    "                            on=['customer_id', 'product_id'], \n",
    "                            how='outer', \n",
    "                            indicator=True)\n",
    "train_df = train_df[(train_df['_merge'] == 'left_only')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can convert our Pandas DataFrames into MXNet NDArrays, use those to create a member of the SparseMatrixDataset class, and add that to an MXNet Data Iterator.  This process is the same for both test and control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 314 ms\n"
     ]
    }
   ],
   "source": [
    "# [JH] need to tune batch_size for hyperparameter \n",
    "batch_size = 1024\n",
    "\n",
    "train = gluon.data.ArrayDataset(nd.array(train_df['user'].values, dtype=np.float32),\n",
    "                                nd.array(train_df['item'].values, dtype=np.float32),\n",
    "                                nd.array(train_df['star_rating'].values, dtype=np.float32))\n",
    "test  = gluon.data.ArrayDataset(nd.array(test_df['user'].values, dtype=np.float32),\n",
    "                                nd.array(test_df['item'].values, dtype=np.float32),\n",
    "                                nd.array(test_df['star_rating'].values, dtype=np.float32))\n",
    "\n",
    "train_iter = gluon.data.DataLoader(train, shuffle=True, num_workers=4, batch_size=batch_size, last_batch='rollover')\n",
    "test_iter = gluon.data.DataLoader(train, shuffle=True, num_workers=4, batch_size=batch_size, last_batch='rollover')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Train Locally\n",
    "\n",
    "### Define Network\n",
    "\n",
    "### [JH] Need to tune by hyperparameter\n",
    "\n",
    "Let's start by defining the neural network version of our matrix factorization task.  In this case, our network is quite simple.  The main components are:\n",
    "- [Embeddings](https://mxnet.incubator.apache.org/api/python/gluon/nn.html#mxnet.gluon.nn.Embedding) which turn our indexes into dense vectors of fixed size.  In this case, 64.\n",
    "- [Dense layers](https://mxnet.incubator.apache.org/api/python/gluon.html#mxnet.gluon.nn.Dense) with ReLU activation.  Each dense layer has the same number of units as our number of embeddings.  Our ReLU activation here also adds some non-linearity to our matrix factorization.\n",
    "- [Dropout layers](https://mxnet.incubator.apache.org/api/python/gluon.html#mxnet.gluon.nn.Dropout) which can be used to prevent over-fitting.\n",
    "- Matrix multiplication of our user matrix and our item matrix to create an estimate of our rating matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.75 ms\n"
     ]
    }
   ],
   "source": [
    "class MFBlock(gluon.HybridBlock):\n",
    "    def __init__(self, max_users, max_items, num_emb, dropout_p=0.5):\n",
    "        super(MFBlock, self).__init__()\n",
    "        \n",
    "        self.max_users = max_users\n",
    "        self.max_items = max_items\n",
    "        self.dropout_p = dropout_p\n",
    "        self.num_emb = num_emb\n",
    "        \n",
    "        with self.name_scope():\n",
    "            self.user_embeddings = gluon.nn.Embedding(max_users, num_emb)\n",
    "            self.item_embeddings = gluon.nn.Embedding(max_items, num_emb)\n",
    "            \n",
    "            self.dropout_user = gluon.nn.Dropout(dropout_p)\n",
    "            self.dropout_item = gluon.nn.Dropout(dropout_p)\n",
    "\n",
    "            self.dense_user   = gluon.nn.Dense(num_emb, activation='relu')\n",
    "            self.dense_item = gluon.nn.Dense(num_emb, activation='relu')\n",
    "            \n",
    "    def hybrid_forward(self, F, users, items):\n",
    "        a = self.user_embeddings(users)\n",
    "        a = self.dense_user(a)\n",
    "        \n",
    "        b = self.item_embeddings(items)\n",
    "        b = self.dense_item(b)\n",
    "\n",
    "        predictions = self.dropout_user(a) * self.dropout_item(b)     \n",
    "        predictions = F.sum(predictions, axis=1)\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.63 ms\n"
     ]
    }
   ],
   "source": [
    "# [JH] Need to tune by hyperparameter\n",
    "num_embeddings = 64\n",
    "\n",
    "net = MFBlock(max_users=customer_index.shape[0], \n",
    "              max_items=product_index.shape[0],\n",
    "              num_emb=num_embeddings,\n",
    "              dropout_p=0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Parameters\n",
    "\n",
    "Let's initialize network weights and set our optimization parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set GPU:  gpu(0)\n",
      "time: 3.46 s\n"
     ]
    }
   ],
   "source": [
    "# Initialize network parameters\n",
    "ctx = mx.gpu()\n",
    "print(\"Set GPU: \", ctx\n",
    "     )\n",
    "net.collect_params().initialize(mx.init.Xavier(magnitude=60),\n",
    "                                ctx=ctx,\n",
    "                                force_reinit=True)\n",
    "net.hybridize()\n",
    "\n",
    "# [JH] Need to tune by hpyerparameter\n",
    "# Set optimization parameters\n",
    "opt = 'sgd'\n",
    "lr = 0.02\n",
    "momentum = 0.9\n",
    "wd = 0.\n",
    "\n",
    "trainer = gluon.Trainer(net.collect_params(),\n",
    "                        opt,\n",
    "                        {'learning_rate': lr,\n",
    "                         'wd': wd,\n",
    "                         'momentum': momentum})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute\n",
    "\n",
    "Let's define a function to carry out the training of our neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.13 ms\n"
     ]
    }
   ],
   "source": [
    "def execute(train_iter, test_iter, net, epochs, ctx):\n",
    "    \n",
    "    loss_function = gluon.loss.L2Loss()\n",
    "    for e in range(epochs):\n",
    "        \n",
    "        print(\"epoch: {}\".format(e))\n",
    "        \n",
    "        for i, (user, item, label) in enumerate(train_iter):\n",
    "                user = user.as_in_context(ctx)\n",
    "                item = item.as_in_context(ctx)\n",
    "                label = label.as_in_context(ctx)\n",
    "                \n",
    "                with mx.autograd.record():\n",
    "                    output = net(user, item)               \n",
    "                    loss = loss_function(output, label)\n",
    "                    \n",
    "                loss.backward()\n",
    "                trainer.step(batch_size)\n",
    "\n",
    "        print(\"EPOCH {}: MSE ON TRAINING and TEST: {}. {}\".format(e,\n",
    "                                                                   eval_net(train_iter, net, ctx, loss_function),\n",
    "                                                                   eval_net(test_iter, net, ctx, loss_function)))\n",
    "    print(\"end of training\")\n",
    "    return net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Let's also define a function which evaluates our network on a given dataset.  \n",
    "#### - This is called by our `execute` function above to provide `mean squared error` values on our training and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.99 ms\n"
     ]
    }
   ],
   "source": [
    "def eval_net(data, net, ctx, loss_function):\n",
    "    acc = MSE()\n",
    "    for i, (user, item, label) in enumerate(data):\n",
    "        \n",
    "            user = user.as_in_context(ctx)\n",
    "            item = item.as_in_context(ctx)\n",
    "            label = label.as_in_context(ctx)\n",
    "            predictions = net(user, item).reshape((batch_size, 1))\n",
    "            acc.update(preds=[predictions], labels=[label])\n",
    "   \n",
    "    return acc.get()[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's train for a few epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "EPOCH 0: MSE ON TRAINING and TEST: 1.2824539707062093. 1.2793790704460555\n",
      "end of training\n",
      "CPU times: user 1.69 s, sys: 235 ms, total: 1.92 s\n",
      "Wall time: 2.69 s\n",
      "time: 2.69 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# [JH] Need to tune by hyperparameter\n",
    "# epochs = 3\n",
    "epochs = 1\n",
    "\n",
    "trained_net = execute(train_iter, test_iter, net, epochs, ctx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Early Validation\n",
    "\n",
    "We can see our training error going down, but our validation accuracy bounces around a bit.  Let's check how our model is predicting for an individual user.  We could pick randomly, but for this case, let's try user #6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>item</th>\n",
       "      <th>u6_predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24818</th>\n",
       "      <td>B014X3ETEC</td>\n",
       "      <td>24818</td>\n",
       "      <td>5.257283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27449</th>\n",
       "      <td>B0111Z1JOS</td>\n",
       "      <td>27449</td>\n",
       "      <td>5.173516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14021</th>\n",
       "      <td>B00B53DIJQ</td>\n",
       "      <td>14021</td>\n",
       "      <td>5.125332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9411</th>\n",
       "      <td>B00LI721V0</td>\n",
       "      <td>9411</td>\n",
       "      <td>5.109960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14390</th>\n",
       "      <td>B0088WY684</td>\n",
       "      <td>14390</td>\n",
       "      <td>5.090626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10231</th>\n",
       "      <td>B0163DPZDO</td>\n",
       "      <td>10231</td>\n",
       "      <td>5.080999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8406</th>\n",
       "      <td>B0114979CW</td>\n",
       "      <td>8406</td>\n",
       "      <td>5.077700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8594</th>\n",
       "      <td>B002APVEF8</td>\n",
       "      <td>8594</td>\n",
       "      <td>5.073211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30857</th>\n",
       "      <td>B013B5M7RO</td>\n",
       "      <td>30857</td>\n",
       "      <td>5.057899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5838</th>\n",
       "      <td>B01H3EBD1A</td>\n",
       "      <td>5838</td>\n",
       "      <td>5.054757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16481</th>\n",
       "      <td>B00NMGUNQK</td>\n",
       "      <td>16481</td>\n",
       "      <td>5.040190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26070</th>\n",
       "      <td>B0041OOACA</td>\n",
       "      <td>26070</td>\n",
       "      <td>5.033893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17338</th>\n",
       "      <td>B00AN53HR0</td>\n",
       "      <td>17338</td>\n",
       "      <td>5.030418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8625</th>\n",
       "      <td>B00E0HEJ8I</td>\n",
       "      <td>8625</td>\n",
       "      <td>5.029718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22087</th>\n",
       "      <td>B016I0R8PA</td>\n",
       "      <td>22087</td>\n",
       "      <td>5.027577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31564</th>\n",
       "      <td>B007EZ10EY</td>\n",
       "      <td>31564</td>\n",
       "      <td>5.013719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18864</th>\n",
       "      <td>B000UG8FW4</td>\n",
       "      <td>18864</td>\n",
       "      <td>4.986999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17324</th>\n",
       "      <td>B00153YEXU</td>\n",
       "      <td>17324</td>\n",
       "      <td>4.983575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28239</th>\n",
       "      <td>B00074L2U6</td>\n",
       "      <td>28239</td>\n",
       "      <td>4.978774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26697</th>\n",
       "      <td>B00I4OK0L8</td>\n",
       "      <td>26697</td>\n",
       "      <td>4.976752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1526</th>\n",
       "      <td>B00827RP4M</td>\n",
       "      <td>1526</td>\n",
       "      <td>4.974675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5845</th>\n",
       "      <td>B0013KGEJW</td>\n",
       "      <td>5845</td>\n",
       "      <td>4.970388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23379</th>\n",
       "      <td>B00DBUVKP0</td>\n",
       "      <td>23379</td>\n",
       "      <td>4.967902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25350</th>\n",
       "      <td>B00HU0C13M</td>\n",
       "      <td>25350</td>\n",
       "      <td>4.963832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16886</th>\n",
       "      <td>B019FFWPQW</td>\n",
       "      <td>16886</td>\n",
       "      <td>4.962798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19287</th>\n",
       "      <td>B00ZERKK22</td>\n",
       "      <td>19287</td>\n",
       "      <td>4.960501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24752</th>\n",
       "      <td>B006ITF2H8</td>\n",
       "      <td>24752</td>\n",
       "      <td>4.957936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5925</th>\n",
       "      <td>B00QJYITMW</td>\n",
       "      <td>5925</td>\n",
       "      <td>4.957781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25898</th>\n",
       "      <td>B00ND1ZB3Y</td>\n",
       "      <td>25898</td>\n",
       "      <td>4.957680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20128</th>\n",
       "      <td>B00CPZEN0G</td>\n",
       "      <td>20128</td>\n",
       "      <td>4.956359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25119</th>\n",
       "      <td>B00S4QN0HW</td>\n",
       "      <td>25119</td>\n",
       "      <td>3.152146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6128</th>\n",
       "      <td>B010A9HRP6</td>\n",
       "      <td>6128</td>\n",
       "      <td>3.150239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20686</th>\n",
       "      <td>B010FKE99M</td>\n",
       "      <td>20686</td>\n",
       "      <td>3.149568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25066</th>\n",
       "      <td>B00DRFX2IM</td>\n",
       "      <td>25066</td>\n",
       "      <td>3.137573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28404</th>\n",
       "      <td>B00HWGZ3R0</td>\n",
       "      <td>28404</td>\n",
       "      <td>3.127322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25384</th>\n",
       "      <td>B00F57H8SU</td>\n",
       "      <td>25384</td>\n",
       "      <td>3.124327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8010</th>\n",
       "      <td>B00E5M2OOE</td>\n",
       "      <td>8010</td>\n",
       "      <td>3.123990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13959</th>\n",
       "      <td>B01G3BB8WS</td>\n",
       "      <td>13959</td>\n",
       "      <td>3.123853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2847</th>\n",
       "      <td>B00M4EDXDG</td>\n",
       "      <td>2847</td>\n",
       "      <td>3.122527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>B0000891IO</td>\n",
       "      <td>1999</td>\n",
       "      <td>3.113370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18420</th>\n",
       "      <td>B01CS4NAJI</td>\n",
       "      <td>18420</td>\n",
       "      <td>3.111000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29014</th>\n",
       "      <td>B00OGMWJFM</td>\n",
       "      <td>29014</td>\n",
       "      <td>3.109918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20524</th>\n",
       "      <td>B00Y1QZ93C</td>\n",
       "      <td>20524</td>\n",
       "      <td>3.106476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24225</th>\n",
       "      <td>B005G4VS8S</td>\n",
       "      <td>24225</td>\n",
       "      <td>3.106375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24994</th>\n",
       "      <td>B01H3UOYNI</td>\n",
       "      <td>24994</td>\n",
       "      <td>3.105303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20123</th>\n",
       "      <td>B01GZBB06U</td>\n",
       "      <td>20123</td>\n",
       "      <td>3.098059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>B000MXIN22</td>\n",
       "      <td>688</td>\n",
       "      <td>3.088613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3813</th>\n",
       "      <td>B004V7D3MA</td>\n",
       "      <td>3813</td>\n",
       "      <td>3.060431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25507</th>\n",
       "      <td>B008HE1P28</td>\n",
       "      <td>25507</td>\n",
       "      <td>3.047514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16781</th>\n",
       "      <td>B01C8R18SA</td>\n",
       "      <td>16781</td>\n",
       "      <td>3.040940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20031</th>\n",
       "      <td>B01APL6NBS</td>\n",
       "      <td>20031</td>\n",
       "      <td>3.032615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25930</th>\n",
       "      <td>B00B4BDJZM</td>\n",
       "      <td>25930</td>\n",
       "      <td>3.028218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11195</th>\n",
       "      <td>B00JXMD4Z4</td>\n",
       "      <td>11195</td>\n",
       "      <td>3.026448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17046</th>\n",
       "      <td>B000VHTCEC</td>\n",
       "      <td>17046</td>\n",
       "      <td>3.014136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10900</th>\n",
       "      <td>B00FRIJA10</td>\n",
       "      <td>10900</td>\n",
       "      <td>3.010784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8514</th>\n",
       "      <td>B01FN6F582</td>\n",
       "      <td>8514</td>\n",
       "      <td>3.007667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17866</th>\n",
       "      <td>B0041OEW96</td>\n",
       "      <td>17866</td>\n",
       "      <td>3.002697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10332</th>\n",
       "      <td>B00FGL79BQ</td>\n",
       "      <td>10332</td>\n",
       "      <td>2.949126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17893</th>\n",
       "      <td>B00FQKIQ9Q</td>\n",
       "      <td>17893</td>\n",
       "      <td>2.947777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26943</th>\n",
       "      <td>B008Y952JI</td>\n",
       "      <td>26943</td>\n",
       "      <td>2.930870</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32346 rows Ã 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       product_id   item  u6_predictions\n",
       "24818  B014X3ETEC  24818        5.257283\n",
       "27449  B0111Z1JOS  27449        5.173516\n",
       "14021  B00B53DIJQ  14021        5.125332\n",
       "9411   B00LI721V0   9411        5.109960\n",
       "14390  B0088WY684  14390        5.090626\n",
       "10231  B0163DPZDO  10231        5.080999\n",
       "8406   B0114979CW   8406        5.077700\n",
       "8594   B002APVEF8   8594        5.073211\n",
       "30857  B013B5M7RO  30857        5.057899\n",
       "5838   B01H3EBD1A   5838        5.054757\n",
       "16481  B00NMGUNQK  16481        5.040190\n",
       "26070  B0041OOACA  26070        5.033893\n",
       "17338  B00AN53HR0  17338        5.030418\n",
       "8625   B00E0HEJ8I   8625        5.029718\n",
       "22087  B016I0R8PA  22087        5.027577\n",
       "31564  B007EZ10EY  31564        5.013719\n",
       "18864  B000UG8FW4  18864        4.986999\n",
       "17324  B00153YEXU  17324        4.983575\n",
       "28239  B00074L2U6  28239        4.978774\n",
       "26697  B00I4OK0L8  26697        4.976752\n",
       "1526   B00827RP4M   1526        4.974675\n",
       "5845   B0013KGEJW   5845        4.970388\n",
       "23379  B00DBUVKP0  23379        4.967902\n",
       "25350  B00HU0C13M  25350        4.963832\n",
       "16886  B019FFWPQW  16886        4.962798\n",
       "19287  B00ZERKK22  19287        4.960501\n",
       "24752  B006ITF2H8  24752        4.957936\n",
       "5925   B00QJYITMW   5925        4.957781\n",
       "25898  B00ND1ZB3Y  25898        4.957680\n",
       "20128  B00CPZEN0G  20128        4.956359\n",
       "...           ...    ...             ...\n",
       "25119  B00S4QN0HW  25119        3.152146\n",
       "6128   B010A9HRP6   6128        3.150239\n",
       "20686  B010FKE99M  20686        3.149568\n",
       "25066  B00DRFX2IM  25066        3.137573\n",
       "28404  B00HWGZ3R0  28404        3.127322\n",
       "25384  B00F57H8SU  25384        3.124327\n",
       "8010   B00E5M2OOE   8010        3.123990\n",
       "13959  B01G3BB8WS  13959        3.123853\n",
       "2847   B00M4EDXDG   2847        3.122527\n",
       "1999   B0000891IO   1999        3.113370\n",
       "18420  B01CS4NAJI  18420        3.111000\n",
       "29014  B00OGMWJFM  29014        3.109918\n",
       "20524  B00Y1QZ93C  20524        3.106476\n",
       "24225  B005G4VS8S  24225        3.106375\n",
       "24994  B01H3UOYNI  24994        3.105303\n",
       "20123  B01GZBB06U  20123        3.098059\n",
       "688    B000MXIN22    688        3.088613\n",
       "3813   B004V7D3MA   3813        3.060431\n",
       "25507  B008HE1P28  25507        3.047514\n",
       "16781  B01C8R18SA  16781        3.040940\n",
       "20031  B01APL6NBS  20031        3.032615\n",
       "25930  B00B4BDJZM  25930        3.028218\n",
       "11195  B00JXMD4Z4  11195        3.026448\n",
       "17046  B000VHTCEC  17046        3.014136\n",
       "10900  B00FRIJA10  10900        3.010784\n",
       "8514   B01FN6F582   8514        3.007667\n",
       "17866  B0041OEW96  17866        3.002697\n",
       "10332  B00FGL79BQ  10332        2.949126\n",
       "17893  B00FQKIQ9Q  17893        2.947777\n",
       "26943  B008Y952JI  26943        2.930870\n",
       "\n",
       "[32346 rows x 3 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 38.3 ms\n"
     ]
    }
   ],
   "source": [
    "product_index['u6_predictions'] = trained_net(nd.array([6] * product_index.shape[0]).as_in_context(ctx), \n",
    "                                              nd.array(product_index['item'].values).as_in_context(ctx)).asnumpy()\n",
    "product_index.sort_values('u6_predictions', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's compare this to the predictions for another user (we'll try user #7)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>item</th>\n",
       "      <th>u6_predictions</th>\n",
       "      <th>u7_predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24024</th>\n",
       "      <td>B019Q8BL5Y</td>\n",
       "      <td>24024</td>\n",
       "      <td>4.680803</td>\n",
       "      <td>4.845093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18864</th>\n",
       "      <td>B000UG8FW4</td>\n",
       "      <td>18864</td>\n",
       "      <td>4.986999</td>\n",
       "      <td>4.838005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19266</th>\n",
       "      <td>B001B4AMRK</td>\n",
       "      <td>19266</td>\n",
       "      <td>4.734147</td>\n",
       "      <td>4.796792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10231</th>\n",
       "      <td>B0163DPZDO</td>\n",
       "      <td>10231</td>\n",
       "      <td>5.080999</td>\n",
       "      <td>4.762260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28280</th>\n",
       "      <td>B018UNZNZK</td>\n",
       "      <td>28280</td>\n",
       "      <td>4.861670</td>\n",
       "      <td>4.745142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21789</th>\n",
       "      <td>B00DHJRM3O</td>\n",
       "      <td>21789</td>\n",
       "      <td>4.656195</td>\n",
       "      <td>4.742263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14021</th>\n",
       "      <td>B00B53DIJQ</td>\n",
       "      <td>14021</td>\n",
       "      <td>5.125332</td>\n",
       "      <td>4.714750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11524</th>\n",
       "      <td>B008WTJENK</td>\n",
       "      <td>11524</td>\n",
       "      <td>4.504077</td>\n",
       "      <td>4.710421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26808</th>\n",
       "      <td>B00AZO0736</td>\n",
       "      <td>26808</td>\n",
       "      <td>4.810485</td>\n",
       "      <td>4.691214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7639</th>\n",
       "      <td>B00936TMCE</td>\n",
       "      <td>7639</td>\n",
       "      <td>4.622311</td>\n",
       "      <td>4.680311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9595</th>\n",
       "      <td>B005OUID0K</td>\n",
       "      <td>9595</td>\n",
       "      <td>4.895197</td>\n",
       "      <td>4.672156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1077</th>\n",
       "      <td>B00BBT71SI</td>\n",
       "      <td>1077</td>\n",
       "      <td>4.471921</td>\n",
       "      <td>4.669843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29097</th>\n",
       "      <td>B00VZW8DA6</td>\n",
       "      <td>29097</td>\n",
       "      <td>4.612114</td>\n",
       "      <td>4.661638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6335</th>\n",
       "      <td>B00MQ2R4DQ</td>\n",
       "      <td>6335</td>\n",
       "      <td>4.820184</td>\n",
       "      <td>4.657168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>B0147L2K50</td>\n",
       "      <td>740</td>\n",
       "      <td>4.271299</td>\n",
       "      <td>4.655389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26697</th>\n",
       "      <td>B00I4OK0L8</td>\n",
       "      <td>26697</td>\n",
       "      <td>4.976752</td>\n",
       "      <td>4.654827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24122</th>\n",
       "      <td>B005B881O8</td>\n",
       "      <td>24122</td>\n",
       "      <td>4.858676</td>\n",
       "      <td>4.652934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26887</th>\n",
       "      <td>B0183M07RW</td>\n",
       "      <td>26887</td>\n",
       "      <td>4.941840</td>\n",
       "      <td>4.647112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4291</th>\n",
       "      <td>B00K6006ZI</td>\n",
       "      <td>4291</td>\n",
       "      <td>4.345375</td>\n",
       "      <td>4.645448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5925</th>\n",
       "      <td>B00QJYITMW</td>\n",
       "      <td>5925</td>\n",
       "      <td>4.957781</td>\n",
       "      <td>4.638146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7557</th>\n",
       "      <td>B00B5J8F1G</td>\n",
       "      <td>7557</td>\n",
       "      <td>4.603307</td>\n",
       "      <td>4.633881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24597</th>\n",
       "      <td>B0026FBJXE</td>\n",
       "      <td>24597</td>\n",
       "      <td>4.449508</td>\n",
       "      <td>4.627631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21412</th>\n",
       "      <td>B0152BIGCK</td>\n",
       "      <td>21412</td>\n",
       "      <td>4.842495</td>\n",
       "      <td>4.626785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15010</th>\n",
       "      <td>B00HWHOFRI</td>\n",
       "      <td>15010</td>\n",
       "      <td>4.520926</td>\n",
       "      <td>4.626625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11559</th>\n",
       "      <td>B01BNSKPR0</td>\n",
       "      <td>11559</td>\n",
       "      <td>4.452205</td>\n",
       "      <td>4.619711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11310</th>\n",
       "      <td>B00KSQFGWS</td>\n",
       "      <td>11310</td>\n",
       "      <td>4.550601</td>\n",
       "      <td>4.614829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13171</th>\n",
       "      <td>B0015Z1MOW</td>\n",
       "      <td>13171</td>\n",
       "      <td>4.622183</td>\n",
       "      <td>4.614646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11803</th>\n",
       "      <td>B00K5B7GZQ</td>\n",
       "      <td>11803</td>\n",
       "      <td>4.580354</td>\n",
       "      <td>4.612657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25342</th>\n",
       "      <td>B000XEXAE6</td>\n",
       "      <td>25342</td>\n",
       "      <td>4.952476</td>\n",
       "      <td>4.612506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28048</th>\n",
       "      <td>B006NZFR4K</td>\n",
       "      <td>28048</td>\n",
       "      <td>4.708956</td>\n",
       "      <td>4.612505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25355</th>\n",
       "      <td>B017TT6SDW</td>\n",
       "      <td>25355</td>\n",
       "      <td>3.712958</td>\n",
       "      <td>2.996164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15334</th>\n",
       "      <td>B00WDZ8JZ8</td>\n",
       "      <td>15334</td>\n",
       "      <td>3.278684</td>\n",
       "      <td>2.995600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18957</th>\n",
       "      <td>B013WZPBXU</td>\n",
       "      <td>18957</td>\n",
       "      <td>3.297523</td>\n",
       "      <td>2.989026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4514</th>\n",
       "      <td>B001F29GXE</td>\n",
       "      <td>4514</td>\n",
       "      <td>3.520235</td>\n",
       "      <td>2.984276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27972</th>\n",
       "      <td>B00I97KDEE</td>\n",
       "      <td>27972</td>\n",
       "      <td>3.271641</td>\n",
       "      <td>2.983833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18733</th>\n",
       "      <td>B01D24ALBI</td>\n",
       "      <td>18733</td>\n",
       "      <td>3.353997</td>\n",
       "      <td>2.981320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4589</th>\n",
       "      <td>B01EBE0QIG</td>\n",
       "      <td>4589</td>\n",
       "      <td>3.404353</td>\n",
       "      <td>2.976348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29014</th>\n",
       "      <td>B00OGMWJFM</td>\n",
       "      <td>29014</td>\n",
       "      <td>3.109918</td>\n",
       "      <td>2.975790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12043</th>\n",
       "      <td>B00QB63RHK</td>\n",
       "      <td>12043</td>\n",
       "      <td>3.574258</td>\n",
       "      <td>2.975568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23906</th>\n",
       "      <td>B00YDLZ5MA</td>\n",
       "      <td>23906</td>\n",
       "      <td>3.317282</td>\n",
       "      <td>2.966346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10025</th>\n",
       "      <td>B00LVT2LDS</td>\n",
       "      <td>10025</td>\n",
       "      <td>3.422592</td>\n",
       "      <td>2.962677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24091</th>\n",
       "      <td>B0052XWG8Y</td>\n",
       "      <td>24091</td>\n",
       "      <td>3.319395</td>\n",
       "      <td>2.961239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>B007HJFHM8</td>\n",
       "      <td>466</td>\n",
       "      <td>3.236348</td>\n",
       "      <td>2.957183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15102</th>\n",
       "      <td>B00BJTJGC4</td>\n",
       "      <td>15102</td>\n",
       "      <td>3.928450</td>\n",
       "      <td>2.955830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20524</th>\n",
       "      <td>B00Y1QZ93C</td>\n",
       "      <td>20524</td>\n",
       "      <td>3.106476</td>\n",
       "      <td>2.952532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13442</th>\n",
       "      <td>B0058FNIOW</td>\n",
       "      <td>13442</td>\n",
       "      <td>3.476428</td>\n",
       "      <td>2.950747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2735</th>\n",
       "      <td>B00AFYHB8A</td>\n",
       "      <td>2735</td>\n",
       "      <td>3.241971</td>\n",
       "      <td>2.948194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6877</th>\n",
       "      <td>B00CSI6USI</td>\n",
       "      <td>6877</td>\n",
       "      <td>3.276346</td>\n",
       "      <td>2.942959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16615</th>\n",
       "      <td>B00AG0OY7E</td>\n",
       "      <td>16615</td>\n",
       "      <td>3.574961</td>\n",
       "      <td>2.942008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4869</th>\n",
       "      <td>B005GQ2SD0</td>\n",
       "      <td>4869</td>\n",
       "      <td>3.328050</td>\n",
       "      <td>2.940300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21508</th>\n",
       "      <td>B008X6IJ74</td>\n",
       "      <td>21508</td>\n",
       "      <td>3.307512</td>\n",
       "      <td>2.932969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20123</th>\n",
       "      <td>B01GZBB06U</td>\n",
       "      <td>20123</td>\n",
       "      <td>3.098059</td>\n",
       "      <td>2.932372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25066</th>\n",
       "      <td>B00DRFX2IM</td>\n",
       "      <td>25066</td>\n",
       "      <td>3.137573</td>\n",
       "      <td>2.928521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30302</th>\n",
       "      <td>B00CEP1ICS</td>\n",
       "      <td>30302</td>\n",
       "      <td>3.177089</td>\n",
       "      <td>2.919455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10332</th>\n",
       "      <td>B00FGL79BQ</td>\n",
       "      <td>10332</td>\n",
       "      <td>2.949126</td>\n",
       "      <td>2.910437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8425</th>\n",
       "      <td>B000JQGCT8</td>\n",
       "      <td>8425</td>\n",
       "      <td>3.179994</td>\n",
       "      <td>2.897626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11351</th>\n",
       "      <td>B00B1AB1L0</td>\n",
       "      <td>11351</td>\n",
       "      <td>3.247646</td>\n",
       "      <td>2.870759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30531</th>\n",
       "      <td>B009WQJVGM</td>\n",
       "      <td>30531</td>\n",
       "      <td>3.250753</td>\n",
       "      <td>2.858850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2056</th>\n",
       "      <td>B0058V7M3Y</td>\n",
       "      <td>2056</td>\n",
       "      <td>3.810857</td>\n",
       "      <td>2.853629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30150</th>\n",
       "      <td>B004KZP6B4</td>\n",
       "      <td>30150</td>\n",
       "      <td>3.237572</td>\n",
       "      <td>2.762039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32346 rows Ã 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       product_id   item  u6_predictions  u7_predictions\n",
       "24024  B019Q8BL5Y  24024        4.680803        4.845093\n",
       "18864  B000UG8FW4  18864        4.986999        4.838005\n",
       "19266  B001B4AMRK  19266        4.734147        4.796792\n",
       "10231  B0163DPZDO  10231        5.080999        4.762260\n",
       "28280  B018UNZNZK  28280        4.861670        4.745142\n",
       "21789  B00DHJRM3O  21789        4.656195        4.742263\n",
       "14021  B00B53DIJQ  14021        5.125332        4.714750\n",
       "11524  B008WTJENK  11524        4.504077        4.710421\n",
       "26808  B00AZO0736  26808        4.810485        4.691214\n",
       "7639   B00936TMCE   7639        4.622311        4.680311\n",
       "9595   B005OUID0K   9595        4.895197        4.672156\n",
       "1077   B00BBT71SI   1077        4.471921        4.669843\n",
       "29097  B00VZW8DA6  29097        4.612114        4.661638\n",
       "6335   B00MQ2R4DQ   6335        4.820184        4.657168\n",
       "740    B0147L2K50    740        4.271299        4.655389\n",
       "26697  B00I4OK0L8  26697        4.976752        4.654827\n",
       "24122  B005B881O8  24122        4.858676        4.652934\n",
       "26887  B0183M07RW  26887        4.941840        4.647112\n",
       "4291   B00K6006ZI   4291        4.345375        4.645448\n",
       "5925   B00QJYITMW   5925        4.957781        4.638146\n",
       "7557   B00B5J8F1G   7557        4.603307        4.633881\n",
       "24597  B0026FBJXE  24597        4.449508        4.627631\n",
       "21412  B0152BIGCK  21412        4.842495        4.626785\n",
       "15010  B00HWHOFRI  15010        4.520926        4.626625\n",
       "11559  B01BNSKPR0  11559        4.452205        4.619711\n",
       "11310  B00KSQFGWS  11310        4.550601        4.614829\n",
       "13171  B0015Z1MOW  13171        4.622183        4.614646\n",
       "11803  B00K5B7GZQ  11803        4.580354        4.612657\n",
       "25342  B000XEXAE6  25342        4.952476        4.612506\n",
       "28048  B006NZFR4K  28048        4.708956        4.612505\n",
       "...           ...    ...             ...             ...\n",
       "25355  B017TT6SDW  25355        3.712958        2.996164\n",
       "15334  B00WDZ8JZ8  15334        3.278684        2.995600\n",
       "18957  B013WZPBXU  18957        3.297523        2.989026\n",
       "4514   B001F29GXE   4514        3.520235        2.984276\n",
       "27972  B00I97KDEE  27972        3.271641        2.983833\n",
       "18733  B01D24ALBI  18733        3.353997        2.981320\n",
       "4589   B01EBE0QIG   4589        3.404353        2.976348\n",
       "29014  B00OGMWJFM  29014        3.109918        2.975790\n",
       "12043  B00QB63RHK  12043        3.574258        2.975568\n",
       "23906  B00YDLZ5MA  23906        3.317282        2.966346\n",
       "10025  B00LVT2LDS  10025        3.422592        2.962677\n",
       "24091  B0052XWG8Y  24091        3.319395        2.961239\n",
       "466    B007HJFHM8    466        3.236348        2.957183\n",
       "15102  B00BJTJGC4  15102        3.928450        2.955830\n",
       "20524  B00Y1QZ93C  20524        3.106476        2.952532\n",
       "13442  B0058FNIOW  13442        3.476428        2.950747\n",
       "2735   B00AFYHB8A   2735        3.241971        2.948194\n",
       "6877   B00CSI6USI   6877        3.276346        2.942959\n",
       "16615  B00AG0OY7E  16615        3.574961        2.942008\n",
       "4869   B005GQ2SD0   4869        3.328050        2.940300\n",
       "21508  B008X6IJ74  21508        3.307512        2.932969\n",
       "20123  B01GZBB06U  20123        3.098059        2.932372\n",
       "25066  B00DRFX2IM  25066        3.137573        2.928521\n",
       "30302  B00CEP1ICS  30302        3.177089        2.919455\n",
       "10332  B00FGL79BQ  10332        2.949126        2.910437\n",
       "8425   B000JQGCT8   8425        3.179994        2.897626\n",
       "11351  B00B1AB1L0  11351        3.247646        2.870759\n",
       "30531  B009WQJVGM  30531        3.250753        2.858850\n",
       "2056   B0058V7M3Y   2056        3.810857        2.853629\n",
       "30150  B004KZP6B4  30150        3.237572        2.762039\n",
       "\n",
       "[32346 rows x 4 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 32.5 ms\n"
     ]
    }
   ],
   "source": [
    "product_index['u7_predictions'] = trained_net(nd.array([7] * product_index.shape[0]).as_in_context(ctx), \n",
    "                                              nd.array(product_index['item'].values).as_in_context(ctx)).asnumpy()\n",
    "product_index.sort_values('u7_predictions', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predicted ratings are different between the two users, but the same top (and bottom) items for user #6 appear for #7 as well.  Let's look at the correlation across the full set of 38K items to see if this relationship holds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 580 ms\n"
     ]
    }
   ],
   "source": [
    "product_index[['u6_predictions', 'u7_predictions']].plot.scatter('u6_predictions', 'u7_predictions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that this correlation is nearly perfect.  Essentially the average rating of items dominates across users and we'll recommend the same well-reviewed items to everyone.  As it turns out, we can add more embeddings and this relationship will go away since we're better able to capture differential preferences across users.\n",
    "\n",
    "However, with just a 64 dimensional embedding, it took 7 minutes to run just 3 epochs.  If we ran this outside of our Notebook Instance we could run larger jobs and move on to other work would improve productivity.\n",
    "\n",
    "---\n",
    "\n",
    "## Train with SageMaker\n",
    "\n",
    "Now that we've trained on this smaller dataset, we can expand training in SageMaker's distributed, managed training environment.\n",
    "\n",
    "### Wrap Code\n",
    "\n",
    "To use SageMaker's pre-built MXNet container, we'll need to wrap our code from above into a Python script.  There's a great deal of flexibility in using SageMaker's pre-built containers, and detailed documentation can be found [here](https://github.com/aws/sagemaker-python-sdk#mxnet-sagemaker-estimators), but for our example, it consisted of:\n",
    "1. Wrapping all data preparation into a `prepare_train_data` function (we could name this whatever we like)\n",
    "1. Copying and pasting classes and functions from above word-for-word\n",
    "1. Defining a `train` function that:\n",
    "  1. Adds a bit of new code to pick up the input TSV dataset on the SageMaker Training cluster\n",
    "  1. Takes in a dict of hyperparameters (which we specified as globals above)\n",
    "  1. Creates the net and executes training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 631 Âµs\n"
     ]
    }
   ],
   "source": [
    "# !cat recommender.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Locally\n",
    "\n",
    "Now we can test our train function locally.  This helps ensure we don't have any bugs before submitting our code to SageMaker's pre-built MXNet container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/dse260-CapStone-Amazon/JH/JH-gluon_recommender_system\n",
      "time: 238 ms\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 4.1M\n",
      "drwxrwxr-x  2 ec2-user ec2-user 4.0K May 16 01:49 .\n",
      "drwxrwxrwx 52 root     root     148K May 16 01:52 ..\n",
      "-rw-rw-r--  1 ec2-user ec2-user 3.9M May 16 01:49 remove_long_tail_customer_product_start_with_voted_review.csv\n",
      "time: 239 ms\n"
     ]
    }
   ],
   "source": [
    "!ls -ahl /tmp/recsys/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 4.1M\n",
      "drwxrwxr-x  2 ec2-user ec2-user 4.0K May 16 01:49 .\n",
      "drwxrwxrwx 52 root     root     148K May 16 01:52 ..\n",
      "-rw-rw-r--  1 ec2-user ec2-user 3.9M May 16 01:49 remove_long_tail_customer_product_start_with_voted_review.csv\n",
      "time: 237 ms\n"
     ]
    }
   ],
   "source": [
    "!ls -ahl /tmp/recsys/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access /tmp/recsys/asin_overall_reviewerID_with_voted_review.csv: No such file or directory\n",
      "time: 238 ms\n"
     ]
    }
   ],
   "source": [
    "!ls -al /tmp/recsys/asin_overall_reviewerID_with_voted_review.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JH - training_dir:  /tmp/recsys/\n",
      "JH - df:        customer_id  product_id  star_rating\n",
      "0   AZ9VR9ESKVJEV  B001AXVE7O          5.0\n",
      "1  A22J6E4W5280PN  B001AXVE7O          5.0\n",
      "2  A2F3AONT5ZFWUQ  B001AXVE7O          5.0\n",
      "3  A35S4JL923WBHM  B001AXVE7O          5.0\n",
      "4  A3A4UKJUP34E18  B001AXVE7O          4.0\n",
      "epoch: 0\n",
      "EPOCH 0: MSE ON TRAINING and TEST: 2.8416786504828413. 2.8437224160070005\n",
      "end of training\n",
      "CPU times: user 909 ms, sys: 633 ms, total: 1.54 s\n",
      "Wall time: 1.79 s\n",
      "time: 1.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# !cp remove_long_tail_customer_product_start_with_voted_review.csv /tmp/recsys/\n",
    "# !cp remove_long_tail_customer_product_start_with_voted_review.tsv.gz /tmp/recsys/\n",
    "# !cp remove_long_tail_customer_product_start_with_voted_review.pickle /tmp/recsys/\n",
    "\n",
    "# need to update recommender.py code for my case\n",
    "# del recommender\n",
    "import recommender\n",
    "\n",
    "local_test_net, local_customer_index, local_product_index = recommender.train(\n",
    "    {'train': '/tmp/recsys/'}, \n",
    "    {'num_embeddings': 64, \n",
    "     'opt': 'sgd', \n",
    "     'lr': 0.02, \n",
    "     'momentum': 0.9, \n",
    "     'wd': 0.,\n",
    "     'epochs': 1},\n",
    "    ['local'],\n",
    "    1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Move Data to S3\n",
    "\n",
    "Holding our data in memory works fine when we're interactively exploring a sample of data, but for larger, longer running processes, we'd prefer to run them in the background with SageMaker Training.  To do this, let's move the dataset to S3 so that it can be picked up by SageMaker training.  This is perfect for use cases like periodic re-training, expanding to a larger dataset, or moving production workloads to larger hardware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change log level\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.addHandler(logging.StreamHandler()) # Writes to console\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logging.getLogger('boto3').setLevel(logging.CRITICAL)\n",
    "logging.getLogger('botocore').setLevel(logging.CRITICAL)\n",
    "logging.getLogger('s3transfer').setLevel(logging.CRITICAL)\n",
    "logging.getLogger('urllib3').setLevel(logging.CRITICAL)\n",
    "\n",
    "import boto3 \n",
    "import os \n",
    "# from dotenv import load_dotenv\n",
    "\n",
    "# load_dotenv() # this loads the .env file with our credentials\n",
    "\n",
    "file_name = 'remove_long_tail_customer_product_start_with_voted_review.csv' # name of the file to upload\n",
    "file_name_1 = 'remove_long_tail_customer_product_start_with_voted_review.pickle' # name of the file to upload\n",
    "file_name_2 = 'remove_long_tail_customer_product_start_with_voted_review.tsv.gz' # name of the file to upload\n",
    "file_name_3 = 'asin_overall_reviewerID_with_voted_review_2.csv' # name of the file to upload\n",
    "\n",
    "bucket_name = 'dse-cohort5-group1' # name of the bucket\n",
    "\n",
    "AWS_ACCESS_KEY_ID='AKIAZAERIKDLAVRFZK35'\n",
    "AWS_SECRET_ACCESS_KEY='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'\n",
    "\n",
    "s3_client = boto3.client(\n",
    "    's3', region_name='us-west-1',\n",
    "    aws_access_key_id=os.getenv(AWS_ACCESS_KEY_ID),\n",
    "    aws_secret_access_key=os.getenv(AWS_SECRET_ACCESS_KEY)\n",
    ")\n",
    "\n",
    "# s3://dse-cohort5-group1/data-lake-landing-zone/reviews/Clothing_Shoes_and_Jewelry.json.gz\n",
    "key_file='data-lake-landing-zone/reviews/'+file_name\n",
    "response = s3_client.upload_file(file_name, bucket_name, key_file)\n",
    "print(response)\n",
    "\n",
    "key_file='data-lake-landing-zone/reviews/'+file_name_1\n",
    "response = s3_client.upload_file(file_name_1, bucket_name, key_file)\n",
    "print(response)\n",
    "\n",
    "key_file='data-lake-landing-zone/reviews/'+file_name_2\n",
    "response = s3_client.upload_file(file_name_2, bucket_name, key_file)\n",
    "print(response)\n",
    "\n",
    "key_file='data-lake-landing-zone/reviews/'+file_name_3\n",
    "response = s3_client.upload_file(file_name_3, bucket_name, key_file)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit\n",
    "\n",
    "Now, we can create an MXNet estimator from the SageMaker Python SDK.  To do so, we need to pass in:\n",
    "1. Instance type and count for our SageMaker Training cluster.  SageMaker's MXNet containers support distributed GPU training, so we could easily set this to multiple ml.p2 or ml.p3 instances if we wanted.\n",
    "  - *Note, this would require some changes to our recommender.py script as we would need to setup the context an key value store properly, as well as determining if and how to distribute the training data.*\n",
    "1. An S3 path for out model artifacts and a role with access to S3 input and output paths.\n",
    "1. Hyperparameters for our neural network.  Since with a 64 dimensional embedding, our recommendations reverted too closely to the mean, let's increase this by an order of magnitude when we train outside of our local instance.  We'll also increase the epochs to see how our accuracy evolves over time. We'll leave all other hyperparameters the same.\n",
    "\n",
    "Once we use `.fit()` this creates a SageMaker Training Job that spins up instances, loads the appropriate packages and data, runs our `train` function from `recommender.py`, wraps up and saves model artifacts to S3, and finishes by tearing down the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('s3://{}/{}/train/'.format(bucket, prefix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m = MXNet('recommender.py', \n",
    "#           py_version='py3',\n",
    "#           role=role, \n",
    "#           train_instance_count=1, \n",
    "#           train_instance_type=\"ml.p2.xlarge\",\n",
    "#           output_path='s3://{}/{}/output'.format(bucket, prefix),\n",
    "#           hyperparameters={'num_embeddings': 512, \n",
    "#                            'opt': opt, \n",
    "#                            'lr': lr, \n",
    "#                            'momentum': momentum, \n",
    "#                            'wd': wd,\n",
    "#                            'epochs': 10},\n",
    "#          framework_version='1.1')\n",
    "\n",
    "\n",
    "m = MXNet('recommender.py', \n",
    "          py_version='py3',\n",
    "          role=role, \n",
    "          train_instance_count=1, \n",
    "          train_instance_type=\"ml.p3.2xlarge\",\n",
    "          output_path='s3://dse-cohort5-group1/samgemaker-0515-test/output',\n",
    "          hyperparameters={'num_embeddings': 512, \n",
    "                           'opt': opt, \n",
    "                           'lr': lr, \n",
    "                           'momentum': momentum, \n",
    "                           'wd': wd,\n",
    "                           'epochs': 4},\n",
    "         framework_version='1.2.1')\n",
    "\n",
    "\n",
    "\n",
    "# m.fit({'train': 's3://{}/{}/train/'.format(bucket, prefix)})\n",
    "m.fit({'train': 's3://dse-cohort5-group1/data-lake-landing-zone/reviews/asin_overall_reviewerID_with_voted_review_2.csv'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Host\n",
    "\n",
    "Now that we've trained our model, deploying it to a real-time, production endpoint is easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = m.deploy(initial_instance_count=1, \n",
    "                     instance_type='ml.m4.xlarge')\n",
    "predictor.serializer = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have an endpoint, let's test it out.  We'll predict user #6's ratings for the top and bottom ASINs from our local model.\n",
    "\n",
    "*This could be done by sending HTTP POST requests from a separate web service, but to keep things easy, we'll just use the `.predict()` method from the SageMaker Python SDK.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.predict(json.dumps({'customer_id': customer_index[customer_index['user'] == 6]['customer_id'].values.tolist(), \n",
    "                              'product_id': ['B00KH1O9HW', 'B00M5KODWO']}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note, some of our predictions are actually greater than 5, which is to be expected as we didn't do anything special to account for ratings being capped at that value.  Since we are only looking to ranking by predicted rating, this won't create problems for our specific use case.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate\n",
    "\n",
    "Let's start by calculating a naive baseline to approximate how well our model is doing.  The simplest estimate would be to assume every user item rating is just the average rating over all ratings.\n",
    "\n",
    "*Note, we could do better by using each individual video's average, however, in this case it doesn't really matter as the same conclusions would hold.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Naive MSE:', np.mean((test_df['star_rating'] - np.mean(train_df['star_rating'])) ** 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll calculate predictions for our test dataset.\n",
    "\n",
    "*Note, this will align closely to our CloudWatch output above, but may differ slightly due to skipping partial mini-batches in our eval_net function.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = []\n",
    "for array in np.array_split(test_df[['customer_id', 'product_id']].values, 40):\n",
    "    test_preds += predictor.predict(json.dumps({'customer_id': array[:, 0].tolist(), \n",
    "                                                'product_id': array[:, 1].tolist()}))\n",
    "\n",
    "test_preds = np.array(test_preds)\n",
    "print('MSE:', np.mean((test_df['star_rating'] - test_preds) ** 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that our neural network and embedding model produces substantially better results (~1.27 vs 1.65 on mean square error).\n",
    "\n",
    "For recommender systems, subjective accuracy also matters.  Let's get some recommendations for a random user to see if they make intuitive sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_df[reduced_df['user'] == 6].sort_values(['star_rating', 'item'], ascending=[False, True])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, user #6 seems to like sprawling dramamtic television series and sci-fi, but they dislike silly comedies.\n",
    "\n",
    "Now we'll loop through and predict user #6's ratings for every common video in the catalog, to see which ones we'd recommend and which ones we wouldn't."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for array in np.array_split(product_index['product_id'].values, 40):\n",
    "    predictions += predictor.predict(json.dumps({'customer_id': customer_index[customer_index['user'] == 6]['customer_id'].values.tolist() * array.shape[0], \n",
    "                                                 'product_id': array.tolist()}))\n",
    "\n",
    "predictions = pd.DataFrame({'product_id': product_index['product_id'],\n",
    "                            'prediction': predictions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = reduced_df.groupby('product_id')['product_title'].last().reset_index()\n",
    "predictions_titles = predictions.merge(titles)\n",
    "predictions_titles.sort_values(['prediction', 'product_id'], ascending=[False, True])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, our predicted highly rated shows have some well-reviewed TV dramas and some sci-fi.  Meanwhile, our bottom rated shows include goofball comedies.\n",
    "\n",
    "*Note, because of random initialization in the weights, results on subsequent runs may differ slightly.*\n",
    "\n",
    "Let's confirm that we no longer have almost perfect correlation in recommendations with user #7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_user7 = []\n",
    "for array in np.array_split(product_index['product_id'].values, 40):\n",
    "    predictions_user7 += predictor.predict(json.dumps({'customer_id': customer_index[customer_index['user'] == 7]['customer_id'].values.tolist() * array.shape[0], \n",
    "                                                       'product_id': array.tolist()}))\n",
    "plt.scatter(predictions['prediction'], np.array(predictions_user7))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Wrap-up\n",
    "\n",
    "In this example, we developed a deep learning model to predict customer ratings.  This could serve as the foundation of a recommender system in a variety of use cases.  However, there are many ways in which it could be improved.  For example we did very little with:\n",
    "- hyperparameter tuning\n",
    "- controlling for overfitting (early stopping, dropout, etc.)\n",
    "- testing whether binarizing our target variable would improve results\n",
    "- including other information sources (video genres, historical ratings, time of review)\n",
    "- adjusting our threshold for user and item inclusion \n",
    "\n",
    "In addition to improving the model, we could improve the engineering by:\n",
    "- Setting the context and key value store up for distributed training\n",
    "- Fine tuning our data ingestion (e.g. num_workers on our data iterators) to ensure we're fully utilizing our GPU\n",
    "- Thinking about how pre-processing would need to change as datasets scale beyond a single machine\n",
    "\n",
    "Beyond that, recommenders are a very active area of research and techniques from active learning, reinforcement learning, segmentation, ensembling, and more should be investigated to deliver well-rounded recommendations.\n",
    "\n",
    "### Clean-up (optional)\n",
    "\n",
    "Let's finish by deleting our endpoint to avoid stray hosting charges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker.Session().delete_endpoint(predictor.endpoint)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "notice": "Copyright 2017 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
