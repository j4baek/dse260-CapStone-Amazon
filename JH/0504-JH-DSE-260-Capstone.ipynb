{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference\n",
    "- https://towardsdatascience.com/building-a-collaborative-filtering-recommender-system-with-clickstream-data-dffc86c8c65\n",
    "- https://pypi.org/project/python-amazon-simple-product-api/\n",
    "- https://github.com/benfred/implicit\n",
    "- https://medium.com/@patelneha1495/recommendation-system-in-python-using-als-algorithm-and-apache-spark-27aca08eaab3\n",
    "- https://towardsdatascience.com/prototyping-a-recommender-system-step-by-step-part-2-alternating-least-square-als-matrix-4a76c58714a1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data format\n",
    "- Format is one-review-per-line in json. See examples below for further help reading the data.\n",
    "\n",
    "    - reviewerID - ID of the reviewer, e.g. A2SUAM1J3GNN3B\n",
    "    - asin - ID of the product, e.g. 0000013714\n",
    "    - reviewerName - name of the reviewer\n",
    "    - vote - helpful votes of the review\n",
    "    - style - a disctionary of the product metadata, e.g., \"Format\" is \"Hardcover\"\n",
    "    - reviewText - text of the review\n",
    "    - overall - rating of the product\n",
    "    - summary - summary of the review\n",
    "    - unixReviewTime - time of the review (unix time)\n",
    "    - reviewTime - time of the review (raw)\n",
    "    - image - images that users post after they have received the produc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### To measure all running time\n",
    "# https://github.com/cpcloud/ipython-autotime\n",
    "\n",
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Garbage collector: collected 60 objects.\n",
      "time: 14.6 ms\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "collected = gc.collect()\n",
    "print (\"Garbage collector: collected %d objects.\" % collected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 517 ms\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import scipy.sparse as sparse\n",
    "import numpy as np\n",
    "import random\n",
    "import implicit\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 184 ms\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import tqdm\n",
    "import codecs\n",
    "\n",
    "# spark imports\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import UserDefinedFunction, explode, desc\n",
    "from pyspark.sql.types import StringType, ArrayType\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# data science imports\n",
    "import math\n",
    "\n",
    "# visualization imports\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import json\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 484 Âµs\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_cores = 8\n",
    "memory_gb = 32\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"amazon recommendation\") \\\n",
    "    .config(\"spark.driver.memory\", '{}g'.format(memory_gb)) \\\n",
    "    .config(\"spark.master\", 'local[{}]'.format(number_cores)) \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# get spark context\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Download dataset from: http://deepyeti.ucsd.edu/jianmo/amazon/categoryFiles/Clothing_Shoes_and_Jewelry.json.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../../Data_fulldata/Review/ClothingShoesAndJewelry/'\n",
    "REVIEW_DATA = 'Clothing_Shoes_and_Jewelry.json.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ../../Data_fulldata/Review/ClothingShoesAndJewelry/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Please unzip Clothing_Shoes_and_Jewelry.json.gz to Clothing_Shoes_and_Jewelry.json\n",
    "2. Load Clothing_Shoes_and_Jewelry.json (14.1 GB (14,144,939,923 bytes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = spark.read.load(DATA_PATH+REVIEW_DATA, format='json', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Shape of Data\", (ratings.count(), len(ratings.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract ['asin', 'overall', 'reviewerID'] from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_ratings = ratings.drop(\n",
    " 'image',\n",
    " 'reviewText',\n",
    " 'reviewTime',\n",
    " 'reviewerName',\n",
    " 'style',\n",
    " 'summary',\n",
    " 'unixReviewTime',\n",
    " 'verified',\n",
    " 'vote')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_ratings.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(product_ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert pyspark.sql.dataframe.DataFrame to Pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rating_df = product_ratings.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- make csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_ratings.write.csv(\"./data/asin_overall_reviewerID.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -al ./data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 18.8 s\n"
     ]
    }
   ],
   "source": [
    "rating_df = pd.read_csv('./data/asin_overall_reviewerID.csv/part-00000-6ef94642-3c25-4f7d-ade9-981f91953b81-c000.csv',\n",
    "                        names=['asin', 'overall', 'reviewerID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewerID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0871167042</td>\n",
       "      <td>5.0</td>\n",
       "      <td>A2IC3NZN488KWK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0871167042</td>\n",
       "      <td>4.0</td>\n",
       "      <td>A3OT9BYASFGU2X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0871167042</td>\n",
       "      <td>5.0</td>\n",
       "      <td>A28GK1G2KDXHRP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0871167042</td>\n",
       "      <td>5.0</td>\n",
       "      <td>A3NFXFEKW8OK0E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0871167042</td>\n",
       "      <td>5.0</td>\n",
       "      <td>A3I6G5TKBVJEK9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0871167042</td>\n",
       "      <td>5.0</td>\n",
       "      <td>A1A7Y1M8AJWNZ8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0871167042</td>\n",
       "      <td>5.0</td>\n",
       "      <td>A30FG02C424EJ5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0871167042</td>\n",
       "      <td>5.0</td>\n",
       "      <td>ADQQYU1UCDEWB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0871167042</td>\n",
       "      <td>5.0</td>\n",
       "      <td>A39YL2NXZORK56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0871167042</td>\n",
       "      <td>5.0</td>\n",
       "      <td>A2PRY50ZESF1MH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin  overall      reviewerID\n",
       "0  0871167042      5.0  A2IC3NZN488KWK\n",
       "1  0871167042      4.0  A3OT9BYASFGU2X\n",
       "2  0871167042      5.0  A28GK1G2KDXHRP\n",
       "3  0871167042      5.0  A3NFXFEKW8OK0E\n",
       "4  0871167042      5.0  A3I6G5TKBVJEK9\n",
       "5  0871167042      5.0  A1A7Y1M8AJWNZ8\n",
       "6  0871167042      5.0  A30FG02C424EJ5\n",
       "7  0871167042      5.0   ADQQYU1UCDEWB\n",
       "8  0871167042      5.0  A39YL2NXZORK56\n",
       "9  0871167042      5.0  A2PRY50ZESF1MH"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 8.34 ms\n"
     ]
    }
   ],
   "source": [
    "rating_df.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0    19525093\n",
       "4.0     5707951\n",
       "3.0     2982765\n",
       "1.0     2271737\n",
       "2.0     1804553\n",
       "Name: overall, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 241 ms\n"
     ]
    }
   ],
   "source": [
    "rating_df['overall'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 352 Âµs\n"
     ]
    }
   ],
   "source": [
    "# rating_df.groupby(['reviewerID', 'asin']).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Drop duplicated records.\n",
    "- Group overall together with reviwerID and asin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A0000040I1OM9N4SGBD8</td>\n",
       "      <td>B00NX2IHS4</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A0000040I1OM9N4SGBD8</td>\n",
       "      <td>B01136O82A</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A0000040I1OM9N4SGBD8</td>\n",
       "      <td>B0183QBP4M</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A0000378ZNUHTQUDNNHR</td>\n",
       "      <td>B017M5JE16</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A0000448ZD4QU0AQCOH8</td>\n",
       "      <td>B00A21CKO6</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A00008882A0PUVHCTDUP</td>\n",
       "      <td>B00AMIQ64E</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A0000932YCOC06EWVVQY</td>\n",
       "      <td>B00LGY1904</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A0000966VPR3PHG0J8GV</td>\n",
       "      <td>B00H974IAA</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A0001080NID4WWYB32VT</td>\n",
       "      <td>B00AFD6N3K</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A0001170GCHUTHLVFXBQ</td>\n",
       "      <td>B006OR711Y</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             reviewerID        asin  overall\n",
       "0  A0000040I1OM9N4SGBD8  B00NX2IHS4      2.0\n",
       "1  A0000040I1OM9N4SGBD8  B01136O82A      5.0\n",
       "2  A0000040I1OM9N4SGBD8  B0183QBP4M      5.0\n",
       "3  A0000378ZNUHTQUDNNHR  B017M5JE16      5.0\n",
       "4  A0000448ZD4QU0AQCOH8  B00A21CKO6      5.0\n",
       "5  A00008882A0PUVHCTDUP  B00AMIQ64E      5.0\n",
       "6  A0000932YCOC06EWVVQY  B00LGY1904      5.0\n",
       "7  A0000966VPR3PHG0J8GV  B00H974IAA      3.0\n",
       "8  A0001080NID4WWYB32VT  B00AFD6N3K      5.0\n",
       "9  A0001170GCHUTHLVFXBQ  B006OR711Y      4.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1min 17s\n"
     ]
    }
   ],
   "source": [
    "rating_df = rating_df.drop_duplicates()\n",
    "grouped_df = rating_df.groupby(['reviewerID', 'asin']).sum().reset_index()\n",
    "grouped_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reviewerID     object\n",
       "asin           object\n",
       "overall       float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.03 ms\n"
     ]
    }
   ],
   "source": [
    "grouped_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU training requires factor size to be a multiple of 32. Increasing factors from 20 to 32.\n",
      "WARNING:root:OpenBLAS detected. Its highly recommend to set the environment variable 'export OPENBLAS_NUM_THREADS=1' to disable its internal multithreading\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9d571e433144810bbde71228ccb42a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "time: 1min 19s\n"
     ]
    }
   ],
   "source": [
    "grouped_df['reviewerID_encode'] = grouped_df['reviewerID'].astype(\"category\")\n",
    "grouped_df['asin_encode'] = grouped_df['asin'].astype(\"category\")\n",
    "grouped_df['reviewerID_encode'] = grouped_df['reviewerID_encode'].cat.codes\n",
    "grouped_df['asin_encode'] = grouped_df['asin_encode'].cat.codes\n",
    "grouped_df = grouped_df[['reviewerID','reviewerID_encode', 'asin', 'asin_encode', 'overall']]\n",
    "\n",
    "sparse_content_person = sparse.csr_matrix(\n",
    "    (grouped_df['overall'].astype(float), \n",
    "    (grouped_df['asin_encode'], grouped_df['reviewerID_encode']))\n",
    ")\n",
    "\n",
    "sparse_person_content = sparse.csr_matrix(\n",
    "    (grouped_df['overall'].astype(float), \n",
    "    (grouped_df['reviewerID_encode'], grouped_df['asin_encode']))\n",
    ")\n",
    "\n",
    "model = implicit.als.AlternatingLeastSquares(\n",
    "    factors=20, \n",
    "    regularization=0.1, \n",
    "    iterations=50, \n",
    "    use_gpu=True)\n",
    "\n",
    "alpha = 15\n",
    "data = (sparse_content_person * alpha).astype('double')\n",
    "\n",
    "model.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewerID_encode</th>\n",
       "      <th>asin</th>\n",
       "      <th>asin_encode</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A0000040I1OM9N4SGBD8</td>\n",
       "      <td>0</td>\n",
       "      <td>B00NX2IHS4</td>\n",
       "      <td>1564263</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A0000040I1OM9N4SGBD8</td>\n",
       "      <td>0</td>\n",
       "      <td>B01136O82A</td>\n",
       "      <td>2020823</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A0000040I1OM9N4SGBD8</td>\n",
       "      <td>0</td>\n",
       "      <td>B0183QBP4M</td>\n",
       "      <td>2279962</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A0000378ZNUHTQUDNNHR</td>\n",
       "      <td>1</td>\n",
       "      <td>B017M5JE16</td>\n",
       "      <td>2255212</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A0000448ZD4QU0AQCOH8</td>\n",
       "      <td>2</td>\n",
       "      <td>B00A21CKO6</td>\n",
       "      <td>674036</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31663531</th>\n",
       "      <td>AZZZZJYGA32</td>\n",
       "      <td>12483675</td>\n",
       "      <td>B00FDK84X2</td>\n",
       "      <td>1032039</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31663532</th>\n",
       "      <td>AZZZZS162JNL0</td>\n",
       "      <td>12483676</td>\n",
       "      <td>B001HTQA0W</td>\n",
       "      <td>120539</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31663533</th>\n",
       "      <td>AZZZZS162JNL0</td>\n",
       "      <td>12483676</td>\n",
       "      <td>B00IVVJ1AA</td>\n",
       "      <td>1254215</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31663534</th>\n",
       "      <td>AZZZZS162JNL0</td>\n",
       "      <td>12483676</td>\n",
       "      <td>B01636KA86</td>\n",
       "      <td>2187337</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31663535</th>\n",
       "      <td>AZZZZS5Z6MEWC</td>\n",
       "      <td>12483677</td>\n",
       "      <td>B00O4CMLB6</td>\n",
       "      <td>1574663</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31663536 rows Ã 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    reviewerID  reviewerID_encode        asin  asin_encode  \\\n",
       "0         A0000040I1OM9N4SGBD8                  0  B00NX2IHS4      1564263   \n",
       "1         A0000040I1OM9N4SGBD8                  0  B01136O82A      2020823   \n",
       "2         A0000040I1OM9N4SGBD8                  0  B0183QBP4M      2279962   \n",
       "3         A0000378ZNUHTQUDNNHR                  1  B017M5JE16      2255212   \n",
       "4         A0000448ZD4QU0AQCOH8                  2  B00A21CKO6       674036   \n",
       "...                        ...                ...         ...          ...   \n",
       "31663531           AZZZZJYGA32           12483675  B00FDK84X2      1032039   \n",
       "31663532         AZZZZS162JNL0           12483676  B001HTQA0W       120539   \n",
       "31663533         AZZZZS162JNL0           12483676  B00IVVJ1AA      1254215   \n",
       "31663534         AZZZZS162JNL0           12483676  B01636KA86      2187337   \n",
       "31663535         AZZZZS5Z6MEWC           12483677  B00O4CMLB6      1574663   \n",
       "\n",
       "          overall  \n",
       "0             2.0  \n",
       "1             5.0  \n",
       "2             5.0  \n",
       "3             5.0  \n",
       "4             5.0  \n",
       "...           ...  \n",
       "31663531      5.0  \n",
       "31663532      5.0  \n",
       "31663533      5.0  \n",
       "31663534      5.0  \n",
       "31663535      3.0  \n",
       "\n",
       "[31663536 rows x 5 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 8.87 ms\n"
     ]
    }
   ],
   "source": [
    "grouped_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Labling encoding asin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommend ASIN(Products) based on product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Covnert asin: B00NX2IHS4 to encoded asin: 1564263\n",
      "time: 3.04 s\n"
     ]
    }
   ],
   "source": [
    "asin='B00NX2IHS4'\n",
    "\n",
    "asin_encode = grouped_df.loc[grouped_df['asin'] == asin].iloc[0].asin_encode\n",
    "print(\"Covnert asin: %s to encoded asin: %d\" %(asin, asin_encode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded ASIN: 1564263 | Simility Score: 1.00000 | https://www.amazon.com/dp/B00NX2IHS4\n",
      "Encoded ASIN: 1531965 | Simility Score: 0.98331 | https://www.amazon.com/dp/B00NF12DU6\n",
      "Encoded ASIN: 924900 | Simility Score: 0.98327 | https://www.amazon.com/dp/B00DQI1SK4\n",
      "Encoded ASIN: 1832164 | Simility Score: 0.95290 | https://www.amazon.com/dp/B00UXZMQX6\n",
      "Encoded ASIN: 2531622 | Simility Score: 0.95123 | https://www.amazon.com/dp/B01DYN67DI\n",
      "Encoded ASIN: 1070131 | Simility Score: 0.95093 | https://www.amazon.com/dp/B00G0IVJAG\n",
      "Encoded ASIN: 2074993 | Simility Score: 0.94650 | https://www.amazon.com/dp/B013DP3H0S\n",
      "Encoded ASIN: 2192881 | Simility Score: 0.94549 | https://www.amazon.com/dp/B016886BI2\n",
      "Encoded ASIN: 991875 | Simility Score: 0.94481 | https://www.amazon.com/dp/B00EOSGPNK\n",
      "Encoded ASIN: 1635252 | Simility Score: 0.94459 | https://www.amazon.com/dp/B00PFZ05XW\n",
      "Encoded ASIN: 2563515 | Simility Score: 0.94192 | https://www.amazon.com/dp/B01EOLPJXS\n",
      "Encoded ASIN: 1321296 | Simility Score: 0.94190 | https://www.amazon.com/dp/B00JXP182C\n",
      "Encoded ASIN: 2307332 | Simility Score: 0.94057 | https://www.amazon.com/dp/B018SOFWRU\n",
      "Encoded ASIN: 2539750 | Simility Score: 0.94042 | https://www.amazon.com/dp/B01E5EYOVW\n",
      "Encoded ASIN: 1588750 | Simility Score: 0.93965 | https://www.amazon.com/dp/B00OELVGLS\n",
      "Encoded ASIN: 2537764 | Simility Score: 0.93920 | https://www.amazon.com/dp/B01E447IUC\n",
      "Encoded ASIN: 2189068 | Simility Score: 0.93912 | https://www.amazon.com/dp/B016405MNY\n",
      "Encoded ASIN: 2460154 | Simility Score: 0.93882 | https://www.amazon.com/dp/B01CH3K6TC\n",
      "Encoded ASIN: 1772225 | Simility Score: 0.93872 | https://www.amazon.com/dp/B00TBTFTCU\n",
      "Encoded ASIN: 1314353 | Simility Score: 0.93803 | https://www.amazon.com/dp/B00JTX3K06\n",
      "time: 476 ms\n"
     ]
    }
   ],
   "source": [
    "n_similar = 20\n",
    "\n",
    "person_vecs = model.user_factors\n",
    "content_vecs = model.item_factors\n",
    "\n",
    "content_norms = np.sqrt((content_vecs * content_vecs).sum(axis=1))\n",
    "\n",
    "scores = content_vecs.dot(content_vecs[asin_encode]) / content_norms\n",
    "top_idx = np.argpartition(scores, -n_similar)[-n_similar:]\n",
    "similar = sorted(zip(top_idx, scores[top_idx] / content_norms[asin_encode]), key=lambda x: -x[1])\n",
    "\n",
    "for content in similar:\n",
    "    idx, score = content\n",
    "    print(\"Encoded ASIN: %d\" %(idx), \n",
    "          \"| Simility Score: %.5f\" %(round(score, 5)), \n",
    "          \"| https://www.amazon.com/dp/\"+grouped_df.asin.loc[grouped_df.asin_encode == idx].iloc[0])\n",
    "#     print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 201 Âµs\n"
     ]
    }
   ],
   "source": [
    "# grouped_df.loc[grouped_df['person_id'] == 50].sort_values(by=['eventStrength'], ascending=False)[['title', 'person_id', 'eventStrength']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'B00NX2IHS4'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 22.7 ms\n"
     ]
    }
   ],
   "source": [
    "grouped_df.asin.loc[grouped_df.asin_encode == 1564263].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3674/31663536 [28:07<4977:30:49,  1.77it/s]"
     ]
    }
   ],
   "source": [
    "n_similar = 20\n",
    "output_filename='product_based_recommend.tsv'\n",
    "\n",
    "person_vecs = model.user_factors\n",
    "content_vecs = model.item_factors\n",
    "\n",
    "asin_encode_list = grouped_df['asin_encode'].tolist()\n",
    "\n",
    "with tqdm.tqdm(total=len(asin_encode_list)) as progress:\n",
    "    with codecs.open(output_filename, \"w\", \"utf8\") as o:\n",
    "        for asin_encode in asin_encode_list:\n",
    "        #     print(asin_encode)\n",
    "            content_norms = np.sqrt((content_vecs * content_vecs).sum(axis=1))\n",
    "\n",
    "            scores = content_vecs.dot(content_vecs[asin_encode]) / content_norms\n",
    "            top_idx = np.argpartition(scores, -n_similar)[-n_similar:]\n",
    "            similar = sorted(zip(top_idx, scores[top_idx] / content_norms[asin_encode]), key=lambda x: -x[1])\n",
    "\n",
    "            input_asin =\"\"\n",
    "            for content in similar:\n",
    "                idx, score = content\n",
    "                asin = grouped_df.asin.loc[grouped_df.asin_encode == idx].iloc[0]\n",
    "                \n",
    "                if round(score, 5)==1.00000:\n",
    "#                     print(round(score))\n",
    "                    input_asin = grouped_df.asin.loc[grouped_df.asin_encode == idx].iloc[0]\n",
    "                o.write(\"%s\\t%s\\t%.5f\\t%s\\n\" % (input_asin, asin, round(score, 5), \"https://www.amazon.com/dp/\"+asin))\n",
    "#                 print(input_asin)\n",
    "\n",
    "#                 print(\"Encoded ASIN: %d\" %(idx), \n",
    "#                       \"| Simility Score: %.5f\" %(round(score, 5)), \n",
    "#                       \"| https://www.amazon.com/dp/\"+grouped_df.asin.loc[grouped_df.asin_encode == idx].iloc[0])\n",
    "#             print(\"\\n\")\n",
    "            progress.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommend ASIN(Products) to Persons\n",
    "- The following function will return the top 10 recommendations chosen based on the person / content vectors for contents never interacted with for any given person."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.43 ms\n"
     ]
    }
   ],
   "source": [
    "def recommend(person_id, sparse_person_content, person_vecs, content_vecs, num_contents=10):\n",
    "    # Get the interactions scores from the sparse person content matrix\n",
    "    person_interactions = sparse_person_content[asin_encode,:].toarray()\n",
    "    # Add 1 to everything, so that articles with no interaction yet become equal to 1\n",
    "    person_interactions = person_interactions.reshape(-1) + 1\n",
    "    # Make articles already interacted zero\n",
    "    person_interactions[person_interactions > 1] = 0\n",
    "    # Get dot product of person vector and all content vectors\n",
    "    rec_vector = person_vecs[asin_encode,:].dot(content_vecs.T).toarray()\n",
    "    \n",
    "    # Scale this recommendation vector between 0 and 1\n",
    "    min_max = MinMaxScaler()\n",
    "    rec_vector_scaled = min_max.fit_transform(rec_vector.reshape(-1,1))[:,0]\n",
    "    # Content already interacted have their recommendation multiplied by zero\n",
    "    recommend_vector = person_interactions * rec_vector_scaled\n",
    "    # Sort the indices of the content into order of best recommendations\n",
    "    content_idx = np.argsort(recommend_vector)[::-1][:num_contents]\n",
    "    \n",
    "    # Start empty list to store titles and scores\n",
    "    asin_list = []\n",
    "    scores = []\n",
    "\n",
    "    for idx in content_idx:\n",
    "        # Append titles and scores to the list\n",
    "        asin_list.append(\"https://www.amazon.com/dp/\"+grouped_df.asin.loc[grouped_df.asin_encode == idx].iloc[0])\n",
    "        scores.append(recommend_vector[idx])\n",
    "\n",
    "    recommendations = pd.DataFrame({'ASIN': asin_list, 'SCORE': scores})\n",
    "\n",
    "    return recommendations\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Covnert reviewerID: A0000040I1OM9N4SGBD8 to encoded reviewerID: 1564263\n",
      "time: 2.43 s\n"
     ]
    }
   ],
   "source": [
    "# Create recommendations for person\n",
    "reviewerID=\"A0000040I1OM9N4SGBD8\"\n",
    "reviewerID_encode = grouped_df.loc[grouped_df['reviewerID'] == reviewerID].iloc[0].asin_encode\n",
    "print(\"Covnert reviewerID: %s to encoded reviewerID: %d\" %(reviewerID, reviewerID_encode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "** Recommended list for reviewer: A0000040I1OM9N4SGBD8\n",
      "\n",
      "                                   ASIN     SCORE\n",
      "0  https://www.amazon.com/dp/B004QL5K22  1.000000\n",
      "1  https://www.amazon.com/dp/B00JP6DIW2  0.911267\n",
      "2  https://www.amazon.com/dp/B000E48DCO  0.911195\n",
      "3  https://www.amazon.com/dp/B00152XP5E  0.887067\n",
      "4  https://www.amazon.com/dp/B000MQYJ3Q  0.883714\n",
      "5  https://www.amazon.com/dp/B005FI28S4  0.870804\n",
      "6  https://www.amazon.com/dp/B005934WR0  0.867594\n",
      "7  https://www.amazon.com/dp/B000J4B3TE  0.830848\n",
      "8  https://www.amazon.com/dp/B0002USCE4  0.815416\n",
      "9  https://www.amazon.com/dp/B0002USBB8  0.815330\n",
      "time: 14.6 s\n"
     ]
    }
   ],
   "source": [
    "# Get the trained person and content vectors. We convert them to csr matrices\n",
    "person_vecs = sparse.csr_matrix(model.user_factors)\n",
    "content_vecs = sparse.csr_matrix(model.item_factors)\n",
    "\n",
    "person_id = reviewerID_encode\n",
    "\n",
    "recommendations = recommend(person_id, sparse_person_content, person_vecs, content_vecs)\n",
    "\n",
    "print(\"\\n** Recommended list for reviewer:\", reviewerID)\n",
    "print()\n",
    "print(recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here we have top recommendations for reviewerID=\"A0000040I1OM9N4SGBD8\". \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B01136O82A</td>\n",
       "      <td>A0000040I1OM9N4SGBD8</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B0183QBP4M</td>\n",
       "      <td>A0000040I1OM9N4SGBD8</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B00NX2IHS4</td>\n",
       "      <td>A0000040I1OM9N4SGBD8</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin            reviewerID  overall\n",
       "1  B01136O82A  A0000040I1OM9N4SGBD8      5.0\n",
       "2  B0183QBP4M  A0000040I1OM9N4SGBD8      5.0\n",
       "0  B00NX2IHS4  A0000040I1OM9N4SGBD8      2.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.54 s\n"
     ]
    }
   ],
   "source": [
    "grouped_df.loc[grouped_df['reviewerID'] == 'A0000040I1OM9N4SGBD8'].sort_values(by=['overall'], ascending=False)[['asin', 'reviewerID', 'overall']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation the Recommender System \n",
    "- https://nbviewer.jupyter.org/github/jmsteinw/Notebooks/blob/master/RecEngine_NB.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def make_train(ratings, pct_test = 0.2):\n",
    "    test_set = ratings.copy() # Make a copy of the original set to be the test set. \n",
    "    test_set[test_set != 0] = 1 # Store the test set as a binary preference matrix\n",
    "    \n",
    "    training_set = ratings.copy() # Make a copy of the original data we can alter as our training set. \n",
    "    \n",
    "    nonzero_inds = training_set.nonzero() # Find the indices in the ratings data where an interaction exists\n",
    "    nonzero_pairs = list(zip(nonzero_inds[0], nonzero_inds[1])) # Zip these pairs together of item,user index into list\n",
    "\n",
    "    \n",
    "    random.seed(0) # Set the random seed to zero for reproducibility\n",
    "    \n",
    "    num_samples = int(np.ceil(pct_test*len(nonzero_pairs))) # Round the number of samples needed to the nearest integer\n",
    "    samples = random.sample(nonzero_pairs, num_samples) # Sample a random number of item-user pairs without replacement\n",
    "\n",
    "    content_inds = [index[0] for index in samples] # Get the item row indices\n",
    "\n",
    "    person_inds = [index[1] for index in samples] # Get the user column indices\n",
    "\n",
    "    \n",
    "    training_set[content_inds, person_inds] = 0 # Assign all of the randomly chosen user-item pairs to zero\n",
    "    training_set.eliminate_zeros() # Get rid of zeros in sparse array storage after update to save space\n",
    "    \n",
    "    return training_set, test_set, list(set(person_inds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_train, content_test, content_persons_altered = make_train(sparse_content_person, pct_test = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc_score(predictions, test):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(test, predictions)\n",
    "    return metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mean_auc(training_set, altered_persons, predictions, test_set):\n",
    "    store_auc = [] # An empty list to store the AUC for each user that had an item removed from the training set\n",
    "    popularity_auc = [] # To store popular AUC scores\n",
    "    pop_contents = np.array(test_set.sum(axis = 1)).reshape(-1) # Get sum of item iteractions to find most popular\n",
    "    content_vecs = predictions[1]\n",
    "    for person in altered_persons: # Iterate through each user that had an item altered\n",
    "        training_column = training_set[:,person].toarray().reshape(-1) # Get the training set column\n",
    "        zero_inds = np.where(training_column == 0) # Find where the interaction had not yet occurred\n",
    "        \n",
    "        # Get the predicted values based on our user/item vectors\n",
    "        person_vec = predictions[0][person,:]\n",
    "        pred = person_vec.dot(content_vecs).toarray()[0,zero_inds].reshape(-1)\n",
    "        \n",
    "        # Get only the items that were originally zero\n",
    "        # Select all ratings from the MF prediction for this user that originally had no iteraction\n",
    "        actual = test_set[:,person].toarray()[zero_inds,0].reshape(-1)\n",
    "        \n",
    "        # Select the binarized yes/no interaction pairs from the original full data\n",
    "        # that align with the same pairs in training \n",
    "        pop = pop_contents[zero_inds] # Get the item popularity for our chosen items\n",
    "        \n",
    "        store_auc.append(auc_score(pred, actual)) # Calculate AUC for the given user and store\n",
    "        \n",
    "        popularity_auc.append(auc_score(pop, actual)) # Calculate AUC using most popular and score\n",
    "    # End users iteration\n",
    "    \n",
    "    return float('%.3f'%np.mean(store_auc)), float('%.3f'%np.mean(popularity_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_mean_auc(content_train, content_persons_altered,\n",
    "              [person_vecs, content_vecs.T], content_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
