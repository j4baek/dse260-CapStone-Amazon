{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### To measure all running time\n",
    "# https://github.com/cpcloud/ipython-autotime\n",
    "\n",
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 298 ms\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "from collections import defaultdict\n",
    "import scipy\n",
    "import scipy.optimize\n",
    "import numpy\n",
    "import random\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import time\n",
    "import csv\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Download dataset from https://drive.google.com/drive/folders/1dnCnSqniJMDFGw8VIiKG5S-_hJmGBJqt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 189 µs\n"
     ]
    }
   ],
   "source": [
    "# colnames=['user_id', 'product_id', 'rating'] \n",
    "# rating_df = pd.read_csv(path, names=colnames, header=None,  compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 527 µs\n"
     ]
    }
   ],
   "source": [
    "def parse(path):\n",
    "    for line in gzip.open(path, 'r'):\n",
    "        yield json.loads(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For 5-core ( start ) review "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Dataset/reviews_Clothing_Shoes_and_Jewelry_5_2.json.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'user_id': 'AX1QE6IR7CHXM', 'product_id': '0000031887', 'rating': 5}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.36 s\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = './Dataset/'\n",
    "fn_5core = 'reviews_Clothing_Shoes_and_Jewelry_5_2.json.gz'\n",
    "path = DATA_DIR + fn_5core\n",
    "print(path)\n",
    "\n",
    "BATCH_SIZE = 100000\n",
    "\n",
    "i = 0\n",
    "\n",
    "dataset = []\n",
    "usersPerItem = defaultdict(set)\n",
    "itemsPerUser = defaultdict(set)\n",
    "reviewsPerUser = defaultdict(list)\n",
    "reviewsPerItem = defaultdict(list) \n",
    "\n",
    "for line in parse(path):\n",
    "    d = dict()\n",
    "    d['user_id'] = line['reviewerID']\n",
    "    d['product_id'] = line['asin']\n",
    "    d['rating'] = int(line['overall'])\n",
    "    dataset.append(d)\n",
    "    i += 1\n",
    "    if i > BATCH_SIZE:\n",
    "        break\n",
    "    \n",
    "for d in dataset:\n",
    "    user,item = d['user_id'], d['product_id']\n",
    "    reviewsPerUser[user].append(d)\n",
    "    reviewsPerItem[item].append(d)\n",
    "    usersPerItem[item].add(user)\n",
    "    itemsPerUser[user].add(item)\n",
    "\n",
    "dataset[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 7.55 ms\n"
     ]
    }
   ],
   "source": [
    "N = len(dataset)\n",
    "nUsers = len(reviewsPerUser)\n",
    "nItems = len(reviewsPerItem)\n",
    "\n",
    "#Getting a list of keys\n",
    "users = list(reviewsPerUser.keys())\n",
    "items = list(reviewsPerItem.keys())\n",
    "\n",
    "#This is equivalent to our Rating Mean from week 1\n",
    "alpha = sum([d['rating'] for d in dataset]) / len(dataset)\n",
    "\n",
    "#Create another two defaultdict's, this time being float types because they are prediction based\n",
    "userBiases = defaultdict(float)\n",
    "itemBiases = defaultdict(float)\n",
    "\n",
    "def MSE(predictions, labels):\n",
    "    differences = [(x-y)**2 for x,y in zip(predictions,labels)]\n",
    "    return sum(differences) / len(differences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 462 µs\n"
     ]
    }
   ],
   "source": [
    "def Jaccard(s1, s2):\n",
    "    numer = len(s1.intersection(s2))\n",
    "    denom = len(s1.union(s2))\n",
    "    return numer / denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.53 ms\n"
     ]
    }
   ],
   "source": [
    "def predictRating(user,item):\n",
    "    ratings = []\n",
    "    similarities = []\n",
    "    for d in reviewsPerUser[user]:\n",
    "        i2 = d['product_id']\n",
    "        if i2 == item: continue\n",
    "        ratings.append(d['rating'])\n",
    "        similarities.append(Jaccard(usersPerItem[item],usersPerItem[i2]))\n",
    "    if (sum(similarities) > 0):\n",
    "        weightedRatings = [(x*y) for x,y in zip(ratings,similarities)]\n",
    "        return sum(weightedRatings) / sum(similarities)\n",
    "    else:\n",
    "        # User hasn't rated any similar items\n",
    "        return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.33 ms\n"
     ]
    }
   ],
   "source": [
    "class Logger():\n",
    "    def __init__(self):\n",
    "        self.STATUS = 'OFF'\n",
    "        self.START_TIME = None\n",
    "        self.END_TIME = None\n",
    "        self.EXECUTION_TIME = None\n",
    "        self.LOGS = []\n",
    "        self.MODEL = None\n",
    "        self.SCORE = None\n",
    "        self.STAT = None\n",
    "        \n",
    "    def start(self, model=None, stat=None, score=None):\n",
    "        self.START_TIME = time.time()\n",
    "        self.STATUS = 'ON'\n",
    "        if model:\n",
    "            self.MODEL = model\n",
    "            self.LOGS.append(\"Model: {m}\".format(m=model))\n",
    "        if stat:\n",
    "            self.STAT = stat\n",
    "            self.LOGS.append(\"Statistic: {s}\".format(s=stat))\n",
    "        if score:\n",
    "            self.SCORE = score\n",
    "            self.LOGS.append(\"Score: {s}\".format(s=score))\n",
    "        \n",
    "    def end(self, display=True, score=None):\n",
    "        if self.STATUS == 'OFF':\n",
    "            print(\"No timer started.\")\n",
    "        else:\n",
    "            self.END_TIME = time.time()\n",
    "            self.EXECUTION_TIME = self.END_TIME - self.START_TIME\n",
    "            self.LOGS.append(\"Time: {t}\".format(t=self.EXECUTION_TIME))\n",
    "            if score:\n",
    "                self.SCORE = score\n",
    "                self.LOGS.append(\"Score: {s}\".format(s=score))\n",
    "            if display == True:\n",
    "                self.getStats(last=False)\n",
    "            else:\n",
    "                r = self.LOGS\n",
    "                self.tearDown()\n",
    "                return r\n",
    "            self.tearDown()\n",
    "    \n",
    "    def tearDown(self):\n",
    "        self.STATUS = 'OFF'\n",
    "        self.LOGS = []\n",
    "        \n",
    "    def getStats(self, show=True, last=True):\n",
    "        if show == True:   \n",
    "            if last == True:\n",
    "                print(\"STATUS: {v}\".format(v=self.STATUS))\n",
    "                print(\"START_TIME: {v}\".format(v=self.START_TIME))\n",
    "                print(\"END_TIME: {v}\".format(v=self.END_TIME))\n",
    "                print(\"EXECUTION_TIME: {v}\".format(v=self.EXECUTION_TIME))\n",
    "                print(\"MODEL: {v}\".format(v=self.MODEL))\n",
    "                print(\"STAT: {v}\".format(v=self.STAT))\n",
    "                print(\"SCORE: {v}\".format(v=self.SCORE))\n",
    "            else:\n",
    "                for l in self.LOGS:\n",
    "                    print(l)\n",
    "        else:\n",
    "            return self.MODEL, self.STAT, self.SCORE, self.EXECUTION_TIME\n",
    "\n",
    "        \n",
    "timer = Logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 6.42 ms\n"
     ]
    }
   ],
   "source": [
    "labels = [d['rating'] for d in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1630374059367858\n",
      "1.40054874327075\n",
      "1.1630374059367858 1.40054874327075\n",
      "\n",
      "Model: Baseline\n",
      "Statistic: MSE\n",
      "Score: 1.1630374059367858\n",
      "Time: 0.003266572952270508\n",
      "\n",
      "time: 1.56 s\n"
     ]
    }
   ],
   "source": [
    "# baseline\n",
    "alwaysPredictMean = [alpha for d in dataset]\n",
    "labels = [d['rating'] for d in dataset]\n",
    "MSE(alwaysPredictMean, labels)\n",
    "\n",
    "cfPredictions = [predictRating(d['user_id'], d['product_id']) for d in dataset] \n",
    "\n",
    "print(MSE(alwaysPredictMean, labels))\n",
    "print(MSE(cfPredictions, labels))\n",
    "print(MSE(alwaysPredictMean, labels), MSE(cfPredictions, labels)) \n",
    "print()\n",
    "timer.start(model='Baseline', stat='MSE', score=MSE(alwaysPredictMean, labels))\n",
    "alwaysPredictMean = [alpha for d in dataset]\n",
    "timer.end()\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heuristic \n",
    "\n",
    "- Heuristic analysis is an expert based analysis that determines the susceptibility of a system towards particular threat/risk using various decision rules or weighing methods. MultiCriteria analysis (MCA) is one of the means of weighing.\n",
    "\n",
    "- https://en.wikipedia.org/wiki/Heuristic_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mode: Weighted Ratings Heuristic\n",
      "Score by MSE:  1.40054874327075\n",
      "time: 1.47 s\n"
     ]
    }
   ],
   "source": [
    "score = MSE(cfPredictions, labels)\n",
    "cfPredictions = [predictRating(d['user_id'], d['product_id']) for d in dataset]\n",
    "\n",
    "print(\"Mode: Weighted Ratings Heuristic\")\n",
    "print(\"Score by MSE: \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 101\n",
      "ProductID: B00004SR8Z\n",
      "Number Matches: 10\n",
      "time: 4.72 ms\n"
     ]
    }
   ],
   "source": [
    "def mostSimilar(item, n):\n",
    "    similarities = []\n",
    "    users = usersPerItem[item]\n",
    "    for i2 in usersPerItem:\n",
    "        if i2 == item: continue\n",
    "        sim = Jaccard(users, usersPerItem[i2])\n",
    "        similarities.append([sim,i2])\n",
    "    similarities.sort(reverse=True)\n",
    "    return similarities[:n]\n",
    "\n",
    "def mostSimilarFast(item, n):\n",
    "    similarities = []\n",
    "    users = usersPerItem[item]\n",
    "    candidateItems = set()\n",
    "    for u in users:\n",
    "        candidateItems = candidateItems.union(itemsPerUser[u])\n",
    "    for i2 in candidateItems:\n",
    "        if i2 == item: continue\n",
    "        sim = Jaccard(users, usersPerItem[i2])\n",
    "        similarities.append([sim, i2])\n",
    "    similarities.sort(reverse=True)\n",
    "    return similarities[:n]\n",
    "\n",
    "# Test Params\n",
    "n = 10 \n",
    "idx = 101 \n",
    "query = dataset[idx]['product_id']\n",
    "\n",
    "print(\"Index: {i}\".format(i=idx))\n",
    "print(\"ProductID: {q}\".format(q=query))\n",
    "print(\"Number Matches: {i}\".format(i=n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Most Similar\n",
      "Statistic: Jaccard Similarity\n",
      "Time: 0.03053903579711914\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[0.0392156862745098, 'B001J4HQ76'],\n",
       " [0.038461538461538464, 'B000J46QHS'],\n",
       " [0.038461538461538464, 'B0001XLSWA'],\n",
       " [0.037037037037037035, 'B0036VNOG2'],\n",
       " [0.037037037037037035, 'B0029F1X3W'],\n",
       " [0.037037037037037035, 'B001T0IM5U'],\n",
       " [0.037037037037037035, 'B000OVJY7A'],\n",
       " [0.037037037037037035, 'B000FVY4JW'],\n",
       " [0.03571428571428571, 'B0038P22QE'],\n",
       " [0.03571428571428571, 'B001GXH2JM']]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 33.3 ms\n"
     ]
    }
   ],
   "source": [
    "timer.start(model='Most Similar', stat='Jaccard Similarity')\n",
    "sims1 = mostSimilar(query, n)\n",
    "timer.end(display=True)\n",
    "sims1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Most Similar Optimized\n",
      "Statistic: Jaccard Similarity\n",
      "Time: 0.00029969215393066406\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[0.0392156862745098, 'B001J4HQ76'],\n",
       " [0.038461538461538464, 'B000J46QHS'],\n",
       " [0.038461538461538464, 'B0001XLSWA'],\n",
       " [0.037037037037037035, 'B0036VNOG2'],\n",
       " [0.037037037037037035, 'B0029F1X3W'],\n",
       " [0.037037037037037035, 'B001T0IM5U'],\n",
       " [0.037037037037037035, 'B000OVJY7A'],\n",
       " [0.037037037037037035, 'B000FVY4JW'],\n",
       " [0.03571428571428571, 'B0038P22QE'],\n",
       " [0.03571428571428571, 'B001GXH2JM']]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.47 ms\n"
     ]
    }
   ],
   "source": [
    "timer.start(model='Most Similar Optimized', stat='Jaccard Similarity')\n",
    "sims2 = mostSimilarFast(query, n)\n",
    "timer.end(display=True)\n",
    "sims2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A1KLRMWW2FWPL4</td>\n",
       "      <td>0000031887</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A2G5TCU2WDFZ65</td>\n",
       "      <td>0000031887</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A1RLQXYNCMWRWN</td>\n",
       "      <td>0000031887</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A8U3FAMSJVHS5</td>\n",
       "      <td>0000031887</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A3GEOILWLK86XM</td>\n",
       "      <td>0000031887</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          user_id  product_id  rating\n",
       "0  A1KLRMWW2FWPL4  0000031887       5\n",
       "1  A2G5TCU2WDFZ65  0000031887       5\n",
       "2  A1RLQXYNCMWRWN  0000031887       5\n",
       "3   A8U3FAMSJVHS5  0000031887       5\n",
       "4  A3GEOILWLK86XM  0000031887       5"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 85.3 ms\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(dataset)\n",
    "X = df[['user_id', 'product_id']]\n",
    "y = df[['rating']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaberative filtering \n",
    "\n",
    "* Product Similarity recommedation\n",
    "* User Similarity recomendation\n",
    "\n",
    "This model uses historical user/item ratings that are similar to predict ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Documention for Surprise\n",
    "- http://surpriselib.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 201 µs\n"
     ]
    }
   ],
   "source": [
    "# !pip install surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 253 ms\n"
     ]
    }
   ],
   "source": [
    "from surprise import KNNWithMeans\n",
    "from surprise import Dataset\n",
    "from surprise import accuracy\n",
    "from surprise import Reader\n",
    "import os\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "#Reading the dataset\n",
    "reader = Reader(rating_scale=(0, 5))\n",
    "data = Dataset.load_from_df(df,reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 151 ms\n"
     ]
    }
   ],
   "source": [
    "#Splitting the dataset\n",
    "trainset, testset = train_test_split(data, \n",
    "                                     test_size=0.3,\n",
    "                                     random_state=11, \n",
    "                                     shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use user_based true/false to switch between user-based or item-based collaborative filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Model: Product KNN\n",
      "Statistic: MSE\n",
      "Time: 1.8810961246490479\n",
      "Score:  1.2468510963333113\n",
      "time: 1.88 s\n"
     ]
    }
   ],
   "source": [
    "timer.start(model='Product KNN', stat='MSE')\n",
    "algo = KNNWithMeans(k=5, sim_options={'name': 'cosine', 'user_based': False})\n",
    "algo.fit(trainset)\n",
    "test_pred = algo.test(testset)\n",
    "acc = accuracy.mse(test_pred, verbose=False)\n",
    "timer.end()\n",
    "print(\"Score: \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Model: User KNN\n",
      "Statistic: MSE\n",
      "Time: 31.48060369491577\n",
      "Score:  1.4815124763082748\n",
      "time: 31.5 s\n"
     ]
    }
   ],
   "source": [
    "timer.start(model='User KNN', stat='MSE')\n",
    "algo = KNNWithMeans(k=5, sim_options={'name': 'cosine', 'user_based': True})\n",
    "algo.fit(trainset)\n",
    "test_pred = algo.test(testset)\n",
    "acc = accuracy.mse(test_pred, verbose=False)\n",
    "timer.end()\n",
    "print(\"Score: \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
