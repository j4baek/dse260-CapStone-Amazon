{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://medium.com/@patelneha1495/recommendation-system-in-python-using-als-algorithm-and-apache-spark-27aca08eaab3\n",
    "- https://towardsdatascience.com/prototyping-a-recommender-system-step-by-step-part-2-alternating-least-square-als-matrix-4a76c58714a1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data format\n",
    "- Format is one-review-per-line in json. See examples below for further help reading the data.\n",
    "\n",
    "    - reviewerID - ID of the reviewer, e.g. A2SUAM1J3GNN3B\n",
    "    - asin - ID of the product, e.g. 0000013714\n",
    "    - reviewerName - name of the reviewer\n",
    "    - vote - helpful votes of the review\n",
    "    - style - a disctionary of the product metadata, e.g., \"Format\" is \"Hardcover\"\n",
    "    - reviewText - text of the review\n",
    "    - overall - rating of the product\n",
    "    - summary - summary of the review\n",
    "    - unixReviewTime - time of the review (unix time)\n",
    "    - reviewTime - time of the review (raw)\n",
    "    - image - images that users post after they have received the produc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### To measure all running time\n",
    "# https://github.com/cpcloud/ipython-autotime\n",
    "\n",
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 958 ms\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "# spark imports\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import UserDefinedFunction, explode, desc\n",
    "from pyspark.sql.types import StringType, ArrayType\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "# from pyspark.ml.recommendation import ALS\n",
    "from pyspark.mllib.recommendation import ALS\n",
    "\n",
    "# data science imports\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# visualization imports\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import json\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.98 s\n"
     ]
    }
   ],
   "source": [
    "# spark config\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"movie recommendation\") \\\n",
    "    .config(\"spark.driver.maxResultSize\", \"96g\") \\\n",
    "    .config(\"spark.driver.memory\", \"96g\") \\\n",
    "    .config(\"spark.executor.memory\", \"16g\") \\\n",
    "    .config(\"spark.master\", \"local[12]\") \\\n",
    "    .getOrCreate()\n",
    "# spark = SparkSession \\\n",
    "#     .builder \\\n",
    "#     .appName(\"movie recommendation\") \\\n",
    "#     .config(\"spark.driver.maxResultSize\", \"8g\") \\\n",
    "#     .config(\"spark.driver.memory\", \"8g\") \\\n",
    "#     .config(\"spark.executor.memory\", \"8g\") \\\n",
    "#     .config(\"spark.master\", \"local[12]\") \\\n",
    "#     .getOrCreate()\n",
    "\n",
    "# get spark context\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Download dataset from: http://deepyeti.ucsd.edu/jianmo/amazon/categoryFiles/Clothing_Shoes_and_Jewelry.json.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 530 Âµs\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = '../../Data_fulldata/Review/ClothingShoesAndJewelry/'\n",
    "REVIEW_DATA = 'Clothing_Shoes_and_Jewelry.json.gz'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Please unzip Clothing_Shoes_and_Jewelry.json.gz to Clothing_Shoes_and_Jewelry.json\n",
    "2. Load Clothing_Shoes_and_Jewelry.json (14.1 GB (14,144,939,923 bytes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2min 8s\n"
     ]
    }
   ],
   "source": [
    "ratings = spark.read.load(DATA_PATH+REVIEW_DATA, format='json', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+-------+--------------------+-----------+--------------+-------------+--------------------+--------------------+--------------+--------+----+\n",
      "|      asin|image|overall|          reviewText| reviewTime|    reviewerID| reviewerName|               style|             summary|unixReviewTime|verified|vote|\n",
      "+----------+-----+-------+--------------------+-----------+--------------+-------------+--------------------+--------------------+--------------+--------+----+\n",
      "|0871167042| null|    5.0|This book has bea...| 05 4, 2014|A2IC3NZN488KWK|   Ruby Tulip|[,,,,,,,,  Paperb...|      Unique designs|    1399161600|    true|   2|\n",
      "|0871167042| null|    4.0|I love the ideas ...|04 26, 2014|A3OT9BYASFGU2X|    Laurie K.|[,,,,,,,,  Paperb...|makes you want to...|    1398470400|    true|null|\n",
      "|0871167042| null|    5.0|As someone who ha...|04 17, 2014|A28GK1G2KDXHRP|Marie Rhoades|[,,,,,,,,  Paperb...|Highly Recommend ...|    1397692800|   false|   6|\n",
      "+----------+-----+-------+--------------------+-----------+--------------+-------------+--------------------+--------------------+--------------+--------+----+\n",
      "only showing top 3 rows\n",
      "\n",
      "time: 290 ms\n"
     ]
    }
   ],
   "source": [
    "ratings.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.11 ms\n"
     ]
    }
   ],
   "source": [
    "type(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Data (32292099, 12)\n",
      "time: 1min 18s\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of Data\", (ratings.count(), len(ratings.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop and Clean data\n",
    "    - Drop null in Vote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 10.9 ms\n"
     ]
    }
   ],
   "source": [
    "clean_ratings = ratings.na.drop(how='any', subset='vote')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Data (2886813, 12)\n",
      "time: 1min 23s\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of Data\", (clean_ratings.count(), len(clean_ratings.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark SQL and OLAP\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What is the total number of review in the data sets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have a total of 2886813 review in the data sets\n",
      "time: 1min 27s\n"
     ]
    }
   ],
   "source": [
    "tmp = clean_ratings.count()\n",
    "print('We have a total of {} review in the data sets'.format(tmp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What are the overall?\n",
    "    - overall - rating of the product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct values of overall:\n",
      "[1.0, 2.0, 3.0, 4.0, 5.0]\n",
      "time: 1min 27s\n"
     ]
    }
   ],
   "source": [
    "print('Distinct values of overall:')\n",
    "print(sorted(clean_ratings.select('overall').distinct().rdd.map(lambda r: r[0]).collect()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What are the vote?\n",
    "    - vote - helpful votes of the review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct values of vote:\n",
      "['1,000', '1,004', '1,008', '1,009', '1,012', '1,014', '1,024', '1,038', '1,052', '1,062', '1,066', '1,077', '1,091', '1,092', '1,115', '1,118', '1,125', '1,134', '1,151', '1,195', '1,199', '1,204', '1,223', '1,232', '1,241', '1,250', '1,272', '1,322', '1,332', '1,333', '1,354', '1,359', '1,376', '1,377', '1,409', '1,449', '1,464', '1,488', '1,494', '1,506', '1,556', '1,652', '1,693', '1,706', '1,790', '1,858', '1,861', '1,895', '1,922', '1,926', '1,939', '1,942', '1,960', '10', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '11', '11,445', '11,578', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '12', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '13', '130', '131', '132', '133', '134', '135', '136', '137', '138', '139', '14', '140', '141', '142', '143', '144', '145', '146', '147', '148', '149', '15', '150', '151', '152', '153', '154', '155', '156', '157', '158', '159', '16', '160', '161', '162', '163', '164', '165', '166', '167', '168', '169', '17', '170', '171', '172', '173', '174', '175', '176', '177', '178', '179', '18', '180', '181', '182', '183', '184', '185', '186', '187', '188', '189', '19', '190', '191', '192', '193', '194', '195', '196', '197', '198', '199', '2', '2,278', '2,294', '2,330', '2,333', '2,573', '2,575', '2,672', '2,727', '2,943', '20', '200', '201', '202', '203', '204', '205', '206', '207', '208', '209', '21', '210', '211', '212', '213', '214', '215', '216', '217', '218', '219', '22', '220', '221', '222', '223', '224', '225', '226', '227', '228', '229', '23', '230', '231', '232', '233', '234', '235', '236', '237', '238', '239', '24', '240', '241', '242', '243', '244', '245', '246', '247', '248', '249', '25', '250', '251', '252', '253', '254', '255', '256', '257', '258', '259', '26', '260', '261', '262', '263', '264', '265', '266', '267', '268', '269', '27', '270', '271', '272', '273', '274', '275', '276', '277', '278', '279', '28', '280', '281', '282', '283', '284', '285', '286', '287', '288', '289', '29', '290', '291', '292', '293', '294', '295', '296', '297', '298', '299', '3', '3,116', '3,364', '3,594', '3,829', '3,977', '30', '300', '301', '302', '303', '304', '305', '306', '307', '308', '309', '31', '310', '311', '312', '313', '314', '315', '316', '317', '318', '319', '32', '320', '321', '322', '323', '324', '325', '326', '327', '328', '329', '33', '330', '331', '332', '333', '334', '335', '336', '337', '338', '339', '34', '340', '341', '342', '343', '344', '345', '346', '347', '348', '349', '35', '350', '351', '352', '353', '354', '355', '356', '357', '358', '359', '36', '360', '361', '362', '363', '364', '365', '366', '367', '368', '369', '37', '370', '371', '372', '373', '374', '375', '376', '377', '378', '379', '38', '380', '381', '382', '383', '384', '385', '386', '387', '388', '389', '39', '390', '392', '393', '394', '395', '396', '397', '398', '399', '4', '4,536', '40', '400', '401', '402', '403', '404', '405', '406', '407', '408', '409', '41', '41,420', '410', '411', '412', '413', '414', '415', '416', '417', '418', '419', '42', '420', '421', '422', '423', '424', '425', '427', '428', '429', '43', '430', '431', '432', '433', '434', '435', '436', '437', '438', '439', '44', '440', '441', '442', '443', '444', '445', '446', '447', '448', '449', '45', '450', '451', '453', '454', '455', '456', '457', '458', '459', '46', '460', '462', '463', '464', '465', '466', '467', '468', '469', '47', '470', '471', '473', '475', '476', '477', '478', '479', '48', '480', '481', '484', '485', '487', '488', '489', '49', '490', '491', '492', '494', '495', '496', '497', '498', '499', '5', '5,034', '5,075', '5,153', '5,351', '50', '500', '501', '502', '504', '507', '508', '51', '510', '511', '512', '514', '515', '516', '518', '519', '52', '520', '521', '523', '524', '527', '529', '53', '530', '531', '533', '534', '535', '536', '537', '538', '539', '54', '540', '541', '542', '543', '544', '545', '546', '547', '548', '55', '550', '551', '553', '554', '555', '557', '558', '559', '56', '560', '561', '562', '565', '566', '567', '568', '57', '570', '572', '576', '577', '578', '579', '58', '581', '584', '585', '586', '588', '589', '59', '590', '592', '593', '595', '598', '6', '6,898', '60', '600', '601', '602', '605', '606', '607', '608', '609', '61', '612', '613', '614', '615', '616', '617', '619', '62', '620', '621', '622', '623', '624', '625', '626', '63', '630', '631', '632', '634', '635', '638', '639', '64', '640', '641', '644', '646', '647', '65', '651', '652', '655', '656', '658', '659', '66', '661', '664', '666', '667', '668', '669', '67', '673', '676', '68', '680', '683', '684', '685', '686', '689', '69', '692', '696', '697', '7', '70', '700', '702', '703', '704', '705', '706', '71', '711', '719', '72', '720', '722', '723', '724', '728', '73', '730', '731', '733', '736', '738', '74', '741', '747', '749', '75', '750', '751', '753', '757', '759', '76', '760', '761', '764', '766', '767', '769', '77', '772', '773', '775', '779', '78', '781', '783', '787', '789', '79', '792', '8', '80', '802', '806', '809', '81', '814', '816', '817', '82', '823', '828', '83', '830', '831', '833', '84', '849', '85', '86', '861', '87', '871', '872', '874', '875', '88', '880', '886', '889', '89', '894', '897', '9', '90', '909', '91', '914', '915', '918', '92', '928', '93', '935', '937', '938', '94', '941', '945', '947', '95', '951', '96', '967', '969', '97', '972', '977', '98', '983', '99', '990', '998']\n",
      "time: 1min 28s\n"
     ]
    }
   ],
   "source": [
    "print('Distinct values of vote:')\n",
    "print(sorted(clean_ratings.select('vote').distinct().rdd.map(lambda r: r[0]).collect()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What is minimum number of ratings per user and minimum number of ratings per product?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+-------+--------------------+-----------+--------------+-------------+--------------------+--------------------+--------------+--------+----+\n",
      "|      asin|image|overall|          reviewText| reviewTime|    reviewerID| reviewerName|               style|             summary|unixReviewTime|verified|vote|\n",
      "+----------+-----+-------+--------------------+-----------+--------------+-------------+--------------------+--------------------+--------------+--------+----+\n",
      "|0871167042| null|    5.0|This book has bea...| 05 4, 2014|A2IC3NZN488KWK|   Ruby Tulip|[,,,,,,,,  Paperb...|      Unique designs|    1399161600|    true|   2|\n",
      "|0871167042| null|    5.0|As someone who ha...|04 17, 2014|A28GK1G2KDXHRP|Marie Rhoades|[,,,,,,,,  Paperb...|Highly Recommend ...|    1397692800|   false|   6|\n",
      "+----------+-----+-------+--------------------+-----------+--------------+-------------+--------------------+--------------------+--------------+--------+----+\n",
      "only showing top 2 rows\n",
      "\n",
      "time: 167 ms\n"
     ]
    }
   ],
   "source": [
    "clean_ratings.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the users that rated product and the product that were rated:\n",
      "Minimum number of ratings per user is 1\n",
      "Minimum number of ratings per product is 1\n",
      "time: 3min 3s\n"
     ]
    }
   ],
   "source": [
    "tmp1 = clean_ratings.groupBy(\"reviewerID\").count().toPandas()['count'].min()\n",
    "tmp2 = clean_ratings.groupBy(\"asin\").count().toPandas()['count'].min()\n",
    "print('For the users that rated product and the product that were rated:')\n",
    "print('Minimum number of ratings per user is {}'.format(tmp1))\n",
    "print('Minimum number of ratings per product is {}'.format(tmp2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What is \n",
    "1. maximun number of ratings per user \n",
    "2. maximun number of ratings per product\n",
    "3. maximun number of vote per product?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the users that rated product and the product that were rated:\n",
      "Maximun number of ratings per user is 186\n",
      "Maximun number of ratings per product is 2493\n",
      "Maximun number of ratings per vote is 1186954\n",
      "time: 4min 43s\n"
     ]
    }
   ],
   "source": [
    "tmp1 = clean_ratings.groupBy(\"reviewerID\").count().toPandas()['count'].max()\n",
    "tmp2 = clean_ratings.groupBy(\"asin\").count().toPandas()['count'].max()\n",
    "tmp3 = clean_ratings.groupBy(\"vote\").count().toPandas()['count'].max()\n",
    "print('For the users that rated product and the product that were rated:')\n",
    "print('Maximun number of ratings per user is {}'.format(tmp1))\n",
    "print('Maximun number of ratings per product is {}'.format(tmp2))\n",
    "print('Maximun number of ratings per vote is {}'.format(tmp3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- How many products are rated by only one user?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "290806 out of 631570 product are rated by only one user\n",
      "time: 3min 23s\n"
     ]
    }
   ],
   "source": [
    "tmp1 = sum(clean_ratings.groupBy(\"asin\").count().toPandas()['count'] == 1)\n",
    "tmp2 = clean_ratings.select('asin').distinct().count()\n",
    "print('{} out of {} product are rated by only one user'.format(tmp1, tmp2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What is the total number of users in the data sets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have a total of 631570 distinct product in the data sets\n",
      "time: 1min 42s\n"
     ]
    }
   ],
   "source": [
    "tmp = clean_ratings.select('asin').distinct().count()\n",
    "print('We have a total of {} distinct product in the data sets'.format(tmp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Style Column - How we can use this one? How I can get data from \"Format\"?\n",
    "- Parsing Style column\n",
    "\n",
    "    - Row(Capacity:=None, Color Name:=None, Color:=None, Design:=None, Diameter:=None, Edition:=None, Flavor Name:=None, Flavor:=None, Format:=' Paperback', Gem Type:=None, Grip Type:=None, Initial:=None, Item Display Length:=None, Item Package Quantity:=None, Length:=None, Material Type:=None, Material:=None, Metal Stamp:=None, Metal Type:=None, Model Number:=None, Number of Items:=None, Offer Type:=None, Package Quantity:=None, Package Type:=None, Pattern:=None, Primary Stone Gem Type:=None, Product Packaging:=None, Scent Name:=None, Shape:=None, Size Name:=None, Size per Pearl:=None, Size:=None, Stone Shape:=None, Style Name:=None, Style:=None, Team Name:=None, Total Diamond Weight:=None, Width:=None)\n",
    "\n",
    "    - Row(Capacity:=None, Color Name:=None, Color:=None, Design:=None, Diameter:=None, Edition:=None, Flavor Name:=None, Flavor:=None, Format:=' Kindle Edition', Gem Type:=None, Grip Type:=None, Initial:=None, Item Display Length:=None, Item Package Quantity:=None, Length:=None, Material Type:=None, Material:=None, Metal Stamp:=None, Metal Type:=None, Model Number:=None, Number of Items:=None, Offer Type:=None, Package Quantity:=None, Package Type:=None, Pattern:=None, Primary Stone Gem Type:=None, Product Packaging:=None, Scent Name:=None, Shape:=None, Size Name:=None, Size per Pearl:=None, Size:=None, Stone Shape:=None, Style Name:=None, Style:=None, Team Name:=None, Total Diamond Weight:=None, Width:=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2min 7s\n"
     ]
    }
   ],
   "source": [
    "clean_ratings.select('style').toPandas().head(n=10).to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+-------+--------------------+-----------+--------------+-------------+--------------------+--------------------+--------------+--------+----+\n",
      "|      asin|image|overall|          reviewText| reviewTime|    reviewerID| reviewerName|               style|             summary|unixReviewTime|verified|vote|\n",
      "+----------+-----+-------+--------------------+-----------+--------------+-------------+--------------------+--------------------+--------------+--------+----+\n",
      "|0871167042| null|    5.0|This book has bea...| 05 4, 2014|A2IC3NZN488KWK|   Ruby Tulip|[,,,,,,,,  Paperb...|      Unique designs|    1399161600|    true|   2|\n",
      "|0871167042| null|    5.0|As someone who ha...|04 17, 2014|A28GK1G2KDXHRP|Marie Rhoades|[,,,,,,,,  Paperb...|Highly Recommend ...|    1397692800|   false|   6|\n",
      "+----------+-----+-------+--------------------+-----------+--------------+-------------+--------------------+--------------------+--------------+--------+----+\n",
      "only showing top 2 rows\n",
      "\n",
      "time: 67.2 ms\n"
     ]
    }
   ],
   "source": [
    "clean_ratings.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation system in python using ALS algorithm and Apache Spark\n",
    "\n",
    "### Terminologies:\n",
    "There are certain terminologies which needs to be understood before moving forward.\n",
    "1. Apache Spark: Apache Spark is an open-source distributed general-purpose cluster-computing framework.It can be used with Hadoop too.\n",
    "2. Collaborative filtering: Collaborative filtering is a method of making automatic predictions (filtering) about the interests of a user by collecting preferences or taste information from many users. Consider example if a person A likes item 1, 2, 3 and B like 2,3,4 then they have similar interests and A should like item 4 and B should like item 1.\n",
    "3. Alternating least square(ALS) matrix factorization: The idea is basically to take a large (or potentially huge) matrix and factor it into some smaller representation of the original matrix through alternating least squares. We end up with two or more lower dimensional matrices whose product equals the original one.ALS comes inbuilt in Apache Spark.\n",
    "4. PySpark: PySpark is the collaboration of Apache Spark and Python. PySpark is the Python API for Spark.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+-------+--------------------+-----------+--------------+--------------------+--------------------+--------------------+--------------+--------+----+\n",
      "|      asin|image|overall|          reviewText| reviewTime|    reviewerID|        reviewerName|               style|             summary|unixReviewTime|verified|vote|\n",
      "+----------+-----+-------+--------------------+-----------+--------------+--------------------+--------------------+--------------------+--------------+--------+----+\n",
      "|0871167042| null|    5.0|This book has bea...| 05 4, 2014|A2IC3NZN488KWK|          Ruby Tulip|[,,,,,,,,  Paperb...|      Unique designs|    1399161600|    true|   2|\n",
      "|0871167042| null|    4.0|I love the ideas ...|04 26, 2014|A3OT9BYASFGU2X|           Laurie K.|[,,,,,,,,  Paperb...|makes you want to...|    1398470400|    true|null|\n",
      "|0871167042| null|    5.0|As someone who ha...|04 17, 2014|A28GK1G2KDXHRP|       Marie Rhoades|[,,,,,,,,  Paperb...|Highly Recommend ...|    1397692800|   false|   6|\n",
      "|0871167042| null|    5.0|beautiful layout ...|04 16, 2014|A3NFXFEKW8OK0E|              Bobbie|[,,,,,,,,  Paperb...|          great book|    1397606400|    true|null|\n",
      "|0871167042| null|    5.0|Some days ago I r...|04 15, 2014|A3I6G5TKBVJEK9|              mperez|[,,,,,,,,  Paperb...|           Excellent|    1397520000|    true|null|\n",
      "|0871167042| null|    5.0|Excellent! It was...|03 31, 2014|A1A7Y1M8AJWNZ8|              Laurie|[,,,,,,,,  Paperb...|              Great!|    1396224000|    true|null|\n",
      "|0871167042| null|    5.0|Loved their appro...|03 31, 2014|A30FG02C424EJ5|        NWCancerBaby|[,,,,,,,,  Paperb...|          Great Book|    1396224000|    true|null|\n",
      "|0871167042| null|    5.0|Well written and ...|03 28, 2014| ADQQYU1UCDEWB|              Marlee|[,,,,,,,,  Paperb...|Beach Glass and W...|    1395964800|    true|null|\n",
      "|0871167042| null|    5.0|I highly recommen...|03 23, 2014|A39YL2NXZORK56|        Susan Coffey|[,,,,,,,,  Paperb...|Excellent additio...|    1395532800|    true|  14|\n",
      "|0871167042| null|    5.0|This beautifully ...|03 20, 2014|A2PRY50ZESF1MH|         Nancy Petro|[,,,,,,,,  Paperb...|Beautiful, Instru...|    1395273600|    true|   7|\n",
      "|0871167042| null|    5.0|               great|05 30, 2015|A2G9GWQEWWNQUB|         Pamelarenee|[,,,,,,,,  Paperb...|          Five Stars|    1432944000|    true|null|\n",
      "|0871167042| null|    4.0|Great book. Lots ...| 05 7, 2015|A3RGH15H17SM1Z|             beadmom|[,,,,,,,,  Paperb...|         Great book.|    1430956800|    true|null|\n",
      "|0871167042| null|    3.0|           It's O.K.| 04 3, 2015|A20QJNRKLJVP1E|            Sue Cook|[,,,,,,,,  Paperb...|         Three Stars|    1428019200|    true|null|\n",
      "|0871167042| null|    5.0|Fantastic book - ...|03 27, 2015|A1G26EYQGW3YF1|             N. Bean|[,,,,,,,,  Paperb...|      Wonderful book|    1427414400|    true|   2|\n",
      "|0871167042| null|    4.0|I like cold conne...|03 16, 2015|A2JGAZF2Y2BDU6|              drc536|                null|A Wonderful Surprise|    1426464000|   false|null|\n",
      "|0871167042| null|    5.0|Always love the w...|02 21, 2015|A3NI5OGW35SLY2|                Gail|[,,,,,,,,  Paperb...|         Great Book!|    1424476800|    true|null|\n",
      "|0871167042| null|    5.0|       Nice patterns|01 21, 2015|A1OPRA4NE56EV6|       carol a inman|[,,,,,,,,  Paperb...|          Five Stars|    1421798400|    true|null|\n",
      "|0871167042| null|    4.0|love the spirit o...|12 18, 2014|A3M6UXIK7XTA7A|                  CV|[,,,,,,,,  Paperb...|          Four Stars|    1418860800|    true|null|\n",
      "|0871167042| null|    5.0|  just what I wanted|11 24, 2014|A3I3B5OSB80ZXC|dorothy I huttenl...|[,,,,,,,,  Paperb...|          Five Stars|    1416787200|    true|null|\n",
      "|0871167042| null|    5.0|Beautiful picture...|10 21, 2014| A62O7C5RQB353|               Robin|[,,,,,,,,  Paperb...|          Five Stars|    1413849600|   false|null|\n",
      "|0871167042| null|    5.0|This has got to b...|10 17, 2014| A8MZ2YP8UJA9Q|               Lu H.|[,,,,,,,,  Paperb...|          Five Stars|    1413504000|    true|null|\n",
      "|0871167042| null|    5.0|This is a fabulou...| 10 9, 2014| AL3IEZLLIAGNH|  Jean Van Brederode|[,,,,,,,,  Paperb...|The designs are w...|    1412812800|   false|null|\n",
      "|0871167042| null|    2.0|Not a fan. Limite...| 09 3, 2014|A22ZX01TPWQY4G|              Nonnie|[,,,,,,,,  Paperb...|           Two Stars|    1409702400|    true|null|\n",
      "|0871167042| null|    3.0|If you're an expe...|07 23, 2014|A1YIEW86G14BHP|           Aldne Now|[,,,,,,,,  Paperb...|     OK Jewelry Book|    1406073600|    true|   5|\n",
      "|0871167042| null|    5.0|A very good book....|07 14, 2014|A3A96RTGZTWKWG|  Designs by Germany|[,,,,,,,,  Paperb...|  Great jewelry book|    1405296000|    true|null|\n",
      "|0871167042| null|    4.0|Hi, have been mak...| 06 5, 2014| AA7PNT2OPS3RP|     Catherine Franz|[,,,,,,,,  Paperb...|Organic and upcyc...|    1401926400|    true|   3|\n",
      "|0871167042| null|    5.0|There's nothing p...|05 30, 2014|A3LOIIIW4G3TL7|         Picky Virgo|[,,,,,,,,  Paperb...|      Perfect Title!|    1401408000|    true|   2|\n",
      "|0871167042| null|    5.0|Great projects th...|05 12, 2014|A25QEMMPTX5D5D|    Susan Hildebrand|[,,,,,,,,  Paperb...|Wonderful project...|    1399852800|    true|null|\n",
      "|0871167042| null|    5.0|I love this book!...|05 10, 2014| AZI75OKBKZ98R|           T. Malone|[,,,,,,,,  Paperb...|       Inspirational|    1399680000|    true|   2|\n",
      "|0871167042| null|    5.0|I wanted to suppo...| 05 7, 2014|A1NZRLAQC3XB32|          L. Foxwell|[,,,,,,,,  Paperb...|nice book for beg...|    1399420800|    true|null|\n",
      "|1519588135| null|    5.0|Just love this se...|12 13, 2015|A16DSXRAN5QK94|              Denise|[,,,,,,,,  Kindle...|            Loved it|    1449964800|    true|   5|\n",
      "|1519588135| null|    3.0|I wanted to LOVE ...|12 13, 2015|A3GWE80SUGORJD|        Bette Hansen|[,,,,,,,,  Kindle...|I wanted to LOVE ...|    1449964800|   false|null|\n",
      "|1519588135| null|    4.0|This was really a...|12 12, 2015|A2NLY1TJ8TYV6D|          GSKM in sc|[,,,,,,,,  Kindle...|             Enjoyed|    1449878400|    true|   2|\n",
      "|1519588135| null|    5.0|Brice Henderson f...|12 12, 2015|A2GU5SHR2DC29H|              ZETTER|[,,,,,,,,  Kindle...|    Sweetest Love!!!|    1449878400|    true|  22|\n",
      "|1519588135| null|    4.0|This book was a s...| 12 7, 2015|A2FHBHNKHRDS72|Reading by the Bo...|[,,,,,,,,  Kindle...|Solid and Engagin...|    1449446400|    true|   3|\n",
      "|1519588135| null|    5.0|As always Jeannet...| 12 7, 2015|A1EAXUN286CZ5Z|        Tina Brimlow|[,,,,,,,,  Kindle...|A new series, ano...|    1449446400|    true|   8|\n",
      "|1519588135| null|    5.0|A great start to ...| 12 7, 2015|A1OMRK7B7SN83C|     Kindle Customer|[,,,,,,,,  Kindle...|   A great new start|    1449446400|    true|   5|\n",
      "|1519588135| null|    5.0|Fab new series.  ...| 12 7, 2015|A3TCVTOI95UQUT|              Amanda|[,,,,,,,,  Kindle...|      Fab new series|    1449446400|   false|   2|\n",
      "|1519588135| null|    4.0|Good read.. unpre...|03 14, 2018|A17S6SU1PHP443|        James Castle|[,,,,,,,,  Kindle...|             Amazing|    1520985600|    true|null|\n",
      "|1519588135| null|    5.0|Great Read. I rea...|03 14, 2018|A3IUKE1LC890XR|     Amazon Customer|[,,,,,,,,  Kindle...|          Great Read|    1520985600|    true|null|\n",
      "|1519588135| null|    4.0|Great quick read ...|03 10, 2018|A2R2AOAQ0E7CCN|     Amazon Customer|[,,,,,,,,  Kindle...|       One White Lie|    1520640000|    true|null|\n",
      "|1519588135| null|    5.0|Delightful read q...| 03 6, 2018|A3FLZJDY64B3NS|     Amazon Customer|[,,,,,,,,  Kindle...|          Five Stars|    1520294400|    true|null|\n",
      "|1519588135| null|    5.0|I'm new to this a...|02 23, 2018|A2CPOWZUTJWXJ7|             griffle|[,,,,,,,,  Kindle...|Enjoying this ser...|    1519344000|    true|null|\n",
      "|1519588135| null|    5.0|Great series to r...|02 22, 2018| ASR774IIR8VN7|          Lucinda Jo|[,,,,,,,,  Kindle...|          Five Stars|    1519257600|    true|null|\n",
      "|1519588135| null|    5.0|I enjoyed the story.|02 21, 2018| AH6N2G535GBTV|        Anita Gillis|[,,,,,,,,  Kindle...|          Five Stars|    1519171200|    true|null|\n",
      "|1519588135| null|    4.0|Loved the ups and...|02 17, 2018| AOOQKOAO92KYC|              Missym|[,,,,,,,,  Kindle...|       One White Lie|    1518825600|    true|null|\n",
      "|1519588135| null|    4.0|I have enjoyed re...|02 10, 2018|  ARQV45QV4HI0|     Amazon Customer|[,,,,,,,,  Kindle...|           Good read|    1518220800|    true|null|\n",
      "|1519588135| null|    5.0|One of the best r...| 02 7, 2018|A3IP9K53AAY4BD|  Amazon Customer ln|[,,,,,,,,  Kindle...|       One white Lie|    1517961600|    true|null|\n",
      "|1519588135| null|    5.0|Loved this book f...| 02 3, 2018|A39J539BKZCHCQ|                  JR|[,,,,,,,,  Kindle...|          Great Read|    1517616000|    true|null|\n",
      "|1519588135| null|    5.0|Loved this story ...| 02 3, 2018|A2DODWGA5PVBH7|     Kindle Customer|[,,,,,,,,  Kindle...|         Long coming|    1517616000|    true|null|\n",
      "+----------+-----+-------+--------------------+-----------+--------------+--------------------+--------------------+--------------------+--------------+--------+----+\n",
      "only showing top 50 rows\n",
      "\n",
      "time: 2min 5s\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "df = spark.read.json(DATA_PATH+REVIEW_DATA)\n",
    "df.show(50,truncate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Select appropriate columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+--------------+\n",
      "|      asin|overall|    reviewerID|\n",
      "+----------+-------+--------------+\n",
      "|0871167042|    5.0|A2IC3NZN488KWK|\n",
      "|0871167042|    4.0|A3OT9BYASFGU2X|\n",
      "|0871167042|    5.0|A28GK1G2KDXHRP|\n",
      "|0871167042|    5.0|A3NFXFEKW8OK0E|\n",
      "|0871167042|    5.0|A3I6G5TKBVJEK9|\n",
      "|0871167042|    5.0|A1A7Y1M8AJWNZ8|\n",
      "|0871167042|    5.0|A30FG02C424EJ5|\n",
      "|0871167042|    5.0| ADQQYU1UCDEWB|\n",
      "|0871167042|    5.0|A39YL2NXZORK56|\n",
      "|0871167042|    5.0|A2PRY50ZESF1MH|\n",
      "|0871167042|    5.0|A2G9GWQEWWNQUB|\n",
      "|0871167042|    4.0|A3RGH15H17SM1Z|\n",
      "|0871167042|    3.0|A20QJNRKLJVP1E|\n",
      "|0871167042|    5.0|A1G26EYQGW3YF1|\n",
      "|0871167042|    4.0|A2JGAZF2Y2BDU6|\n",
      "|0871167042|    5.0|A3NI5OGW35SLY2|\n",
      "|0871167042|    5.0|A1OPRA4NE56EV6|\n",
      "|0871167042|    4.0|A3M6UXIK7XTA7A|\n",
      "|0871167042|    5.0|A3I3B5OSB80ZXC|\n",
      "|0871167042|    5.0| A62O7C5RQB353|\n",
      "+----------+-------+--------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "time: 72 ms\n"
     ]
    }
   ],
   "source": [
    "nd=df.select(df['asin'],df['overall'],df['reviewerID'])\n",
    "nd.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Converting String to index\n",
    "\n",
    "Before making an ALS model it needs to be clear that ALS only accepts integer value as parameters. Hence we need to convert asin and reviewerID column in index form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+--------------+----------+----------------+\n",
      "|      asin|overall|    reviewerID|asin_index|reviewerID_index|\n",
      "+----------+-------+--------------+----------+----------------+\n",
      "|0871167042|    5.0|A2IC3NZN488KWK|  122222.0|        157794.0|\n",
      "|0871167042|    4.0|A3OT9BYASFGU2X|  122222.0|       6460415.0|\n",
      "|0871167042|    5.0|A28GK1G2KDXHRP|  122222.0|       7128913.0|\n",
      "|0871167042|    5.0|A3NFXFEKW8OK0E|  122222.0|       8584184.0|\n",
      "|0871167042|    5.0|A3I6G5TKBVJEK9|  122222.0|       7606980.0|\n",
      "|0871167042|    5.0|A1A7Y1M8AJWNZ8|  122222.0|       5345257.0|\n",
      "|0871167042|    5.0|A30FG02C424EJ5|  122222.0|       1004286.0|\n",
      "|0871167042|    5.0| ADQQYU1UCDEWB|  122222.0|       3077653.0|\n",
      "|0871167042|    5.0|A39YL2NXZORK56|  122222.0|       8082569.0|\n",
      "|0871167042|    5.0|A2PRY50ZESF1MH|  122222.0|       6020161.0|\n",
      "|0871167042|    5.0|A2G9GWQEWWNQUB|  122222.0|        439771.0|\n",
      "|0871167042|    4.0|A3RGH15H17SM1Z|  122222.0|       5094237.0|\n",
      "|0871167042|    3.0|A20QJNRKLJVP1E|  122222.0|       9566676.0|\n",
      "|0871167042|    5.0|A1G26EYQGW3YF1|  122222.0|       4048191.0|\n",
      "|0871167042|    4.0|A2JGAZF2Y2BDU6|  122222.0|       4743839.0|\n",
      "|0871167042|    5.0|A3NI5OGW35SLY2|  122222.0|        893152.0|\n",
      "|0871167042|    5.0|A1OPRA4NE56EV6|  122222.0|        244551.0|\n",
      "|0871167042|    4.0|A3M6UXIK7XTA7A|  122222.0|        467330.0|\n",
      "|0871167042|    5.0|A3I3B5OSB80ZXC|  122222.0|       5611156.0|\n",
      "|0871167042|    5.0| A62O7C5RQB353|  122222.0|       6522325.0|\n",
      "+----------+-------+--------------+----------+----------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "time: 6min 7s\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "indexer = [StringIndexer(inputCol=column, outputCol=column+\"_index\") for column in list(set(nd.columns)-set(['overall'])) ]\n",
    "pipeline = Pipeline(stages=indexer)\n",
    "transformed = pipeline.fit(nd).transform(nd)\n",
    "transformed.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Creating training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 188 Âµs\n"
     ]
    }
   ],
   "source": [
    "# (training,test)=transformed.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[asin: string, overall: double, reviewerID: string, asin_index: double, reviewerID_index: double]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 12.1 s\n"
     ]
    }
   ],
   "source": [
    "train, validation, test = transformed.randomSplit([0.6, 0.2, 0.2], seed=99)\n",
    "\n",
    "# cache data\n",
    "train.cache()\n",
    "validation.cache()\n",
    "test.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Creating ALS model and fitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 266 Âµs\n"
     ]
    }
   ],
   "source": [
    "# als=ALS(maxIter=5,regParam=0.09,rank=25,userCol=\"reviewerID_index\",itemCol=\"asin_index\",ratingCol=\"overall\",coldStartStrategy=\"drop\",nonnegative=True)\n",
    "# model=als.fit(training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- hyper-params in Alternating Least Square (ALS):\n",
    "    - num_iters: the maximum number of iterations to run (defaults to 10)\n",
    "\n",
    "    - ranks: the number of latent factors in the model (defaults to 10)\n",
    "        - the number of latent factors can be tuned via cross-validation. \n",
    "        - **Latent factors are the features in the lower dimension latent space projected from user-item interaction matrix.**\n",
    "        - The idea behind matrix factorization is to use latent factors to represent user preferences or movie topics in a much lower dimension space. \n",
    "        - Matrix factorization is one of very effective dimension reduction techniques in machine learning.\n",
    "    - reg_param: the regularization parameter in ALS (defaults to 1.0)\n",
    "        - A common strategy to avoid overfitting is to add regularization terms to the objective function.\n",
    "        - Its objective function is slightly different than Funk SVD: ALS uses L2 regularization while Funk uses L1 regularization\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.86 ms\n"
     ]
    }
   ],
   "source": [
    "def train_ALS(train_data, validation_data, num_iters, reg_param, ranks):\n",
    "    \"\"\"\n",
    "    grid search function to select the best model based on RMSE of\n",
    "    validation data\n",
    "    Parameters\n",
    "    ----------\n",
    "    train_data: spark DF with columns ['asin', 'overall', 'reviewerID']\n",
    "    \n",
    "    validation_data: spark DF with columns ['asin', 'overall', 'reviewerID']\n",
    "    \n",
    "    num_iters: int, max number of learning iterations\n",
    "    \n",
    "    reg_param: list of float, one dimension of hyper-param tuning grid\n",
    "    \n",
    "    ranks: list of float, one dimension of hyper-param tuning grid\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    The best fitted ALS model with lowest RMSE score on validation data\n",
    "    \"\"\"\n",
    "    \n",
    "    # initial\n",
    "    min_error = float('inf')\n",
    "    best_rank = -1\n",
    "    best_regularization = 0\n",
    "    best_model = None\n",
    "    \n",
    "    for rank in ranks:\n",
    "        for reg in reg_param:\n",
    "            # train ALS model\n",
    "            model = ALS.train(\n",
    "                ratings=train_data,    # (userID, productID, rating) tuple\n",
    "                iterations=num_iters,\n",
    "                rank=rank,\n",
    "                lambda_=reg,           # regularization param\n",
    "                seed=99)\n",
    "            \n",
    "            # make prediction\n",
    "            valid_data = validation_data.map(lambda p: (p[0], p[1]))\n",
    "            predictions = model.predictAll(valid_data).map(lambda r: ((r[0], r[1]), r[2]))\n",
    "            \n",
    "            # get the rating result\n",
    "            ratesAndPreds = validation_data.map(lambda r: ((r[0], r[1]), r[2])).join(predictions)\n",
    "            \n",
    "            # get the RMSE\n",
    "            MSE = ratesAndPreds.map(lambda r: (r[1][0] - r[1][1])**2).mean()\n",
    "            error = math.sqrt(MSE)\n",
    "            print('{} latent factors and regularization = {}: validation RMSE is {}'.format(rank, reg, error))\n",
    "            if error < min_error:\n",
    "                min_error = error\n",
    "                best_rank = rank\n",
    "                best_regularization = reg\n",
    "                best_model = model\n",
    "                \n",
    "    print('\\nThe best model has {} latent factors and regularization = {}'.format(best_rank, best_regularization))\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Exception happened during processing of request from ('127.0.0.1', 44972)\n",
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jh/anaconda3/envs/movie_recomm/lib/python3.7/site-packages/py4j/java_gateway.py\", line 1159, in send_command\n",
      "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
      "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jh/anaconda3/envs/movie_recomm/lib/python3.7/site-packages/py4j/java_gateway.py\", line 985, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/home/jh/anaconda3/envs/movie_recomm/lib/python3.7/site-packages/py4j/java_gateway.py\", line 1164, in send_command\n",
      "    \"Error while receiving\", e, proto.ERROR_ON_RECEIVE)\n",
      "py4j.protocol.Py4JNetworkError: Error while receiving\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jh/anaconda3/envs/movie_recomm/lib/python3.7/socketserver.py\", line 313, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/home/jh/anaconda3/envs/movie_recomm/lib/python3.7/socketserver.py\", line 344, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/home/jh/anaconda3/envs/movie_recomm/lib/python3.7/socketserver.py\", line 357, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/home/jh/anaconda3/envs/movie_recomm/lib/python3.7/socketserver.py\", line 717, in __init__\n",
      "    self.handle()\n",
      "  File \"/home/jh/anaconda3/envs/movie_recomm/lib/python3.7/site-packages/pyspark/accumulators.py\", line 269, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"/home/jh/anaconda3/envs/movie_recomm/lib/python3.7/site-packages/pyspark/accumulators.py\", line 241, in poll\n",
      "    if func():\n",
      "  File \"/home/jh/anaconda3/envs/movie_recomm/lib/python3.7/site-packages/pyspark/accumulators.py\", line 245, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "  File \"/home/jh/anaconda3/envs/movie_recomm/lib/python3.7/site-packages/pyspark/serializers.py\", line 724, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "----------------------------------------\n",
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jh/anaconda3/envs/movie_recomm/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-28-108ad13ccb30>\", line 8, in <module>\n",
      "    final_model = train_ALS(train, validation, num_iterations, reg_params, ranks)\n",
      "  File \"<ipython-input-27-fed98f5c3b82>\", line 36, in train_ALS\n",
      "    seed=99)\n",
      "  File \"/home/jh/anaconda3/envs/movie_recomm/lib/python3.7/site-packages/pyspark/mllib/recommendation.py\", line 273, in train\n",
      "    model = callMLlibFunc(\"trainALSModel\", cls._prepare(ratings), rank, iterations,\n",
      "  File \"/home/jh/anaconda3/envs/movie_recomm/lib/python3.7/site-packages/pyspark/mllib/recommendation.py\", line 230, in _prepare\n",
      "    first = ratings.first()\n",
      "  File \"/home/jh/anaconda3/envs/movie_recomm/lib/python3.7/site-packages/pyspark/rdd.py\", line 1378, in first\n",
      "    rs = self.take(1)\n",
      "  File \"/home/jh/anaconda3/envs/movie_recomm/lib/python3.7/site-packages/pyspark/rdd.py\", line 1360, in take\n",
      "    res = self.context.runJob(self, takeUpToNumLeft, p)\n",
      "  File \"/home/jh/anaconda3/envs/movie_recomm/lib/python3.7/site-packages/pyspark/context.py\", line 1069, in runJob\n",
      "    sock_info = self._jvm.PythonRDD.runJob(self._jsc.sc(), mappedRDD._jrdd, partitions)\n",
      "  File \"/home/jh/anaconda3/envs/movie_recomm/lib/python3.7/site-packages/py4j/java_gateway.py\", line 1257, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/home/jh/anaconda3/envs/movie_recomm/lib/python3.7/site-packages/pyspark/sql/utils.py\", line 63, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/jh/anaconda3/envs/movie_recomm/lib/python3.7/site-packages/py4j/protocol.py\", line 336, in get_return_value\n",
      "    format(target_id, \".\", name))\n",
      "py4j.protocol.Py4JError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jh/anaconda3/envs/movie_recomm/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jh/anaconda3/envs/movie_recomm/lib/python3.7/site-packages/py4j/java_gateway.py\", line 1159, in send_command\n",
      "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
      "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jh/anaconda3/envs/movie_recomm/lib/python3.7/site-packages/py4j/java_gateway.py\", line 985, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/home/jh/anaconda3/envs/movie_recomm/lib/python3.7/site-packages/py4j/java_gateway.py\", line 1164, in send_command\n",
      "    \"Error while receiving\", e, proto.ERROR_ON_RECEIVE)\n",
      "py4j.protocol.Py4JNetworkError: Error while receiving\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:41813)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jh/anaconda3/envs/movie_recomm/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-28-108ad13ccb30>\", line 8, in <module>\n",
      "    final_model = train_ALS(train, validation, num_iterations, reg_params, ranks)\n",
      "  File \"<ipython-input-27-fed98f5c3b82>\", line 36, in train_ALS\n",
      "    seed=99)\n",
      "  File \"/home/jh/anaconda3/envs/movie_recomm/lib/python3.7/site-packages/pyspark/mllib/recommendation.py\", line 273, in train\n",
      "    model = callMLlibFunc(\"trainALSModel\", cls._prepare(ratings), rank, iterations,\n",
      "  File \"/home/jh/anaconda3/envs/movie_recomm/lib/python3.7/site-packages/pyspark/mllib/recommendation.py\", line 230, in _prepare\n",
      "    first = ratings.first()\n",
      "  File \"/home/jh/anaconda3/envs/movie_recomm/lib/python3.7/site-packages/pyspark/rdd.py\", line 1378, in first\n",
      "    rs = self.take(1)\n",
      "  File \"/home/jh/anaconda3/envs/movie_recomm/lib/python3.7/site-packages/pyspark/rdd.py\", line 1360, in take\n",
      "    res = self.context.runJob(self, takeUpToNumLeft, p)\n",
      "  File \"/home/jh/anaconda3/envs/movie_recomm/lib/python3.7/site-packages/pyspark/context.py\", line 1069, in runJob\n",
      "    sock_info = self._jvm.PythonRDD.runJob(self._jsc.sc(), mappedRDD._jrdd, partitions)\n",
      "  File \"/home/jh/anaconda3/envs/movie_recomm/lib/python3.7/site-packages/py4j/java_gateway.py\", line 1257, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/home/jh/anaconda3/envs/movie_recomm/lib/python3.7/site-packages/pyspark/sql/utils.py\", line 63, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/jh/anaconda3/envs/movie_recomm/lib/python3.7/site-packages/py4j/protocol.py\", line 336, in get_return_value\n",
      "    format(target_id, \".\", name))\n",
      "py4j.protocol.Py4JError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jh/anaconda3/envs/movie_recomm/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jh/anaconda3/envs/movie_recomm/lib/python3.7/site-packages/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jh/anaconda3/envs/movie_recomm/lib/python3.7/site-packages/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:41813)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jh/anaconda3/envs/movie_recomm/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-28-108ad13ccb30>\", line 8, in <module>\n",
      "    final_model = train_ALS(train, validation, num_iterations, reg_params, ranks)\n",
      "  File \"<ipython-input-27-fed98f5c3b82>\", line 36, in train_ALS\n",
      "    seed=99)\n",
      "  File \"/home/jh/anaconda3/envs/movie_recomm/lib/python3.7/site-packages/pyspark/mllib/recommendation.py\", line 273, in train\n",
      "    model = callMLlibFunc(\"trainALSModel\", cls._prepare(ratings), rank, iterations,\n",
      "  File \"/home/jh/anaconda3/envs/movie_recomm/lib/python3.7/site-packages/pyspark/mllib/recommendation.py\", line 230, in _prepare\n",
      "    first = ratings.first()\n",
      "  File \"/home/jh/anaconda3/envs/movie_recomm/lib/python3.7/site-packages/pyspark/rdd.py\", line 1378, in first\n",
      "    rs = self.take(1)\n",
      "  File \"/home/jh/anaconda3/envs/movie_recomm/lib/python3.7/site-packages/pyspark/rdd.py\", line 1360, in take\n",
      "    res = self.context.runJob(self, takeUpToNumLeft, p)\n",
      "  File \"/home/jh/anaconda3/envs/movie_recomm/lib/python3.7/site-packages/pyspark/context.py\", line 1069, in runJob\n",
      "    sock_info = self._jvm.PythonRDD.runJob(self._jsc.sc(), mappedRDD._jrdd, partitions)\n",
      "  File \"/home/jh/anaconda3/envs/movie_recomm/lib/python3.7/site-packages/py4j/java_gateway.py\", line 1257, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/home/jh/anaconda3/envs/movie_recomm/lib/python3.7/site-packages/pyspark/sql/utils.py\", line 63, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/jh/anaconda3/envs/movie_recomm/lib/python3.7/site-packages/py4j/protocol.py\", line 336, in get_return_value\n",
      "    format(target_id, \".\", name))\n",
      "py4j.protocol.Py4JError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jh/anaconda3/envs/movie_recomm/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jh/anaconda3/envs/movie_recomm/lib/python3.7/site-packages/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jh/anaconda3/envs/movie_recomm/lib/python3.7/site-packages/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:41813)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jh/anaconda3/envs/movie_recomm/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-28-108ad13ccb30>\", line 8, in <module>\n",
      "    final_model = train_ALS(train, validation, num_iterations, reg_params, ranks)\n",
      "  File \"<ipython-input-27-fed98f5c3b82>\", line 36, in train_ALS\n",
      "    seed=99)\n",
      "  File \"/home/jh/anaconda3/envs/movie_recomm/lib/python3.7/site-packages/pyspark/mllib/recommendation.py\", line 273, in train\n",
      "    model = callMLlibFunc(\"trainALSModel\", cls._prepare(ratings), rank, iterations,\n",
      "  File \"/home/jh/anaconda3/envs/movie_recomm/lib/python3.7/site-packages/pyspark/mllib/recommendation.py\", line 230, in _prepare\n",
      "    first = ratings.first()\n",
      "  File \"/home/jh/anaconda3/envs/movie_recomm/lib/python3.7/site-packages/pyspark/rdd.py\", line 1378, in first\n",
      "    rs = self.take(1)\n",
      "  File \"/home/jh/anaconda3/envs/movie_recomm/lib/python3.7/site-packages/pyspark/rdd.py\", line 1360, in take\n",
      "    res = self.context.runJob(self, takeUpToNumLeft, p)\n",
      "  File \"/home/jh/anaconda3/envs/movie_recomm/lib/python3.7/site-packages/pyspark/context.py\", line 1069, in runJob\n",
      "    sock_info = self._jvm.PythonRDD.runJob(self._jsc.sc(), mappedRDD._jrdd, partitions)\n",
      "  File \"/home/jh/anaconda3/envs/movie_recomm/lib/python3.7/site-packages/py4j/java_gateway.py\", line 1257, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/home/jh/anaconda3/envs/movie_recomm/lib/python3.7/site-packages/pyspark/sql/utils.py\", line 63, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/jh/anaconda3/envs/movie_recomm/lib/python3.7/site-packages/py4j/protocol.py\", line 336, in get_return_value\n",
      "    format(target_id, \".\", name))\n",
      "py4j.protocol.Py4JError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jh/anaconda3/envs/movie_recomm/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jh/anaconda3/envs/movie_recomm/lib/python3.7/site-packages/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jh/anaconda3/envs/movie_recomm/lib/python3.7/site-packages/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:41813)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jh/anaconda3/envs/movie_recomm/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-28-108ad13ccb30>\", line 8, in <module>\n",
      "    final_model = train_ALS(train, validation, num_iterations, reg_params, ranks)\n",
      "  File \"<ipython-input-27-fed98f5c3b82>\", line 36, in train_ALS\n",
      "    seed=99)\n",
      "  File \"/home/jh/anaconda3/envs/movie_recomm/lib/python3.7/site-packages/pyspark/mllib/recommendation.py\", line 273, in train\n",
      "    model = callMLlibFunc(\"trainALSModel\", cls._prepare(ratings), rank, iterations,\n",
      "  File \"/home/jh/anaconda3/envs/movie_recomm/lib/python3.7/site-packages/pyspark/mllib/recommendation.py\", line 230, in _prepare\n",
      "    first = ratings.first()\n",
      "  File \"/home/jh/anaconda3/envs/movie_recomm/lib/python3.7/site-packages/pyspark/rdd.py\", line 1378, in first\n",
      "    rs = self.take(1)\n",
      "  File \"/home/jh/anaconda3/envs/movie_recomm/lib/python3.7/site-packages/pyspark/rdd.py\", line 1360, in take\n",
      "    res = self.context.runJob(self, takeUpToNumLeft, p)\n",
      "  File \"/home/jh/anaconda3/envs/movie_recomm/lib/python3.7/site-packages/pyspark/context.py\", line 1069, in runJob\n",
      "    sock_info = self._jvm.PythonRDD.runJob(self._jsc.sc(), mappedRDD._jrdd, partitions)\n",
      "  File \"/home/jh/anaconda3/envs/movie_recomm/lib/python3.7/site-packages/py4j/java_gateway.py\", line 1257, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/home/jh/anaconda3/envs/movie_recomm/lib/python3.7/site-packages/pyspark/sql/utils.py\", line 63, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/jh/anaconda3/envs/movie_recomm/lib/python3.7/site-packages/py4j/protocol.py\", line 336, in get_return_value\n",
      "    format(target_id, \".\", name))\n",
      "py4j.protocol.Py4JError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jh/anaconda3/envs/movie_recomm/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jh/anaconda3/envs/movie_recomm/lib/python3.7/site-packages/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jh/anaconda3/envs/movie_recomm/lib/python3.7/site-packages/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:41813)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jh/anaconda3/envs/movie_recomm/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-28-108ad13ccb30>\", line 8, in <module>\n",
      "    final_model = train_ALS(train, validation, num_iterations, reg_params, ranks)\n",
      "  File \"<ipython-input-27-fed98f5c3b82>\", line 36, in train_ALS\n",
      "    seed=99)\n",
      "  File \"/home/jh/anaconda3/envs/movie_recomm/lib/python3.7/site-packages/pyspark/mllib/recommendation.py\", line 273, in train\n",
      "    model = callMLlibFunc(\"trainALSModel\", cls._prepare(ratings), rank, iterations,\n",
      "  File \"/home/jh/anaconda3/envs/movie_recomm/lib/python3.7/site-packages/pyspark/mllib/recommendation.py\", line 230, in _prepare\n",
      "    first = ratings.first()\n",
      "  File \"/home/jh/anaconda3/envs/movie_recomm/lib/python3.7/site-packages/pyspark/rdd.py\", line 1378, in first\n",
      "    rs = self.take(1)\n",
      "  File \"/home/jh/anaconda3/envs/movie_recomm/lib/python3.7/site-packages/pyspark/rdd.py\", line 1360, in take\n",
      "    res = self.context.runJob(self, takeUpToNumLeft, p)\n",
      "  File \"/home/jh/anaconda3/envs/movie_recomm/lib/python3.7/site-packages/pyspark/context.py\", line 1069, in runJob\n",
      "    sock_info = self._jvm.PythonRDD.runJob(self._jsc.sc(), mappedRDD._jrdd, partitions)\n",
      "  File \"/home/jh/anaconda3/envs/movie_recomm/lib/python3.7/site-packages/py4j/java_gateway.py\", line 1257, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/home/jh/anaconda3/envs/movie_recomm/lib/python3.7/site-packages/pyspark/sql/utils.py\", line 63, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/jh/anaconda3/envs/movie_recomm/lib/python3.7/site-packages/py4j/protocol.py\", line 336, in get_return_value\n",
      "    format(target_id, \".\", name))\n",
      "py4j.protocol.Py4JError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jh/anaconda3/envs/movie_recomm/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jh/anaconda3/envs/movie_recomm/lib/python3.7/site-packages/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jh/anaconda3/envs/movie_recomm/lib/python3.7/site-packages/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:41813)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jh/anaconda3/envs/movie_recomm/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-28-108ad13ccb30>\", line 8, in <module>\n",
      "    final_model = train_ALS(train, validation, num_iterations, reg_params, ranks)\n",
      "  File \"<ipython-input-27-fed98f5c3b82>\", line 36, in train_ALS\n",
      "    seed=99)\n",
      "  File \"/home/jh/anaconda3/envs/movie_recomm/lib/python3.7/site-packages/pyspark/mllib/recommendation.py\", line 273, in train\n",
      "    model = callMLlibFunc(\"trainALSModel\", cls._prepare(ratings), rank, iterations,\n",
      "  File \"/home/jh/anaconda3/envs/movie_recomm/lib/python3.7/site-packages/pyspark/mllib/recommendation.py\", line 230, in _prepare\n",
      "    first = ratings.first()\n",
      "  File \"/home/jh/anaconda3/envs/movie_recomm/lib/python3.7/site-packages/pyspark/rdd.py\", line 1378, in first\n",
      "    rs = self.take(1)\n",
      "  File \"/home/jh/anaconda3/envs/movie_recomm/lib/python3.7/site-packages/pyspark/rdd.py\", line 1360, in take\n",
      "    res = self.context.runJob(self, takeUpToNumLeft, p)\n",
      "  File \"/home/jh/anaconda3/envs/movie_recomm/lib/python3.7/site-packages/pyspark/context.py\", line 1069, in runJob\n",
      "    sock_info = self._jvm.PythonRDD.runJob(self._jsc.sc(), mappedRDD._jrdd, partitions)\n",
      "  File \"/home/jh/anaconda3/envs/movie_recomm/lib/python3.7/site-packages/py4j/java_gateway.py\", line 1257, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/home/jh/anaconda3/envs/movie_recomm/lib/python3.7/site-packages/pyspark/sql/utils.py\", line 63, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/jh/anaconda3/envs/movie_recomm/lib/python3.7/site-packages/py4j/protocol.py\", line 336, in get_return_value\n",
      "    format(target_id, \".\", name))\n",
      "py4j.protocol.Py4JError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jh/anaconda3/envs/movie_recomm/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jh/anaconda3/envs/movie_recomm/lib/python3.7/site-packages/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jh/anaconda3/envs/movie_recomm/lib/python3.7/site-packages/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n"
     ]
    },
    {
     "ename": "Py4JError",
     "evalue": "An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-108ad13ccb30>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# grid search and select best model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mfinal_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_ALS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mranks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'Total Runtime: {:.2f} seconds'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-fed98f5c3b82>\u001b[0m in \u001b[0;36mtrain_ALS\u001b[0;34m(train_data, validation_data, num_iters, reg_param, ranks)\u001b[0m\n\u001b[1;32m     34\u001b[0m                 \u001b[0mrank\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0mlambda_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreg\u001b[0m\u001b[0;34m,\u001b[0m           \u001b[0;31m# regularization param\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                 seed=99)\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;31m# make prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/movie_recomm/lib/python3.7/site-packages/pyspark/mllib/recommendation.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(cls, ratings, rank, iterations, lambda_, blocks, nonnegative, seed)\u001b[0m\n\u001b[1;32m    271\u001b[0m           \u001b[0;34m(\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         \"\"\"\n\u001b[0;32m--> 273\u001b[0;31m         model = callMLlibFunc(\"trainALSModel\", cls._prepare(ratings), rank, iterations,\n\u001b[0m\u001b[1;32m    274\u001b[0m                               lambda_, blocks, nonnegative, seed)\n\u001b[1;32m    275\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mMatrixFactorizationModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/movie_recomm/lib/python3.7/site-packages/pyspark/mllib/recommendation.py\u001b[0m in \u001b[0;36m_prepare\u001b[0;34m(cls, ratings)\u001b[0m\n\u001b[1;32m    228\u001b[0m             raise TypeError(\"Ratings should be represented by either an RDD or a DataFrame, \"\n\u001b[1;32m    229\u001b[0m                             \"but got %s.\" % type(ratings))\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0mfirst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mratings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfirst\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRating\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/movie_recomm/lib/python3.7/site-packages/pyspark/rdd.py\u001b[0m in \u001b[0;36mfirst\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1376\u001b[0m         \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRDD\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mempty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1377\u001b[0m         \"\"\"\n\u001b[0;32m-> 1378\u001b[0;31m         \u001b[0mrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1379\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1380\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/movie_recomm/lib/python3.7/site-packages/pyspark/rdd.py\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, num)\u001b[0m\n\u001b[1;32m   1358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1359\u001b[0m             \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartsScanned\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartsScanned\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnumPartsToTry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotalParts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1360\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunJob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtakeUpToNumLeft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1362\u001b[0m             \u001b[0mitems\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/movie_recomm/lib/python3.7/site-packages/pyspark/context.py\u001b[0m in \u001b[0;36mrunJob\u001b[0;34m(self, rdd, partitionFunc, partitions, allowLocal)\u001b[0m\n\u001b[1;32m   1067\u001b[0m         \u001b[0;31m# SparkContext#runJob.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1068\u001b[0m         \u001b[0mmappedRDD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapPartitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartitionFunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1069\u001b[0;31m         \u001b[0msock_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunJob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmappedRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartitions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1070\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmappedRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd_deserializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/movie_recomm/lib/python3.7/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/movie_recomm/lib/python3.7/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/movie_recomm/lib/python3.7/site-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    334\u001b[0m             raise Py4JError(\n\u001b[1;32m    335\u001b[0m                 \u001b[0;34m\"An error occurred while calling {0}{1}{2}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m                 format(target_id, \".\", name))\n\u001b[0m\u001b[1;32m    337\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0mtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JError\u001b[0m: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4min 23s\n"
     ]
    }
   ],
   "source": [
    "# hyper-param config\n",
    "num_iterations = 10\n",
    "ranks = [8, 10, 12, 14, 16, 18, 20]\n",
    "reg_params = [0.001, 0.01, 0.05, 0.1, 0.2]\n",
    "\n",
    "# grid search and select best model\n",
    "start_time = time.time()\n",
    "final_model = train_ALS(train, validation, num_iterations, reg_params, ranks)\n",
    "\n",
    "print ('Total Runtime: {:.2f} seconds'.format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
