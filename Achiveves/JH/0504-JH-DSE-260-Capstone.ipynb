{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference\n",
    "- https://towardsdatascience.com/building-a-collaborative-filtering-recommender-system-with-clickstream-data-dffc86c8c65\n",
    "- https://pypi.org/project/python-amazon-simple-product-api/\n",
    "- https://github.com/benfred/implicit\n",
    "- https://medium.com/@patelneha1495/recommendation-system-in-python-using-als-algorithm-and-apache-spark-27aca08eaab3\n",
    "- https://towardsdatascience.com/prototyping-a-recommender-system-step-by-step-part-2-alternating-least-square-als-matrix-4a76c58714a1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data format\n",
    "- Format is one-review-per-line in json. See examples below for further help reading the data.\n",
    "\n",
    "    - reviewerID - ID of the reviewer, e.g. A2SUAM1J3GNN3B\n",
    "    - asin - ID of the product, e.g. 0000013714\n",
    "    - reviewerName - name of the reviewer\n",
    "    - vote - helpful votes of the review\n",
    "    - style - a disctionary of the product metadata, e.g., \"Format\" is \"Hardcover\"\n",
    "    - reviewText - text of the review\n",
    "    - overall - rating of the product\n",
    "    - summary - summary of the review\n",
    "    - unixReviewTime - time of the review (unix time)\n",
    "    - reviewTime - time of the review (raw)\n",
    "    - image - images that users post after they have received the produc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ipython-autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### To measure all running time\n",
    "# https://github.com/cpcloud/ipython-autotime\n",
    "\n",
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Garbage collector: collected 0 objects.\n",
      "time: 15.8 ms\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "collected = gc.collect()\n",
    "print (\"Garbage collector: collected %d objects.\" % collected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install implicit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 665 ms\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import scipy.sparse as sparse\n",
    "import numpy as np\n",
    "import random\n",
    "import implicit\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 205 ms\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import tqdm\n",
    "import codecs\n",
    "\n",
    "# spark imports\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import UserDefinedFunction, explode, desc\n",
    "from pyspark.sql.types import StringType, ArrayType\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# data science imports\n",
    "import math\n",
    "\n",
    "# visualization imports\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import json\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 845 µs\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.21 s\n"
     ]
    }
   ],
   "source": [
    "number_cores = 16\n",
    "memory_gb = 32\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"amazon recommendation\") \\\n",
    "    .config(\"spark.driver.memory\", '{}g'.format(memory_gb)) \\\n",
    "    .config(\"spark.master\", 'local[{}]'.format(number_cores)) \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# get spark context\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Download dataset from: http://deepyeti.ucsd.edu/jianmo/amazon/categoryFiles/Clothing_Shoes_and_Jewelry.json.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 3.4G\n",
      "drwxrwxr-x  5 ec2-user ec2-user 4.0K May 14 17:55 .\n",
      "drwxrwxr-x 10 ec2-user ec2-user 4.0K May 14 17:30 ..\n",
      "-rw-rw-r--  1 ec2-user ec2-user  46K May 14 17:55 0504-JH-DSE-260-Capstone.ipynb\n",
      "-rw-rw-r--  1 ec2-user ec2-user 3.4G May 14 07:16 Clothing_Shoes_and_Jewelry.json.gz\n",
      "drwxrwxr-x  3 ec2-user ec2-user 4.0K May 14 17:36 gluon_recommender_system\n",
      "drwxrwxr-x  2 ec2-user ec2-user 4.0K May 14 07:14 .ipynb_checkpoints\n",
      "-rw-rw-r--  1 ec2-user ec2-user  83K May 14 02:03 JH-DSE-260-Capstone-ALS-2.ipynb\n",
      "drwxrwxr-x  2 ec2-user ec2-user 4.0K May 14 07:18 spark-warehouse\n",
      "time: 117 ms\n"
     ]
    }
   ],
   "source": [
    "!ls -alh "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 880 µs\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = './'\n",
    "REVIEW_DATA = 'Clothing_Shoes_and_Jewelry.json.gz'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Please unzip Clothing_Shoes_and_Jewelry.json.gz to Clothing_Shoes_and_Jewelry.json\n",
    "2. Load Clothing_Shoes_and_Jewelry.json (14.1 GB (14,144,939,923 bytes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3min 59s\n"
     ]
    }
   ],
   "source": [
    "ratings = spark.read.load(DATA_PATH+REVIEW_DATA, format='json', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+-------+--------------------+-----------+--------------+-------------+--------------------+--------------------+--------------+--------+----+\n",
      "|      asin|image|overall|          reviewText| reviewTime|    reviewerID| reviewerName|               style|             summary|unixReviewTime|verified|vote|\n",
      "+----------+-----+-------+--------------------+-----------+--------------+-------------+--------------------+--------------------+--------------+--------+----+\n",
      "|0871167042| null|    5.0|This book has bea...| 05 4, 2014|A2IC3NZN488KWK|   Ruby Tulip|[,,,,,,,,  Paperb...|      Unique designs|    1399161600|    true|   2|\n",
      "|0871167042| null|    4.0|I love the ideas ...|04 26, 2014|A3OT9BYASFGU2X|    Laurie K.|[,,,,,,,,  Paperb...|makes you want to...|    1398470400|    true|null|\n",
      "|0871167042| null|    5.0|As someone who ha...|04 17, 2014|A28GK1G2KDXHRP|Marie Rhoades|[,,,,,,,,  Paperb...|Highly Recommend ...|    1397692800|   false|   6|\n",
      "+----------+-----+-------+--------------------+-----------+--------------+-------------+--------------------+--------------------+--------------+--------+----+\n",
      "only showing top 3 rows\n",
      "\n",
      "time: 257 ms\n"
     ]
    }
   ],
   "source": [
    "ratings.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.92 ms\n"
     ]
    }
   ],
   "source": [
    "type(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 871 µs\n"
     ]
    }
   ],
   "source": [
    "# print(\"Shape of Data\", (ratings.count(), len(ratings.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop and Clean data\n",
    "    - Drop null in Vote\n",
    "    - Voted review comment is more reliable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 43.3 ms\n"
     ]
    }
   ],
   "source": [
    "clean_ratings = ratings.na.drop(how='any', subset='vote')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Data (2886813, 12)\n",
      "time: 1min 47s\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of Data\", (clean_ratings.count(), len(clean_ratings.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['asin',\n",
       " 'image',\n",
       " 'overall',\n",
       " 'reviewText',\n",
       " 'reviewTime',\n",
       " 'reviewerID',\n",
       " 'reviewerName',\n",
       " 'style',\n",
       " 'summary',\n",
       " 'unixReviewTime',\n",
       " 'verified',\n",
       " 'vote']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.01 ms\n"
     ]
    }
   ],
   "source": [
    "clean_ratings.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract ['asin', 'overall', 'reviewerID'] from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['asin',\n",
       " 'image',\n",
       " 'overall',\n",
       " 'reviewText',\n",
       " 'reviewTime',\n",
       " 'reviewerID',\n",
       " 'reviewerName',\n",
       " 'style',\n",
       " 'summary',\n",
       " 'unixReviewTime',\n",
       " 'verified',\n",
       " 'vote']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.27 ms\n"
     ]
    }
   ],
   "source": [
    "ratings.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 5.38 ms\n"
     ]
    }
   ],
   "source": [
    "product_ratings = ratings.drop(\n",
    " 'image',\n",
    " 'reviewText',\n",
    " 'reviewTime',\n",
    " 'reviewerName',\n",
    " 'style',\n",
    " 'summary',\n",
    " 'unixReviewTime',\n",
    " 'verified',\n",
    " 'vote')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+--------------+\n",
      "|      asin|overall|    reviewerID|\n",
      "+----------+-------+--------------+\n",
      "|0871167042|    5.0|A2IC3NZN488KWK|\n",
      "|0871167042|    4.0|A3OT9BYASFGU2X|\n",
      "|0871167042|    5.0|A28GK1G2KDXHRP|\n",
      "|0871167042|    5.0|A3NFXFEKW8OK0E|\n",
      "|0871167042|    5.0|A3I6G5TKBVJEK9|\n",
      "|0871167042|    5.0|A1A7Y1M8AJWNZ8|\n",
      "|0871167042|    5.0|A30FG02C424EJ5|\n",
      "|0871167042|    5.0| ADQQYU1UCDEWB|\n",
      "|0871167042|    5.0|A39YL2NXZORK56|\n",
      "|0871167042|    5.0|A2PRY50ZESF1MH|\n",
      "|0871167042|    5.0|A2G9GWQEWWNQUB|\n",
      "|0871167042|    4.0|A3RGH15H17SM1Z|\n",
      "|0871167042|    3.0|A20QJNRKLJVP1E|\n",
      "|0871167042|    5.0|A1G26EYQGW3YF1|\n",
      "|0871167042|    4.0|A2JGAZF2Y2BDU6|\n",
      "|0871167042|    5.0|A3NI5OGW35SLY2|\n",
      "|0871167042|    5.0|A1OPRA4NE56EV6|\n",
      "|0871167042|    4.0|A3M6UXIK7XTA7A|\n",
      "|0871167042|    5.0|A3I3B5OSB80ZXC|\n",
      "|0871167042|    5.0| A62O7C5RQB353|\n",
      "+----------+-------+--------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "time: 36.3 ms\n"
     ]
    }
   ],
   "source": [
    "product_ratings.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.85 ms\n"
     ]
    }
   ],
   "source": [
    "type(product_ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert pyspark.sql.dataframe.DataFrame to Pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 512 µs\n"
     ]
    }
   ],
   "source": [
    "# rating_df = product_ratings.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- make csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2min 27s\n"
     ]
    }
   ],
   "source": [
    "product_ratings.write.csv(\"./asin_overall_reviewerID_with_voted_review.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 3471284\n",
      "drwxrwxr-x  6 ec2-user ec2-user       4096 May 14 18:15 .\n",
      "drwxrwxr-x 10 ec2-user ec2-user       4096 May 14 17:30 ..\n",
      "-rw-rw-r--  1 ec2-user ec2-user      31494 May 14 18:15 0504-JH-DSE-260-Capstone.ipynb\n",
      "drwxrwxr-x  2 ec2-user ec2-user       4096 May 14 18:14 asin_overall_reviewerID_with_voted_review.csv\n",
      "-rw-rw-r--  1 ec2-user ec2-user 3554445765 May 14 07:16 Clothing_Shoes_and_Jewelry.json.gz\n",
      "drwxrwxr-x  2 ec2-user ec2-user       4096 May 14 07:14 .ipynb_checkpoints\n",
      "-rw-rw-r--  1 ec2-user ec2-user      84739 May 14 02:03 JH-DSE-260-Capstone-ALS-2.ipynb\n",
      "drwxrwxr-x  3 ec2-user ec2-user       4096 May 14 17:36 JH-gluon_recommender_system\n",
      "drwxrwxr-x  2 ec2-user ec2-user       4096 May 14 07:18 spark-warehouse\n",
      "time: 115 ms\n"
     ]
    }
   ],
   "source": [
    "!ls -al ./"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_df = pd.read_csv('./data/asin_overall_reviewerID.csv/part-00000-6ef94642-3c25-4f7d-ade9-981f91953b81-c000.csv',\n",
    "                        names=['asin', 'overall', 'reviewerID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_df.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_df['overall'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rating_df.groupby(['reviewerID', 'asin']).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Drop duplicated records.\n",
    "- Group overall together with reviwerID and asin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_df = rating_df.drop_duplicates()\n",
    "grouped_df = rating_df.groupby(['reviewerID', 'asin']).sum().reset_index()\n",
    "grouped_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df['reviewerID_encode'] = grouped_df['reviewerID'].astype(\"category\")\n",
    "grouped_df['asin_encode'] = grouped_df['asin'].astype(\"category\")\n",
    "grouped_df['reviewerID_encode'] = grouped_df['reviewerID_encode'].cat.codes\n",
    "grouped_df['asin_encode'] = grouped_df['asin_encode'].cat.codes\n",
    "grouped_df = grouped_df[['reviewerID','reviewerID_encode', 'asin', 'asin_encode', 'overall']]\n",
    "\n",
    "sparse_content_person = sparse.csr_matrix(\n",
    "    (grouped_df['overall'].astype(float), \n",
    "    (grouped_df['asin_encode'], grouped_df['reviewerID_encode']))\n",
    ")\n",
    "\n",
    "sparse_person_content = sparse.csr_matrix(\n",
    "    (grouped_df['overall'].astype(float), \n",
    "    (grouped_df['reviewerID_encode'], grouped_df['asin_encode']))\n",
    ")\n",
    "\n",
    "model = implicit.als.AlternatingLeastSquares(\n",
    "    factors=20, \n",
    "    regularization=0.1, \n",
    "    iterations=50, \n",
    "    use_gpu=True)\n",
    "\n",
    "alpha = 15\n",
    "data = (sparse_content_person * alpha).astype('double')\n",
    "\n",
    "model.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Labling encoding asin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommend ASIN(Products) based on product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asin='B00NX2IHS4'\n",
    "\n",
    "asin_encode = grouped_df.loc[grouped_df['asin'] == asin].iloc[0].asin_encode\n",
    "print(\"Covnert asin: %s to encoded asin: %d\" %(asin, asin_encode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_similar = 20\n",
    "\n",
    "person_vecs = model.user_factors\n",
    "content_vecs = model.item_factors\n",
    "\n",
    "content_norms = np.sqrt((content_vecs * content_vecs).sum(axis=1))\n",
    "\n",
    "scores = content_vecs.dot(content_vecs[asin_encode]) / content_norms\n",
    "top_idx = np.argpartition(scores, -n_similar)[-n_similar:]\n",
    "similar = sorted(zip(top_idx, scores[top_idx] / content_norms[asin_encode]), key=lambda x: -x[1])\n",
    "\n",
    "for content in similar:\n",
    "    idx, score = content\n",
    "    print(\"Encoded ASIN: %d\" %(idx), \n",
    "          \"| Simility Score: %.5f\" %(round(score, 5)), \n",
    "          \"| https://www.amazon.com/dp/\"+grouped_df.asin.loc[grouped_df.asin_encode == idx].iloc[0])\n",
    "#     print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouped_df.loc[grouped_df['person_id'] == 50].sort_values(by=['eventStrength'], ascending=False)[['title', 'person_id', 'eventStrength']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df.asin.loc[grouped_df.asin_encode == 1564263].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_similar = 20\n",
    "output_filename='product_based_recommend.tsv'\n",
    "\n",
    "person_vecs = model.user_factors\n",
    "content_vecs = model.item_factors\n",
    "\n",
    "asin_encode_list = grouped_df['asin_encode'].tolist()\n",
    "\n",
    "with tqdm.tqdm(total=len(asin_encode_list)) as progress:\n",
    "    with codecs.open(output_filename, \"w\", \"utf8\") as o:\n",
    "        for asin_encode in asin_encode_list:\n",
    "        #     print(asin_encode)\n",
    "            content_norms = np.sqrt((content_vecs * content_vecs).sum(axis=1))\n",
    "\n",
    "            scores = content_vecs.dot(content_vecs[asin_encode]) / content_norms\n",
    "            top_idx = np.argpartition(scores, -n_similar)[-n_similar:]\n",
    "            similar = sorted(zip(top_idx, scores[top_idx] / content_norms[asin_encode]), key=lambda x: -x[1])\n",
    "\n",
    "            input_asin =\"\"\n",
    "            for content in similar:\n",
    "                idx, score = content\n",
    "                asin = grouped_df.asin.loc[grouped_df.asin_encode == idx].iloc[0]\n",
    "                \n",
    "                if round(score, 5)==1.00000:\n",
    "#                     print(round(score))\n",
    "                    input_asin = grouped_df.asin.loc[grouped_df.asin_encode == idx].iloc[0]\n",
    "                o.write(\"%s\\t%s\\t%.5f\\t%s\\n\" % (input_asin, asin, round(score, 5), \"https://www.amazon.com/dp/\"+asin))\n",
    "#                 print(input_asin)\n",
    "\n",
    "#                 print(\"Encoded ASIN: %d\" %(idx), \n",
    "#                       \"| Simility Score: %.5f\" %(round(score, 5)), \n",
    "#                       \"| https://www.amazon.com/dp/\"+grouped_df.asin.loc[grouped_df.asin_encode == idx].iloc[0])\n",
    "#             print(\"\\n\")\n",
    "            progress.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommend ASIN(Products) to Persons\n",
    "- The following function will return the top 10 recommendations chosen based on the person / content vectors for contents never interacted with for any given person."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(person_id, sparse_person_content, person_vecs, content_vecs, num_contents=10):\n",
    "    # Get the interactions scores from the sparse person content matrix\n",
    "    person_interactions = sparse_person_content[asin_encode,:].toarray()\n",
    "    # Add 1 to everything, so that articles with no interaction yet become equal to 1\n",
    "    person_interactions = person_interactions.reshape(-1) + 1\n",
    "    # Make articles already interacted zero\n",
    "    person_interactions[person_interactions > 1] = 0\n",
    "    # Get dot product of person vector and all content vectors\n",
    "    rec_vector = person_vecs[asin_encode,:].dot(content_vecs.T).toarray()\n",
    "    \n",
    "    # Scale this recommendation vector between 0 and 1\n",
    "    min_max = MinMaxScaler()\n",
    "    rec_vector_scaled = min_max.fit_transform(rec_vector.reshape(-1,1))[:,0]\n",
    "    # Content already interacted have their recommendation multiplied by zero\n",
    "    recommend_vector = person_interactions * rec_vector_scaled\n",
    "    # Sort the indices of the content into order of best recommendations\n",
    "    content_idx = np.argsort(recommend_vector)[::-1][:num_contents]\n",
    "    \n",
    "    # Start empty list to store titles and scores\n",
    "    asin_list = []\n",
    "    scores = []\n",
    "\n",
    "    for idx in content_idx:\n",
    "        # Append titles and scores to the list\n",
    "        asin_list.append(\"https://www.amazon.com/dp/\"+grouped_df.asin.loc[grouped_df.asin_encode == idx].iloc[0])\n",
    "        scores.append(recommend_vector[idx])\n",
    "\n",
    "    recommendations = pd.DataFrame({'ASIN': asin_list, 'SCORE': scores})\n",
    "\n",
    "    return recommendations\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create recommendations for person\n",
    "reviewerID=\"A0000040I1OM9N4SGBD8\"\n",
    "reviewerID_encode = grouped_df.loc[grouped_df['reviewerID'] == reviewerID].iloc[0].asin_encode\n",
    "print(\"Covnert reviewerID: %s to encoded reviewerID: %d\" %(reviewerID, reviewerID_encode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the trained person and content vectors. We convert them to csr matrices\n",
    "person_vecs = sparse.csr_matrix(model.user_factors)\n",
    "content_vecs = sparse.csr_matrix(model.item_factors)\n",
    "\n",
    "person_id = reviewerID_encode\n",
    "\n",
    "recommendations = recommend(person_id, sparse_person_content, person_vecs, content_vecs)\n",
    "\n",
    "print(\"\\n** Recommended list for reviewer:\", reviewerID)\n",
    "print()\n",
    "print(recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here we have top recommendations for reviewerID=\"A0000040I1OM9N4SGBD8\". \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df.loc[grouped_df['reviewerID'] == 'A0000040I1OM9N4SGBD8'].sort_values(by=['overall'], ascending=False)[['asin', 'reviewerID', 'overall']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation the Recommender System \n",
    "- https://nbviewer.jupyter.org/github/jmsteinw/Notebooks/blob/master/RecEngine_NB.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def make_train(ratings, pct_test = 0.2):\n",
    "    test_set = ratings.copy() # Make a copy of the original set to be the test set. \n",
    "    test_set[test_set != 0] = 1 # Store the test set as a binary preference matrix\n",
    "    \n",
    "    training_set = ratings.copy() # Make a copy of the original data we can alter as our training set. \n",
    "    \n",
    "    nonzero_inds = training_set.nonzero() # Find the indices in the ratings data where an interaction exists\n",
    "    nonzero_pairs = list(zip(nonzero_inds[0], nonzero_inds[1])) # Zip these pairs together of item,user index into list\n",
    "\n",
    "    \n",
    "    random.seed(0) # Set the random seed to zero for reproducibility\n",
    "    \n",
    "    num_samples = int(np.ceil(pct_test*len(nonzero_pairs))) # Round the number of samples needed to the nearest integer\n",
    "    samples = random.sample(nonzero_pairs, num_samples) # Sample a random number of item-user pairs without replacement\n",
    "\n",
    "    content_inds = [index[0] for index in samples] # Get the item row indices\n",
    "\n",
    "    person_inds = [index[1] for index in samples] # Get the user column indices\n",
    "\n",
    "    \n",
    "    training_set[content_inds, person_inds] = 0 # Assign all of the randomly chosen user-item pairs to zero\n",
    "    training_set.eliminate_zeros() # Get rid of zeros in sparse array storage after update to save space\n",
    "    \n",
    "    return training_set, test_set, list(set(person_inds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_train, content_test, content_persons_altered = make_train(sparse_content_person, pct_test = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc_score(predictions, test):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(test, predictions)\n",
    "    return metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mean_auc(training_set, altered_persons, predictions, test_set):\n",
    "    store_auc = [] # An empty list to store the AUC for each user that had an item removed from the training set\n",
    "    popularity_auc = [] # To store popular AUC scores\n",
    "    pop_contents = np.array(test_set.sum(axis = 1)).reshape(-1) # Get sum of item iteractions to find most popular\n",
    "    content_vecs = predictions[1]\n",
    "    for person in altered_persons: # Iterate through each user that had an item altered\n",
    "        training_column = training_set[:,person].toarray().reshape(-1) # Get the training set column\n",
    "        zero_inds = np.where(training_column == 0) # Find where the interaction had not yet occurred\n",
    "        \n",
    "        # Get the predicted values based on our user/item vectors\n",
    "        person_vec = predictions[0][person,:]\n",
    "        pred = person_vec.dot(content_vecs).toarray()[0,zero_inds].reshape(-1)\n",
    "        \n",
    "        # Get only the items that were originally zero\n",
    "        # Select all ratings from the MF prediction for this user that originally had no iteraction\n",
    "        actual = test_set[:,person].toarray()[zero_inds,0].reshape(-1)\n",
    "        \n",
    "        # Select the binarized yes/no interaction pairs from the original full data\n",
    "        # that align with the same pairs in training \n",
    "        pop = pop_contents[zero_inds] # Get the item popularity for our chosen items\n",
    "        \n",
    "        store_auc.append(auc_score(pred, actual)) # Calculate AUC for the given user and store\n",
    "        \n",
    "        popularity_auc.append(auc_score(pop, actual)) # Calculate AUC using most popular and score\n",
    "    # End users iteration\n",
    "    \n",
    "    return float('%.3f'%np.mean(store_auc)), float('%.3f'%np.mean(popularity_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_mean_auc(content_train, content_persons_altered,\n",
    "              [person_vecs, content_vecs.T], content_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
